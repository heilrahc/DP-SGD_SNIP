2023-02-06 23:03:36.155072: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-06 23:03:36.277412: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-06 23:03:36.789982: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-02-06 23:03:36.790044: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-02-06 23:03:36.790052: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
WARNING: this experiment is not being saved.
Loading mnist dataset.
Creating default-fc model.
iteration:  1
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.39it/s]100%|██████████| 1/1 [00:00<00:00,  7.37it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:08<01:17,  8.64s/it] 20%|██        | 2/10 [00:17<01:08,  8.56s/it] 30%|███       | 3/10 [00:25<01:00,  8.67s/it] 40%|████      | 4/10 [00:34<00:51,  8.64s/it] 50%|█████     | 5/10 [00:43<00:43,  8.65s/it] 60%|██████    | 6/10 [00:51<00:34,  8.66s/it] 70%|███████   | 7/10 [01:00<00:26,  8.72s/it] 80%|████████  | 8/10 [01:09<00:17,  8.71s/it] 90%|█████████ | 9/10 [01:18<00:08,  8.76s/it]100%|██████████| 10/10 [01:27<00:00,  8.95s/it]100%|██████████| 10/10 [01:27<00:00,  8.77s/it]
iteration:  2
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 70.19it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:22,  9.14s/it] 20%|██        | 2/10 [00:18<01:13,  9.16s/it] 30%|███       | 3/10 [00:27<01:03,  9.11s/it] 40%|████      | 4/10 [00:36<00:54,  9.04s/it] 50%|█████     | 5/10 [00:45<00:45,  9.08s/it] 60%|██████    | 6/10 [00:54<00:36,  9.09s/it] 70%|███████   | 7/10 [01:03<00:27,  9.08s/it] 80%|████████  | 8/10 [01:12<00:18,  9.07s/it] 90%|█████████ | 9/10 [01:21<00:09,  9.02s/it]100%|██████████| 10/10 [01:30<00:00,  9.02s/it]100%|██████████| 10/10 [01:30<00:00,  9.06s/it]
iteration:  3
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.79it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:21,  9.05s/it] 20%|██        | 2/10 [00:18<01:13,  9.14s/it] 30%|███       | 3/10 [00:27<01:05,  9.30s/it] 40%|████      | 4/10 [00:37<00:57,  9.51s/it] 50%|█████     | 5/10 [00:47<00:48,  9.61s/it] 60%|██████    | 6/10 [00:56<00:38,  9.53s/it] 70%|███████   | 7/10 [01:05<00:28,  9.42s/it] 80%|████████  | 8/10 [01:15<00:18,  9.36s/it] 90%|█████████ | 9/10 [01:24<00:09,  9.31s/it]100%|██████████| 10/10 [01:33<00:00,  9.25s/it]100%|██████████| 10/10 [01:33<00:00,  9.35s/it]
iteration:  4
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.02it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:24,  9.43s/it] 20%|██        | 2/10 [00:18<01:14,  9.37s/it] 30%|███       | 3/10 [00:28<01:07,  9.59s/it] 40%|████      | 4/10 [00:38<00:57,  9.52s/it] 50%|█████     | 5/10 [00:47<00:47,  9.43s/it] 60%|██████    | 6/10 [00:57<00:38,  9.60s/it] 70%|███████   | 7/10 [01:06<00:28,  9.45s/it] 80%|████████  | 8/10 [01:15<00:18,  9.32s/it] 90%|█████████ | 9/10 [01:24<00:09,  9.19s/it]100%|██████████| 10/10 [01:33<00:00,  9.14s/it]100%|██████████| 10/10 [01:33<00:00,  9.33s/it]
iteration:  5
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 69.39it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:08<01:20,  8.95s/it] 20%|██        | 2/10 [00:18<01:12,  9.01s/it] 30%|███       | 3/10 [00:27<01:04,  9.15s/it] 40%|████      | 4/10 [00:37<00:56,  9.38s/it] 50%|█████     | 5/10 [00:46<00:46,  9.25s/it] 60%|██████    | 6/10 [00:55<00:36,  9.19s/it] 70%|███████   | 7/10 [01:04<00:27,  9.16s/it] 80%|████████  | 8/10 [01:13<00:18,  9.18s/it] 90%|█████████ | 9/10 [01:22<00:09,  9.11s/it]100%|██████████| 10/10 [01:31<00:00,  9.08s/it]100%|██████████| 10/10 [01:31<00:00,  9.14s/it]
iteration:  6
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.43it/s]
Number of steps:  64
[ 64 ]Privacy loss is 11.17647147989064
The final epsilon delta values after the training is over:  (11.17647147989064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5517241379310345, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:24,  9.36s/it] 20%|██        | 2/10 [00:18<01:14,  9.28s/it] 30%|███       | 3/10 [00:27<01:03,  9.13s/it] 40%|████      | 4/10 [00:36<00:54,  9.08s/it] 50%|█████     | 5/10 [00:45<00:45,  9.10s/it] 60%|██████    | 6/10 [00:54<00:36,  9.08s/it] 70%|███████   | 7/10 [01:03<00:27,  9.04s/it] 80%|████████  | 8/10 [01:12<00:18,  9.01s/it] 90%|█████████ | 9/10 [01:22<00:09,  9.32s/it]100%|██████████| 10/10 [01:31<00:00,  9.23s/it]100%|██████████| 10/10 [01:31<00:00,  9.16s/it]
iteration:  7
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.25it/s]
Number of steps:  64
[ 64 ]Privacy loss is 11.17647147989064
The final epsilon delta values after the training is over:  (11.17647147989064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5517241379310345, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:08<01:20,  8.99s/it] 20%|██        | 2/10 [00:18<01:12,  9.06s/it] 30%|███       | 3/10 [00:27<01:03,  9.03s/it] 40%|████      | 4/10 [00:35<00:53,  8.98s/it] 50%|█████     | 5/10 [00:44<00:44,  8.95s/it] 60%|██████    | 6/10 [00:53<00:35,  8.98s/it] 70%|███████   | 7/10 [01:02<00:27,  9.01s/it] 80%|████████  | 8/10 [01:12<00:18,  9.04s/it] 90%|█████████ | 9/10 [01:21<00:09,  9.01s/it]100%|██████████| 10/10 [01:30<00:00,  9.01s/it]100%|██████████| 10/10 [01:30<00:00,  9.01s/it]
iteration:  8
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 46.40it/s]
Number of steps:  64
[ 64 ]Privacy loss is 11.17647147989064
The final epsilon delta values after the training is over:  (11.17647147989064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5517241379310345, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:21,  9.09s/it] 20%|██        | 2/10 [00:18<01:13,  9.18s/it] 30%|███       | 3/10 [00:27<01:04,  9.22s/it] 40%|████      | 4/10 [00:36<00:54,  9.15s/it] 50%|█████     | 5/10 [00:45<00:45,  9.10s/it] 60%|██████    | 6/10 [00:54<00:36,  9.14s/it] 70%|███████   | 7/10 [01:03<00:27,  9.09s/it] 80%|████████  | 8/10 [01:13<00:18,  9.12s/it] 90%|█████████ | 9/10 [01:22<00:09,  9.13s/it]100%|██████████| 10/10 [01:31<00:00,  9.11s/it]100%|██████████| 10/10 [01:31<00:00,  9.13s/it]
iteration:  9
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.57it/s]
Number of steps:  64
[ 64 ]Privacy loss is 11.17647147989064
The final epsilon delta values after the training is over:  (11.17647147989064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5517241379310345, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:21,  9.08s/it] 20%|██        | 2/10 [00:18<01:14,  9.27s/it] 30%|███       | 3/10 [00:27<01:03,  9.14s/it] 40%|████      | 4/10 [00:36<00:54,  9.10s/it] 50%|█████     | 5/10 [00:45<00:45,  9.09s/it] 60%|██████    | 6/10 [00:54<00:36,  9.10s/it] 70%|███████   | 7/10 [01:03<00:27,  9.10s/it] 80%|████████  | 8/10 [01:12<00:18,  9.12s/it] 90%|█████████ | 9/10 [01:22<00:09,  9.17s/it]100%|██████████| 10/10 [01:31<00:00,  9.19s/it]100%|██████████| 10/10 [01:31<00:00,  9.15s/it]
iteration:  10
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.22it/s]
Number of steps:  64
[ 64 ]Privacy loss is 11.17647147989064
The final epsilon delta values after the training is over:  (11.17647147989064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5517241379310345, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:22,  9.20s/it] 20%|██        | 2/10 [00:18<01:13,  9.18s/it] 30%|███       | 3/10 [00:27<01:05,  9.35s/it] 40%|████      | 4/10 [00:37<00:56,  9.39s/it] 50%|█████     | 5/10 [00:46<00:46,  9.38s/it] 60%|██████    | 6/10 [00:55<00:37,  9.31s/it] 70%|███████   | 7/10 [01:05<00:27,  9.26s/it] 80%|████████  | 8/10 [01:14<00:18,  9.25s/it] 90%|█████████ | 9/10 [01:23<00:09,  9.26s/it]100%|██████████| 10/10 [01:33<00:00,  9.37s/it]100%|██████████| 10/10 [01:33<00:00,  9.32s/it]
iteration:  11
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.24it/s]
Number of steps:  64
[ 64 ]Privacy loss is 7.369218646919686
The final epsilon delta values after the training is over:  (7.369218646919686, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.603448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:23,  9.32s/it] 20%|██        | 2/10 [00:18<01:14,  9.26s/it] 30%|███       | 3/10 [00:28<01:05,  9.42s/it] 40%|████      | 4/10 [00:37<00:56,  9.36s/it] 50%|█████     | 5/10 [00:46<00:46,  9.34s/it] 60%|██████    | 6/10 [00:56<00:37,  9.35s/it] 70%|███████   | 7/10 [01:05<00:27,  9.33s/it] 80%|████████  | 8/10 [01:14<00:18,  9.33s/it] 90%|█████████ | 9/10 [01:24<00:09,  9.42s/it]100%|██████████| 10/10 [01:33<00:00,  9.41s/it]100%|██████████| 10/10 [01:33<00:00,  9.37s/it]
iteration:  12
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.23it/s]
Number of steps:  64
[ 64 ]Privacy loss is 7.369218646919686
The final epsilon delta values after the training is over:  (7.369218646919686, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.603448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:26,  9.61s/it] 20%|██        | 2/10 [00:19<01:15,  9.48s/it] 30%|███       | 3/10 [00:28<01:05,  9.42s/it] 40%|████      | 4/10 [00:37<00:56,  9.43s/it] 50%|█████     | 5/10 [00:47<00:47,  9.43s/it] 60%|██████    | 6/10 [00:56<00:37,  9.45s/it] 70%|███████   | 7/10 [01:06<00:28,  9.48s/it] 80%|████████  | 8/10 [01:15<00:18,  9.46s/it] 90%|█████████ | 9/10 [01:25<00:09,  9.50s/it]100%|██████████| 10/10 [01:34<00:00,  9.47s/it]100%|██████████| 10/10 [01:34<00:00,  9.47s/it]
iteration:  13
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.11it/s]
Number of steps:  64
[ 64 ]Privacy loss is 7.369218646919686
The final epsilon delta values after the training is over:  (7.369218646919686, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.603448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:25,  9.48s/it] 20%|██        | 2/10 [00:18<01:15,  9.48s/it] 30%|███       | 3/10 [00:28<01:06,  9.47s/it] 40%|████      | 4/10 [00:37<00:57,  9.50s/it] 50%|█████     | 5/10 [00:47<00:47,  9.51s/it] 60%|██████    | 6/10 [00:56<00:38,  9.50s/it] 70%|███████   | 7/10 [01:06<00:28,  9.49s/it] 80%|████████  | 8/10 [01:15<00:18,  9.49s/it] 90%|█████████ | 9/10 [01:25<00:09,  9.49s/it]100%|██████████| 10/10 [01:34<00:00,  9.47s/it]100%|██████████| 10/10 [01:34<00:00,  9.49s/it]
iteration:  14
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.79it/s]
Number of steps:  64
[ 64 ]Privacy loss is 7.369218646919686
The final epsilon delta values after the training is over:  (7.369218646919686, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.603448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:25,  9.52s/it] 20%|██        | 2/10 [00:18<01:15,  9.46s/it] 30%|███       | 3/10 [00:28<01:06,  9.46s/it] 40%|████      | 4/10 [00:37<00:56,  9.46s/it] 50%|█████     | 5/10 [00:47<00:47,  9.48s/it] 60%|██████    | 6/10 [00:56<00:38,  9.51s/it] 70%|███████   | 7/10 [01:06<00:28,  9.52s/it] 80%|████████  | 8/10 [01:15<00:19,  9.51s/it] 90%|█████████ | 9/10 [01:25<00:09,  9.51s/it]100%|██████████| 10/10 [01:35<00:00,  9.57s/it]100%|██████████| 10/10 [01:35<00:00,  9.52s/it]
iteration:  15
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.73it/s]
Number of steps:  64
[ 64 ]Privacy loss is 7.369218646919686
The final epsilon delta values after the training is over:  (7.369218646919686, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.603448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:27,  9.73s/it] 20%|██        | 2/10 [00:19<01:17,  9.72s/it] 30%|███       | 3/10 [00:29<01:07,  9.68s/it] 40%|████      | 4/10 [00:38<00:57,  9.61s/it] 50%|█████     | 5/10 [00:48<00:47,  9.57s/it] 60%|██████    | 6/10 [00:57<00:38,  9.61s/it] 70%|███████   | 7/10 [01:07<00:29,  9.76s/it] 80%|████████  | 8/10 [01:17<00:19,  9.68s/it] 90%|█████████ | 9/10 [01:26<00:09,  9.63s/it]100%|██████████| 10/10 [01:36<00:00,  9.63s/it]100%|██████████| 10/10 [01:36<00:00,  9.65s/it]
iteration:  16
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.88it/s]
Number of steps:  64
[ 64 ]Privacy loss is 6.494281640688786
The final epsilon delta values after the training is over:  (6.494281640688786, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.6551724137931034, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:29,  9.96s/it] 20%|██        | 2/10 [00:19<01:18,  9.76s/it] 30%|███       | 3/10 [00:29<01:07,  9.63s/it] 40%|████      | 4/10 [00:38<00:57,  9.57s/it] 50%|█████     | 5/10 [00:48<00:47,  9.53s/it] 60%|██████    | 6/10 [00:57<00:38,  9.55s/it] 70%|███████   | 7/10 [01:07<00:28,  9.54s/it] 80%|████████  | 8/10 [01:16<00:19,  9.52s/it] 90%|█████████ | 9/10 [01:26<00:09,  9.55s/it]100%|██████████| 10/10 [01:35<00:00,  9.54s/it]100%|██████████| 10/10 [01:35<00:00,  9.57s/it]
iteration:  17
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 48.48it/s]
Number of steps:  64
[ 64 ]Privacy loss is 6.494281640688786
The final epsilon delta values after the training is over:  (6.494281640688786, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.6551724137931034, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:29,  9.90s/it] 20%|██        | 2/10 [00:19<01:18,  9.83s/it] 30%|███       | 3/10 [00:29<01:08,  9.78s/it] 40%|████      | 4/10 [00:38<00:58,  9.69s/it] 50%|█████     | 5/10 [00:48<00:48,  9.72s/it] 60%|██████    | 6/10 [00:58<00:38,  9.68s/it] 70%|███████   | 7/10 [01:08<00:29,  9.73s/it] 80%|████████  | 8/10 [01:17<00:19,  9.68s/it] 90%|█████████ | 9/10 [01:27<00:09,  9.68s/it]100%|██████████| 10/10 [01:37<00:00,  9.68s/it]100%|██████████| 10/10 [01:37<00:00,  9.71s/it]
iteration:  18
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.40it/s]
Number of steps:  64
[ 64 ]Privacy loss is 6.494281640688786
The final epsilon delta values after the training is over:  (6.494281640688786, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.6551724137931034, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:26,  9.65s/it] 20%|██        | 2/10 [00:19<01:17,  9.74s/it] 30%|███       | 3/10 [00:29<01:07,  9.70s/it] 40%|████      | 4/10 [00:38<00:58,  9.67s/it] 50%|█████     | 5/10 [00:48<00:48,  9.73s/it] 60%|██████    | 6/10 [00:58<00:38,  9.67s/it] 70%|███████   | 7/10 [01:07<00:28,  9.65s/it] 80%|████████  | 8/10 [01:17<00:19,  9.70s/it] 90%|█████████ | 9/10 [01:27<00:09,  9.78s/it]100%|██████████| 10/10 [01:37<00:00,  9.83s/it]100%|██████████| 10/10 [01:37<00:00,  9.74s/it]
iteration:  19
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.17it/s]
Number of steps:  64
[ 64 ]Privacy loss is 6.494281640688786
The final epsilon delta values after the training is over:  (6.494281640688786, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.6551724137931034, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:26,  9.63s/it] 20%|██        | 2/10 [00:19<01:17,  9.69s/it] 30%|███       | 3/10 [00:29<01:07,  9.68s/it] 40%|████      | 4/10 [00:38<00:58,  9.69s/it] 50%|█████     | 5/10 [00:48<00:48,  9.67s/it] 60%|██████    | 6/10 [00:58<00:38,  9.69s/it] 70%|███████   | 7/10 [01:07<00:29,  9.70s/it] 80%|████████  | 8/10 [01:17<00:19,  9.69s/it] 90%|█████████ | 9/10 [01:27<00:09,  9.68s/it]100%|██████████| 10/10 [01:36<00:00,  9.67s/it]100%|██████████| 10/10 [01:36<00:00,  9.68s/it]
iteration:  20
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 44.89it/s]
Number of steps:  64
[ 64 ]Privacy loss is 6.494281640688786
The final epsilon delta values after the training is over:  (6.494281640688786, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.6551724137931034, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:29,  9.94s/it] 20%|██        | 2/10 [00:19<01:18,  9.82s/it] 30%|███       | 3/10 [00:29<01:08,  9.74s/it] 40%|████      | 4/10 [00:38<00:58,  9.70s/it] 50%|█████     | 5/10 [00:48<00:48,  9.75s/it] 60%|██████    | 6/10 [00:58<00:38,  9.75s/it] 70%|███████   | 7/10 [01:08<00:29,  9.76s/it] 80%|████████  | 8/10 [01:18<00:19,  9.81s/it] 90%|█████████ | 9/10 [01:27<00:09,  9.77s/it]100%|██████████| 10/10 [01:37<00:00,  9.74s/it]100%|██████████| 10/10 [01:37<00:00,  9.76s/it]
iteration:  21
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.44it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.950910242291995
The final epsilon delta values after the training is over:  (4.950910242291995, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7068965517241379, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:28,  9.87s/it] 20%|██        | 2/10 [00:19<01:19,  9.90s/it] 30%|███       | 3/10 [00:30<01:12, 10.39s/it] 40%|████      | 4/10 [00:40<01:01, 10.21s/it] 50%|█████     | 5/10 [00:50<00:50, 10.05s/it] 60%|██████    | 6/10 [01:00<00:39,  9.93s/it] 70%|███████   | 7/10 [01:09<00:29,  9.85s/it] 80%|████████  | 8/10 [01:19<00:19,  9.82s/it] 90%|█████████ | 9/10 [01:29<00:09,  9.83s/it]100%|██████████| 10/10 [01:39<00:00,  9.81s/it]100%|██████████| 10/10 [01:39<00:00,  9.92s/it]
iteration:  22
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.59it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.950910242291995
The final epsilon delta values after the training is over:  (4.950910242291995, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7068965517241379, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:28,  9.86s/it] 20%|██        | 2/10 [00:20<01:20, 10.04s/it] 30%|███       | 3/10 [00:30<01:10, 10.07s/it] 40%|████      | 4/10 [00:39<00:59,  9.97s/it] 50%|█████     | 5/10 [00:50<00:50, 10.02s/it] 60%|██████    | 6/10 [00:59<00:39,  9.94s/it] 70%|███████   | 7/10 [01:09<00:29,  9.94s/it] 80%|████████  | 8/10 [01:19<00:19,  9.90s/it] 90%|█████████ | 9/10 [01:29<00:09,  9.94s/it]100%|██████████| 10/10 [01:39<00:00,  9.89s/it]100%|██████████| 10/10 [01:39<00:00,  9.94s/it]
iteration:  23
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.62it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.950910242291995
The final epsilon delta values after the training is over:  (4.950910242291995, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7068965517241379, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:27,  9.70s/it] 20%|██        | 2/10 [00:19<01:17,  9.69s/it] 30%|███       | 3/10 [00:29<01:07,  9.69s/it] 40%|████      | 4/10 [00:39<00:58,  9.80s/it] 50%|█████     | 5/10 [00:49<00:49,  9.92s/it] 60%|██████    | 6/10 [00:59<00:39,  9.92s/it] 70%|███████   | 7/10 [01:08<00:29,  9.90s/it] 80%|████████  | 8/10 [01:18<00:19,  9.86s/it] 90%|█████████ | 9/10 [01:28<00:09,  9.83s/it]100%|██████████| 10/10 [01:38<00:00,  9.80s/it]100%|██████████| 10/10 [01:38<00:00,  9.82s/it]
iteration:  24
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.67it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.950910242291995
The final epsilon delta values after the training is over:  (4.950910242291995, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7068965517241379, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:28,  9.84s/it] 20%|██        | 2/10 [00:19<01:20, 10.01s/it] 30%|███       | 3/10 [00:30<01:10, 10.05s/it] 40%|████      | 4/10 [00:39<00:59,  9.93s/it] 50%|█████     | 5/10 [00:49<00:49,  9.89s/it] 60%|██████    | 6/10 [00:59<00:39,  9.83s/it] 70%|███████   | 7/10 [01:09<00:29,  9.86s/it] 80%|████████  | 8/10 [01:19<00:19,  9.82s/it] 90%|█████████ | 9/10 [01:28<00:09,  9.79s/it]100%|██████████| 10/10 [01:38<00:00,  9.78s/it]100%|██████████| 10/10 [01:38<00:00,  9.85s/it]
iteration:  25
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.13it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.950910242291995
The final epsilon delta values after the training is over:  (4.950910242291995, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7068965517241379, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:27,  9.72s/it] 20%|██        | 2/10 [00:19<01:18,  9.83s/it] 30%|███       | 3/10 [00:29<01:08,  9.81s/it] 40%|████      | 4/10 [00:39<00:58,  9.81s/it] 50%|█████     | 5/10 [00:49<00:49,  9.87s/it] 60%|██████    | 6/10 [00:59<00:39,  9.88s/it] 70%|███████   | 7/10 [01:09<00:29,  9.89s/it] 80%|████████  | 8/10 [01:18<00:19,  9.83s/it] 90%|█████████ | 9/10 [01:28<00:09,  9.79s/it]100%|██████████| 10/10 [01:38<00:00,  9.78s/it]100%|██████████| 10/10 [01:38<00:00,  9.82s/it]
iteration:  26
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.52it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.390909639865212
The final epsilon delta values after the training is over:  (4.390909639865212, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7586206896551724, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:29,  9.90s/it] 20%|██        | 2/10 [00:19<01:19,  9.91s/it] 30%|███       | 3/10 [00:29<01:09,  9.94s/it] 40%|████      | 4/10 [00:39<00:59,  9.93s/it] 50%|█████     | 5/10 [00:49<00:49,  9.90s/it] 60%|██████    | 6/10 [00:59<00:39,  9.83s/it] 70%|███████   | 7/10 [01:09<00:29,  9.82s/it] 80%|████████  | 8/10 [01:19<00:19,  9.88s/it] 90%|█████████ | 9/10 [01:28<00:09,  9.89s/it]100%|██████████| 10/10 [01:38<00:00,  9.86s/it]100%|██████████| 10/10 [01:38<00:00,  9.88s/it]
iteration:  27
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.45it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.390909639865212
The final epsilon delta values after the training is over:  (4.390909639865212, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7586206896551724, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:30, 10.03s/it] 20%|██        | 2/10 [00:20<01:20, 10.12s/it] 30%|███       | 3/10 [00:30<01:12, 10.30s/it] 40%|████      | 4/10 [00:40<01:00, 10.17s/it] 50%|█████     | 5/10 [00:50<00:50, 10.14s/it] 60%|██████    | 6/10 [01:00<00:40, 10.10s/it] 70%|███████   | 7/10 [01:10<00:30, 10.04s/it] 80%|████████  | 8/10 [01:20<00:20, 10.10s/it] 90%|█████████ | 9/10 [01:30<00:10, 10.01s/it]100%|██████████| 10/10 [01:40<00:00,  9.96s/it]100%|██████████| 10/10 [01:40<00:00, 10.06s/it]
iteration:  28
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.45it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.390909639865212
The final epsilon delta values after the training is over:  (4.390909639865212, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7586206896551724, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:29,  9.92s/it] 20%|██        | 2/10 [00:19<01:19,  9.93s/it] 30%|███       | 3/10 [00:29<01:09,  9.88s/it] 40%|████      | 4/10 [00:39<00:59,  9.90s/it] 50%|█████     | 5/10 [00:49<00:49,  9.89s/it] 60%|██████    | 6/10 [00:59<00:39,  9.87s/it] 70%|███████   | 7/10 [01:09<00:30, 10.04s/it] 80%|████████  | 8/10 [01:19<00:19,  9.98s/it] 90%|█████████ | 9/10 [01:29<00:10, 10.00s/it]100%|██████████| 10/10 [01:39<00:00,  9.97s/it]100%|██████████| 10/10 [01:39<00:00,  9.95s/it]
iteration:  29
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.78it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.390909639865212
The final epsilon delta values after the training is over:  (4.390909639865212, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7586206896551724, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:31, 10.16s/it] 20%|██        | 2/10 [00:19<01:19,  9.95s/it] 30%|███       | 3/10 [00:29<01:09,  9.88s/it] 40%|████      | 4/10 [00:39<00:59,  9.84s/it] 50%|█████     | 5/10 [00:49<00:49,  9.82s/it] 60%|██████    | 6/10 [00:59<00:39,  9.85s/it] 70%|███████   | 7/10 [01:09<00:29,  9.89s/it] 80%|████████  | 8/10 [01:19<00:19,  9.92s/it] 90%|█████████ | 9/10 [01:29<00:09,  9.92s/it]100%|██████████| 10/10 [01:39<00:00,  9.92s/it]100%|██████████| 10/10 [01:39<00:00,  9.90s/it]
iteration:  30
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.11it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.390909639865212
The final epsilon delta values after the training is over:  (4.390909639865212, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7586206896551724, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:30, 10.04s/it] 20%|██        | 2/10 [00:20<01:20, 10.01s/it] 30%|███       | 3/10 [00:29<01:09,  9.91s/it] 40%|████      | 4/10 [00:39<00:59,  9.88s/it] 50%|█████     | 5/10 [00:49<00:49,  9.86s/it] 60%|██████    | 6/10 [00:59<00:39,  9.96s/it] 70%|███████   | 7/10 [01:09<00:29,  9.92s/it] 80%|████████  | 8/10 [01:19<00:19,  9.93s/it] 90%|█████████ | 9/10 [01:29<00:09,  9.90s/it]100%|██████████| 10/10 [01:39<00:00,  9.88s/it]100%|██████████| 10/10 [01:39<00:00,  9.91s/it]
iteration:  31
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.63it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.5508920214596684
The final epsilon delta values after the training is over:  (3.5508920214596684, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8103448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:30, 10.02s/it] 20%|██        | 2/10 [00:19<01:19,  9.96s/it] 30%|███       | 3/10 [00:29<01:09,  9.92s/it] 40%|████      | 4/10 [00:40<01:00, 10.12s/it] 50%|█████     | 5/10 [00:50<00:50, 10.08s/it] 60%|██████    | 6/10 [01:00<00:40, 10.05s/it] 70%|███████   | 7/10 [01:10<00:30, 10.00s/it] 80%|████████  | 8/10 [01:19<00:19,  9.95s/it] 90%|█████████ | 9/10 [01:30<00:10, 10.03s/it]100%|██████████| 10/10 [01:40<00:00, 10.02s/it]100%|██████████| 10/10 [01:40<00:00, 10.02s/it]
iteration:  32
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 48.18it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.5508920214596684
The final epsilon delta values after the training is over:  (3.5508920214596684, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8103448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:30, 10.09s/it] 20%|██        | 2/10 [00:20<01:20, 10.01s/it] 30%|███       | 3/10 [00:30<01:10, 10.03s/it] 40%|████      | 4/10 [00:39<00:59,  9.95s/it] 50%|█████     | 5/10 [00:49<00:49,  9.98s/it] 60%|██████    | 6/10 [00:59<00:39, 10.00s/it] 70%|███████   | 7/10 [01:09<00:29,  9.97s/it] 80%|████████  | 8/10 [01:19<00:19,  9.94s/it] 90%|█████████ | 9/10 [01:29<00:09,  9.95s/it]100%|██████████| 10/10 [01:39<00:00,  9.99s/it]100%|██████████| 10/10 [01:39<00:00,  9.98s/it]
iteration:  33
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.97it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.5508920214596684
The final epsilon delta values after the training is over:  (3.5508920214596684, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8103448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:29,  9.90s/it] 20%|██        | 2/10 [00:19<01:19,  9.89s/it] 30%|███       | 3/10 [00:30<01:10, 10.04s/it] 40%|████      | 4/10 [00:40<01:00, 10.03s/it] 50%|█████     | 5/10 [00:49<00:49,  9.99s/it] 60%|██████    | 6/10 [00:59<00:39,  9.94s/it] 70%|███████   | 7/10 [01:09<00:29,  9.99s/it] 80%|████████  | 8/10 [01:19<00:19,  9.98s/it] 90%|█████████ | 9/10 [01:30<00:10, 10.05s/it]100%|██████████| 10/10 [01:40<00:00, 10.02s/it]100%|██████████| 10/10 [01:40<00:00, 10.00s/it]
iteration:  34
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.77it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.5508920214596684
The final epsilon delta values after the training is over:  (3.5508920214596684, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8103448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:30, 10.05s/it] 20%|██        | 2/10 [00:19<01:19,  9.96s/it] 30%|███       | 3/10 [00:29<01:09,  9.97s/it] 40%|████      | 4/10 [00:39<00:59,  9.95s/it] 50%|█████     | 5/10 [00:49<00:49,  9.96s/it] 60%|██████    | 6/10 [00:59<00:39,  9.97s/it] 70%|███████   | 7/10 [01:09<00:30, 10.01s/it] 80%|████████  | 8/10 [01:19<00:20, 10.01s/it] 90%|█████████ | 9/10 [01:30<00:10, 10.06s/it]100%|██████████| 10/10 [01:40<00:00, 10.03s/it]100%|██████████| 10/10 [01:40<00:00, 10.01s/it]
iteration:  35
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.79it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.5508920214596684
The final epsilon delta values after the training is over:  (3.5508920214596684, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8103448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:31, 10.13s/it] 20%|██        | 2/10 [00:20<01:20, 10.01s/it] 30%|███       | 3/10 [00:30<01:10, 10.02s/it] 40%|████      | 4/10 [00:39<00:59,  9.97s/it] 50%|█████     | 5/10 [00:49<00:49,  9.94s/it] 60%|██████    | 6/10 [00:59<00:39,  9.92s/it] 70%|███████   | 7/10 [01:09<00:29,  9.93s/it] 80%|████████  | 8/10 [01:19<00:19,  9.92s/it] 90%|█████████ | 9/10 [01:29<00:09,  9.98s/it]100%|██████████| 10/10 [01:39<00:00,  9.96s/it]100%|██████████| 10/10 [01:39<00:00,  9.96s/it]
iteration:  36
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.67it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.136072318576378
The final epsilon delta values after the training is over:  (3.136072318576378, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8620689655172413, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:30, 10.09s/it] 20%|██        | 2/10 [00:20<01:21, 10.15s/it] 30%|███       | 3/10 [00:30<01:10, 10.05s/it] 40%|████      | 4/10 [00:40<01:00, 10.06s/it] 50%|█████     | 5/10 [00:50<00:50, 10.02s/it] 60%|██████    | 6/10 [01:00<00:39, 10.00s/it] 70%|███████   | 7/10 [01:10<00:30, 10.00s/it] 80%|████████  | 8/10 [01:20<00:19,  9.99s/it] 90%|█████████ | 9/10 [01:30<00:10, 10.02s/it]100%|██████████| 10/10 [01:40<00:00, 10.02s/it]100%|██████████| 10/10 [01:40<00:00, 10.03s/it]
iteration:  37
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.40it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.136072318576378
The final epsilon delta values after the training is over:  (3.136072318576378, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8620689655172413, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:34, 10.54s/it] 20%|██        | 2/10 [00:20<01:21, 10.22s/it] 30%|███       | 3/10 [00:30<01:10, 10.10s/it] 40%|████      | 4/10 [00:40<01:00, 10.04s/it] 50%|█████     | 5/10 [00:50<00:50, 10.01s/it] 60%|██████    | 6/10 [01:00<00:40, 10.11s/it] 70%|███████   | 7/10 [01:10<00:30, 10.08s/it] 80%|████████  | 8/10 [01:20<00:20, 10.11s/it] 90%|█████████ | 9/10 [01:30<00:10, 10.09s/it]100%|██████████| 10/10 [01:40<00:00, 10.07s/it]100%|██████████| 10/10 [01:40<00:00, 10.10s/it]
iteration:  38
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.96it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.136072318576378
The final epsilon delta values after the training is over:  (3.136072318576378, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8620689655172413, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:33, 10.35s/it] 20%|██        | 2/10 [00:20<01:21, 10.13s/it] 30%|███       | 3/10 [00:30<01:10, 10.05s/it] 40%|████      | 4/10 [00:40<01:00, 10.14s/it] 50%|█████     | 5/10 [00:50<00:50, 10.11s/it] 60%|██████    | 6/10 [01:00<00:40, 10.05s/it] 70%|███████   | 7/10 [01:10<00:30, 10.06s/it] 80%|████████  | 8/10 [01:20<00:20, 10.09s/it] 90%|█████████ | 9/10 [01:30<00:10, 10.08s/it]100%|██████████| 10/10 [01:40<00:00, 10.08s/it]100%|██████████| 10/10 [01:40<00:00, 10.09s/it]
iteration:  39
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 44.91it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.136072318576378
The final epsilon delta values after the training is over:  (3.136072318576378, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8620689655172413, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:30, 10.05s/it] 20%|██        | 2/10 [00:20<01:20, 10.07s/it] 30%|███       | 3/10 [00:30<01:10, 10.08s/it] 40%|████      | 4/10 [00:40<01:00, 10.06s/it] 50%|█████     | 5/10 [00:50<00:50, 10.12s/it] 60%|██████    | 6/10 [01:00<00:40, 10.12s/it] 70%|███████   | 7/10 [01:10<00:30, 10.10s/it] 80%|████████  | 8/10 [01:20<00:20, 10.07s/it] 90%|█████████ | 9/10 [01:30<00:10, 10.10s/it]100%|██████████| 10/10 [01:40<00:00, 10.08s/it]100%|██████████| 10/10 [01:40<00:00, 10.09s/it]
iteration:  40
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.55it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.136072318576378
The final epsilon delta values after the training is over:  (3.136072318576378, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8620689655172413, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:30, 10.07s/it] 20%|██        | 2/10 [00:20<01:20, 10.06s/it] 30%|███       | 3/10 [00:30<01:10, 10.02s/it] 40%|████      | 4/10 [00:40<01:00, 10.03s/it] 50%|█████     | 5/10 [00:50<00:50, 10.05s/it] 60%|██████    | 6/10 [01:00<00:40, 10.03s/it] 70%|███████   | 7/10 [01:10<00:30, 10.08s/it] 80%|████████  | 8/10 [01:20<00:20, 10.05s/it] 90%|█████████ | 9/10 [01:30<00:10, 10.04s/it]100%|██████████| 10/10 [01:40<00:00, 10.02s/it]100%|██████████| 10/10 [01:40<00:00, 10.04s/it]
iteration:  41
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.48it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.7525821481728774
The final epsilon delta values after the training is over:  (2.7525821481728774, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9137931034482758, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:34, 10.49s/it] 20%|██        | 2/10 [00:20<01:22, 10.25s/it] 30%|███       | 3/10 [00:30<01:11, 10.25s/it] 40%|████      | 4/10 [00:40<01:00, 10.16s/it] 50%|█████     | 5/10 [00:50<00:50, 10.11s/it] 60%|██████    | 6/10 [01:01<00:40, 10.16s/it] 70%|███████   | 7/10 [01:11<00:30, 10.12s/it] 80%|████████  | 8/10 [01:21<00:20, 10.08s/it] 90%|█████████ | 9/10 [01:31<00:10, 10.23s/it]100%|██████████| 10/10 [01:41<00:00, 10.17s/it]100%|██████████| 10/10 [01:41<00:00, 10.18s/it]
iteration:  42
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.40it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.7525821481728774
The final epsilon delta values after the training is over:  (2.7525821481728774, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9137931034482758, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:31, 10.14s/it] 20%|██        | 2/10 [00:20<01:20, 10.05s/it] 30%|███       | 3/10 [00:30<01:10, 10.03s/it] 40%|████      | 4/10 [00:40<01:00, 10.01s/it] 50%|█████     | 5/10 [00:50<00:50, 10.07s/it] 60%|██████    | 6/10 [01:00<00:40, 10.08s/it] 70%|███████   | 7/10 [01:10<00:30, 10.14s/it] 80%|████████  | 8/10 [01:20<00:20, 10.16s/it] 90%|█████████ | 9/10 [01:31<00:10, 10.18s/it]100%|██████████| 10/10 [01:41<00:00, 10.14s/it]100%|██████████| 10/10 [01:41<00:00, 10.11s/it]
iteration:  43
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 43.78it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.7525821481728774
The final epsilon delta values after the training is over:  (2.7525821481728774, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9137931034482758, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:32, 10.24s/it] 20%|██        | 2/10 [00:20<01:22, 10.26s/it] 30%|███       | 3/10 [00:30<01:12, 10.35s/it] 40%|████      | 4/10 [00:41<01:01, 10.28s/it] 50%|█████     | 5/10 [00:51<00:51, 10.23s/it] 60%|██████    | 6/10 [01:01<00:40, 10.19s/it] 70%|███████   | 7/10 [01:11<00:30, 10.19s/it] 80%|████████  | 8/10 [01:22<00:20, 10.42s/it] 90%|█████████ | 9/10 [01:33<00:10, 10.59s/it]100%|██████████| 10/10 [01:43<00:00, 10.45s/it]100%|██████████| 10/10 [01:43<00:00, 10.36s/it]
iteration:  44
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.64it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.7525821481728774
The final epsilon delta values after the training is over:  (2.7525821481728774, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9137931034482758, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:34, 10.55s/it] 20%|██        | 2/10 [00:20<01:22, 10.35s/it] 30%|███       | 3/10 [00:30<01:11, 10.24s/it] 40%|████      | 4/10 [00:40<01:01, 10.17s/it] 50%|█████     | 5/10 [00:50<00:50, 10.13s/it] 60%|██████    | 6/10 [01:01<00:41, 10.26s/it] 70%|███████   | 7/10 [01:11<00:30, 10.22s/it] 80%|████████  | 8/10 [01:21<00:20, 10.19s/it] 90%|█████████ | 9/10 [01:31<00:10, 10.18s/it]100%|██████████| 10/10 [01:42<00:00, 10.18s/it]100%|██████████| 10/10 [01:42<00:00, 10.21s/it]
iteration:  45
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.92it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.7525821481728774
The final epsilon delta values after the training is over:  (2.7525821481728774, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9137931034482758, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:33, 10.35s/it] 20%|██        | 2/10 [00:20<01:21, 10.21s/it] 30%|███       | 3/10 [00:30<01:11, 10.18s/it] 40%|████      | 4/10 [00:40<01:01, 10.22s/it] 50%|█████     | 5/10 [00:51<00:51, 10.29s/it] 60%|██████    | 6/10 [01:02<00:41, 10.45s/it] 70%|███████   | 7/10 [01:12<00:31, 10.46s/it] 80%|████████  | 8/10 [01:22<00:20, 10.41s/it] 90%|█████████ | 9/10 [01:33<00:10, 10.45s/it]100%|██████████| 10/10 [01:43<00:00, 10.39s/it]100%|██████████| 10/10 [01:43<00:00, 10.37s/it]
iteration:  46
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 43.52it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.3962381625999214
The final epsilon delta values after the training is over:  (2.3962381625999214, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9655172413793103, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:33, 10.43s/it] 20%|██        | 2/10 [00:20<01:22, 10.37s/it] 30%|███       | 3/10 [00:31<01:12, 10.33s/it] 40%|████      | 4/10 [00:41<01:01, 10.33s/it] 50%|█████     | 5/10 [00:51<00:52, 10.41s/it] 60%|██████    | 6/10 [01:02<00:41, 10.35s/it] 70%|███████   | 7/10 [01:12<00:30, 10.28s/it] 80%|████████  | 8/10 [01:22<00:20, 10.23s/it] 90%|█████████ | 9/10 [01:32<00:10, 10.24s/it]100%|██████████| 10/10 [01:42<00:00, 10.24s/it]100%|██████████| 10/10 [01:42<00:00, 10.29s/it]
iteration:  47
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.93it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.3962381625999214
The final epsilon delta values after the training is over:  (2.3962381625999214, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9655172413793103, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:36, 10.74s/it] 20%|██        | 2/10 [00:20<01:23, 10.39s/it] 30%|███       | 3/10 [00:31<01:11, 10.28s/it] 40%|████      | 4/10 [00:41<01:01, 10.22s/it] 50%|█████     | 5/10 [00:51<00:50, 10.20s/it] 60%|██████    | 6/10 [01:01<00:41, 10.28s/it] 70%|███████   | 7/10 [01:12<00:30, 10.28s/it] 80%|████████  | 8/10 [01:22<00:20, 10.25s/it] 90%|█████████ | 9/10 [01:32<00:10, 10.24s/it]100%|██████████| 10/10 [01:42<00:00, 10.21s/it]100%|██████████| 10/10 [01:42<00:00, 10.26s/it]
iteration:  48
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.02it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.3962381625999214
The final epsilon delta values after the training is over:  (2.3962381625999214, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9655172413793103, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:31, 10.21s/it] 20%|██        | 2/10 [00:20<01:21, 10.23s/it] 30%|███       | 3/10 [00:30<01:12, 10.35s/it] 40%|████      | 4/10 [00:41<01:01, 10.29s/it] 50%|█████     | 5/10 [00:51<00:51, 10.24s/it] 60%|██████    | 6/10 [01:01<00:40, 10.23s/it] 70%|███████   | 7/10 [01:11<00:30, 10.24s/it] 80%|████████  | 8/10 [01:22<00:20, 10.27s/it] 90%|█████████ | 9/10 [01:32<00:10, 10.26s/it]100%|██████████| 10/10 [01:42<00:00, 10.25s/it]100%|██████████| 10/10 [01:42<00:00, 10.25s/it]
iteration:  49
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.72it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.3962381625999214
The final epsilon delta values after the training is over:  (2.3962381625999214, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9655172413793103, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:31, 10.20s/it] 20%|██        | 2/10 [00:20<01:21, 10.18s/it] 30%|███       | 3/10 [00:30<01:11, 10.17s/it] 40%|████      | 4/10 [00:40<01:01, 10.21s/it] 50%|█████     | 5/10 [00:51<00:51, 10.24s/it] 60%|██████    | 6/10 [01:01<00:40, 10.21s/it] 70%|███████   | 7/10 [01:11<00:30, 10.22s/it] 80%|████████  | 8/10 [01:21<00:20, 10.22s/it] 90%|█████████ | 9/10 [01:31<00:10, 10.24s/it]100%|██████████| 10/10 [01:42<00:00, 10.21s/it]100%|██████████| 10/10 [01:42<00:00, 10.21s/it]
iteration:  50
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.97it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.3962381625999214
The final epsilon delta values after the training is over:  (2.3962381625999214, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9655172413793103, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:32, 10.28s/it] 20%|██        | 2/10 [00:20<01:23, 10.41s/it] 30%|███       | 3/10 [00:31<01:12, 10.34s/it] 40%|████      | 4/10 [00:41<01:01, 10.31s/it] 50%|█████     | 5/10 [00:51<00:51, 10.30s/it] 60%|██████    | 6/10 [01:01<00:41, 10.26s/it] 70%|███████   | 7/10 [01:12<00:30, 10.25s/it] 80%|████████  | 8/10 [01:22<00:20, 10.29s/it] 90%|█████████ | 9/10 [01:32<00:10, 10.30s/it]100%|██████████| 10/10 [01:42<00:00, 10.29s/it]100%|██████████| 10/10 [01:42<00:00, 10.30s/it]
iteration:  51
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.42it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.143529429767139
The final epsilon delta values after the training is over:  (2.143529429767139, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0172413793103448, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:32, 10.30s/it] 20%|██        | 2/10 [00:20<01:22, 10.35s/it] 30%|███       | 3/10 [00:31<01:12, 10.40s/it] 40%|████      | 4/10 [00:41<01:02, 10.37s/it] 50%|█████     | 5/10 [00:51<00:51, 10.33s/it] 60%|██████    | 6/10 [01:02<00:41, 10.32s/it] 70%|███████   | 7/10 [01:12<00:31, 10.40s/it] 80%|████████  | 8/10 [01:22<00:20, 10.36s/it] 90%|█████████ | 9/10 [01:33<00:10, 10.38s/it]100%|██████████| 10/10 [01:43<00:00, 10.34s/it]100%|██████████| 10/10 [01:43<00:00, 10.35s/it]
iteration:  52
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.75it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.143529429767139
The final epsilon delta values after the training is over:  (2.143529429767139, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0172413793103448, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.88s/it] 20%|██        | 2/10 [00:21<01:25, 10.69s/it] 30%|███       | 3/10 [00:32<01:14, 10.64s/it] 40%|████      | 4/10 [00:42<01:03, 10.53s/it] 50%|█████     | 5/10 [00:52<00:52, 10.47s/it] 60%|██████    | 6/10 [01:03<00:41, 10.41s/it] 70%|███████   | 7/10 [01:13<00:31, 10.38s/it] 80%|████████  | 8/10 [01:23<00:20, 10.40s/it] 90%|█████████ | 9/10 [01:34<00:10, 10.37s/it]100%|██████████| 10/10 [01:44<00:00, 10.33s/it]100%|██████████| 10/10 [01:44<00:00, 10.43s/it]
iteration:  53
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.75it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.143529429767139
The final epsilon delta values after the training is over:  (2.143529429767139, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0172413793103448, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:32, 10.25s/it] 20%|██        | 2/10 [00:20<01:23, 10.45s/it] 30%|███       | 3/10 [00:31<01:12, 10.42s/it] 40%|████      | 4/10 [00:41<01:02, 10.38s/it] 50%|█████     | 5/10 [00:52<00:52, 10.41s/it] 60%|██████    | 6/10 [01:02<00:41, 10.45s/it] 70%|███████   | 7/10 [01:12<00:31, 10.41s/it] 80%|████████  | 8/10 [01:23<00:20, 10.35s/it] 90%|█████████ | 9/10 [01:33<00:10, 10.32s/it]100%|██████████| 10/10 [01:43<00:00, 10.35s/it]100%|██████████| 10/10 [01:43<00:00, 10.38s/it]
iteration:  54
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.56it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.143529429767139
The final epsilon delta values after the training is over:  (2.143529429767139, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0172413793103448, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:35, 10.57s/it] 20%|██        | 2/10 [00:20<01:23, 10.48s/it] 30%|███       | 3/10 [00:31<01:12, 10.43s/it] 40%|████      | 4/10 [00:41<01:02, 10.36s/it] 50%|█████     | 5/10 [00:51<00:51, 10.31s/it] 60%|██████    | 6/10 [01:02<00:41, 10.29s/it] 70%|███████   | 7/10 [01:12<00:30, 10.31s/it] 80%|████████  | 8/10 [01:22<00:20, 10.39s/it] 90%|█████████ | 9/10 [01:33<00:10, 10.36s/it]100%|██████████| 10/10 [01:43<00:00, 10.37s/it]100%|██████████| 10/10 [01:43<00:00, 10.37s/it]
iteration:  55
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 43.13it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.143529429767139
The final epsilon delta values after the training is over:  (2.143529429767139, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0172413793103448, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:35, 10.62s/it] 20%|██        | 2/10 [00:20<01:23, 10.38s/it] 30%|███       | 3/10 [00:31<01:12, 10.32s/it] 40%|████      | 4/10 [00:41<01:02, 10.42s/it] 50%|█████     | 5/10 [00:52<00:52, 10.46s/it] 60%|██████    | 6/10 [01:02<00:41, 10.38s/it] 70%|███████   | 7/10 [01:12<00:30, 10.33s/it] 80%|████████  | 8/10 [01:22<00:20, 10.30s/it] 90%|█████████ | 9/10 [01:33<00:10, 10.31s/it]100%|██████████| 10/10 [01:43<00:00, 10.38s/it]100%|██████████| 10/10 [01:43<00:00, 10.37s/it]
iteration:  56
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.80it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.9527687632759303
The final epsilon delta values after the training is over:  (1.9527687632759303, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0689655172413794, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:34, 10.51s/it] 20%|██        | 2/10 [00:20<01:23, 10.40s/it] 30%|███       | 3/10 [00:31<01:12, 10.34s/it] 40%|████      | 4/10 [00:41<01:01, 10.32s/it] 50%|█████     | 5/10 [00:52<00:52, 10.45s/it] 60%|██████    | 6/10 [01:02<00:41, 10.44s/it] 70%|███████   | 7/10 [01:12<00:31, 10.40s/it] 80%|████████  | 8/10 [01:23<00:20, 10.37s/it] 90%|█████████ | 9/10 [01:33<00:10, 10.36s/it]100%|██████████| 10/10 [01:44<00:00, 10.43s/it]100%|██████████| 10/10 [01:44<00:00, 10.40s/it]
iteration:  57
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 43.81it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.9527687632759303
The final epsilon delta values after the training is over:  (1.9527687632759303, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0689655172413794, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:33, 10.38s/it] 20%|██        | 2/10 [00:21<01:25, 10.71s/it] 30%|███       | 3/10 [00:31<01:14, 10.58s/it] 40%|████      | 4/10 [00:42<01:02, 10.48s/it] 50%|█████     | 5/10 [00:52<00:51, 10.39s/it] 60%|██████    | 6/10 [01:02<00:41, 10.35s/it] 70%|███████   | 7/10 [01:12<00:30, 10.33s/it] 80%|████████  | 8/10 [01:23<00:20, 10.32s/it] 90%|█████████ | 9/10 [01:33<00:10, 10.37s/it]100%|██████████| 10/10 [01:44<00:00, 10.37s/it]100%|██████████| 10/10 [01:44<00:00, 10.40s/it]
iteration:  58
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 43.88it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.9527687632759303
The final epsilon delta values after the training is over:  (1.9527687632759303, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0689655172413794, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:33, 10.43s/it] 20%|██        | 2/10 [00:20<01:22, 10.37s/it] 30%|███       | 3/10 [00:31<01:12, 10.35s/it] 40%|████      | 4/10 [00:41<01:02, 10.38s/it] 50%|█████     | 5/10 [00:52<00:52, 10.45s/it] 60%|██████    | 6/10 [01:02<00:41, 10.40s/it] 70%|███████   | 7/10 [01:12<00:31, 10.45s/it] 80%|████████  | 8/10 [01:23<00:20, 10.40s/it] 90%|█████████ | 9/10 [01:33<00:10, 10.40s/it]100%|██████████| 10/10 [01:44<00:00, 10.48s/it]100%|██████████| 10/10 [01:44<00:00, 10.43s/it]
iteration:  59
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.42it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.9527687632759303
The final epsilon delta values after the training is over:  (1.9527687632759303, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0689655172413794, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.79s/it] 20%|██        | 2/10 [00:21<01:24, 10.55s/it] 30%|███       | 3/10 [00:31<01:13, 10.44s/it] 40%|████      | 4/10 [00:41<01:02, 10.40s/it] 50%|█████     | 5/10 [00:52<00:52, 10.45s/it] 60%|██████    | 6/10 [01:02<00:41, 10.47s/it] 70%|███████   | 7/10 [01:13<00:31, 10.45s/it] 80%|████████  | 8/10 [01:23<00:21, 10.52s/it] 90%|█████████ | 9/10 [01:34<00:10, 10.51s/it]100%|██████████| 10/10 [01:44<00:00, 10.48s/it]100%|██████████| 10/10 [01:44<00:00, 10.48s/it]
iteration:  60
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.94it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.9527687632759303
The final epsilon delta values after the training is over:  (1.9527687632759303, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0689655172413794, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:33, 10.41s/it] 20%|██        | 2/10 [00:20<01:23, 10.42s/it] 30%|███       | 3/10 [00:31<01:12, 10.43s/it] 40%|████      | 4/10 [00:41<01:02, 10.39s/it] 50%|█████     | 5/10 [00:51<00:51, 10.38s/it] 60%|██████    | 6/10 [01:02<00:41, 10.38s/it] 70%|███████   | 7/10 [01:13<00:31, 10.47s/it] 80%|████████  | 8/10 [01:23<00:20, 10.44s/it] 90%|█████████ | 9/10 [01:33<00:10, 10.42s/it]100%|██████████| 10/10 [01:44<00:00, 10.53s/it]100%|██████████| 10/10 [01:44<00:00, 10.45s/it]
iteration:  61
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.88it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.7995410093407855
The final epsilon delta values after the training is over:  (1.7995410093407855, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1206896551724137, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:35, 10.63s/it] 20%|██        | 2/10 [00:21<01:24, 10.55s/it] 30%|███       | 3/10 [00:31<01:14, 10.60s/it] 40%|████      | 4/10 [00:42<01:03, 10.53s/it] 50%|█████     | 5/10 [00:52<00:52, 10.55s/it] 60%|██████    | 6/10 [01:03<00:42, 10.50s/it] 70%|███████   | 7/10 [01:13<00:31, 10.52s/it] 80%|████████  | 8/10 [01:24<00:20, 10.49s/it] 90%|█████████ | 9/10 [01:34<00:10, 10.48s/it]100%|██████████| 10/10 [01:45<00:00, 10.47s/it]100%|██████████| 10/10 [01:45<00:00, 10.51s/it]
iteration:  62
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.05it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.7995410093407855
The final epsilon delta values after the training is over:  (1.7995410093407855, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1206896551724137, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:33, 10.42s/it] 20%|██        | 2/10 [00:20<01:23, 10.41s/it] 30%|███       | 3/10 [00:31<01:13, 10.45s/it] 40%|████      | 4/10 [00:41<01:02, 10.47s/it] 50%|█████     | 5/10 [00:52<00:52, 10.47s/it] 60%|██████    | 6/10 [01:02<00:42, 10.53s/it] 70%|███████   | 7/10 [01:13<00:31, 10.55s/it] 80%|████████  | 8/10 [01:24<00:21, 10.53s/it] 90%|█████████ | 9/10 [01:34<00:10, 10.50s/it]100%|██████████| 10/10 [01:45<00:00, 10.52s/it]100%|██████████| 10/10 [01:45<00:00, 10.50s/it]
iteration:  63
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 43.04it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.7995410093407855
The final epsilon delta values after the training is over:  (1.7995410093407855, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1206896551724137, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:39, 11.05s/it] 20%|██        | 2/10 [00:21<01:26, 10.87s/it] 30%|███       | 3/10 [00:32<01:15, 10.78s/it] 40%|████      | 4/10 [00:42<01:04, 10.68s/it] 50%|█████     | 5/10 [00:53<00:53, 10.60s/it] 60%|██████    | 6/10 [01:04<00:42, 10.60s/it] 70%|███████   | 7/10 [01:14<00:31, 10.57s/it] 80%|████████  | 8/10 [01:24<00:21, 10.52s/it] 90%|█████████ | 9/10 [01:35<00:10, 10.57s/it]100%|██████████| 10/10 [01:46<00:00, 10.52s/it]100%|██████████| 10/10 [01:46<00:00, 10.61s/it]
iteration:  64
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.16it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.7995410093407855
The final epsilon delta values after the training is over:  (1.7995410093407855, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1206896551724137, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:34, 10.46s/it] 20%|██        | 2/10 [00:21<01:25, 10.70s/it] 30%|███       | 3/10 [00:31<01:14, 10.66s/it] 40%|████      | 4/10 [00:42<01:03, 10.58s/it] 50%|█████     | 5/10 [00:52<00:52, 10.53s/it] 60%|██████    | 6/10 [01:03<00:42, 10.50s/it] 70%|███████   | 7/10 [01:13<00:31, 10.50s/it] 80%|████████  | 8/10 [01:24<00:21, 10.54s/it] 90%|█████████ | 9/10 [01:35<00:10, 10.65s/it]100%|██████████| 10/10 [01:46<00:00, 10.68s/it]100%|██████████| 10/10 [01:46<00:00, 10.61s/it]
iteration:  65
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.05it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.7995410093407855
The final epsilon delta values after the training is over:  (1.7995410093407855, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1206896551724137, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:33, 10.43s/it] 20%|██        | 2/10 [00:20<01:23, 10.43s/it] 30%|███       | 3/10 [00:31<01:13, 10.49s/it] 40%|████      | 4/10 [00:42<01:03, 10.56s/it] 50%|█████     | 5/10 [00:52<00:53, 10.62s/it] 60%|██████    | 6/10 [01:03<00:42, 10.60s/it] 70%|███████   | 7/10 [01:14<00:31, 10.63s/it] 80%|████████  | 8/10 [01:24<00:21, 10.61s/it] 90%|█████████ | 9/10 [01:35<00:10, 10.68s/it]100%|██████████| 10/10 [01:46<00:00, 10.67s/it]100%|██████████| 10/10 [01:46<00:00, 10.61s/it]
iteration:  66
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.83it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.6696234071796798
The final epsilon delta values after the training is over:  (1.6696234071796798, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1724137931034484, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:36, 10.73s/it] 20%|██        | 2/10 [00:21<01:24, 10.61s/it] 30%|███       | 3/10 [00:31<01:13, 10.55s/it] 40%|████      | 4/10 [00:42<01:03, 10.54s/it] 50%|█████     | 5/10 [00:52<00:52, 10.52s/it] 60%|██████    | 6/10 [01:03<00:42, 10.52s/it] 70%|███████   | 7/10 [01:13<00:31, 10.53s/it] 80%|████████  | 8/10 [01:24<00:21, 10.53s/it] 90%|█████████ | 9/10 [01:35<00:10, 10.60s/it]100%|██████████| 10/10 [01:45<00:00, 10.60s/it]100%|██████████| 10/10 [01:45<00:00, 10.57s/it]
iteration:  67
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.95it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.6696234071796798
The final epsilon delta values after the training is over:  (1.6696234071796798, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1724137931034484, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:38, 10.97s/it] 20%|██        | 2/10 [00:21<01:25, 10.71s/it] 30%|███       | 3/10 [00:32<01:14, 10.63s/it] 40%|████      | 4/10 [00:42<01:03, 10.61s/it] 50%|█████     | 5/10 [00:53<00:52, 10.60s/it] 60%|██████    | 6/10 [01:03<00:42, 10.65s/it] 70%|███████   | 7/10 [01:14<00:32, 10.71s/it] 80%|████████  | 8/10 [01:25<00:21, 10.64s/it] 90%|█████████ | 9/10 [01:35<00:10, 10.59s/it]100%|██████████| 10/10 [01:46<00:00, 10.63s/it]100%|██████████| 10/10 [01:46<00:00, 10.65s/it]
iteration:  68
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 42.17it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.6696234071796798
The final epsilon delta values after the training is over:  (1.6696234071796798, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1724137931034484, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:46, 11.84s/it] 20%|██        | 2/10 [00:22<01:31, 11.39s/it] 30%|███       | 3/10 [00:33<01:17, 11.09s/it] 40%|████      | 4/10 [00:44<01:06, 11.07s/it] 50%|█████     | 5/10 [00:55<00:54, 10.94s/it] 60%|██████    | 6/10 [01:06<00:43, 10.86s/it] 70%|███████   | 7/10 [01:16<00:32, 10.85s/it] 80%|████████  | 8/10 [01:27<00:21, 10.77s/it] 90%|█████████ | 9/10 [01:38<00:10, 10.79s/it]100%|██████████| 10/10 [01:49<00:00, 10.80s/it]100%|██████████| 10/10 [01:49<00:00, 10.92s/it]
iteration:  69
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 40.81it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.6696234071796798
The final epsilon delta values after the training is over:  (1.6696234071796798, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1724137931034484, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:36, 10.75s/it] 20%|██        | 2/10 [00:21<01:25, 10.65s/it] 30%|███       | 3/10 [00:31<01:14, 10.62s/it] 40%|████      | 4/10 [00:42<01:03, 10.59s/it] 50%|█████     | 5/10 [00:53<00:53, 10.65s/it] 60%|██████    | 6/10 [01:03<00:42, 10.62s/it] 70%|███████   | 7/10 [01:14<00:31, 10.61s/it] 80%|████████  | 8/10 [01:24<00:21, 10.61s/it] 90%|█████████ | 9/10 [01:35<00:10, 10.61s/it]100%|██████████| 10/10 [01:46<00:00, 10.59s/it]100%|██████████| 10/10 [01:46<00:00, 10.61s/it]
iteration:  70
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.81it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.6696234071796798
The final epsilon delta values after the training is over:  (1.6696234071796798, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1724137931034484, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:36, 10.69s/it] 20%|██        | 2/10 [00:21<01:25, 10.72s/it] 30%|███       | 3/10 [00:31<01:14, 10.64s/it] 40%|████      | 4/10 [00:42<01:03, 10.60s/it] 50%|█████     | 5/10 [00:53<00:52, 10.58s/it] 60%|██████    | 6/10 [01:03<00:42, 10.56s/it] 70%|███████   | 7/10 [01:14<00:31, 10.57s/it] 80%|████████  | 8/10 [01:24<00:21, 10.59s/it] 90%|█████████ | 9/10 [01:35<00:10, 10.60s/it]100%|██████████| 10/10 [01:46<00:00, 10.63s/it]100%|██████████| 10/10 [01:46<00:00, 10.61s/it]
iteration:  71
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.35it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.54766719601816
The final epsilon delta values after the training is over:  (1.54766719601816, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2241379310344827, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.80s/it] 20%|██        | 2/10 [00:21<01:26, 10.78s/it] 30%|███       | 3/10 [00:32<01:14, 10.68s/it] 40%|████      | 4/10 [00:42<01:03, 10.63s/it] 50%|█████     | 5/10 [00:53<00:53, 10.66s/it] 60%|██████    | 6/10 [01:03<00:42, 10.63s/it] 70%|███████   | 7/10 [01:14<00:31, 10.61s/it] 80%|████████  | 8/10 [01:25<00:21, 10.66s/it] 90%|█████████ | 9/10 [01:35<00:10, 10.66s/it]100%|██████████| 10/10 [01:46<00:00, 10.66s/it]100%|██████████| 10/10 [01:46<00:00, 10.66s/it]
iteration:  72
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.69it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.54766719601816
The final epsilon delta values after the training is over:  (1.54766719601816, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2241379310344827, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:38, 10.98s/it] 20%|██        | 2/10 [00:21<01:26, 10.80s/it] 30%|███       | 3/10 [00:32<01:15, 10.72s/it] 40%|████      | 4/10 [00:42<01:04, 10.71s/it] 50%|█████     | 5/10 [00:53<00:53, 10.66s/it] 60%|██████    | 6/10 [01:04<00:42, 10.71s/it] 70%|███████   | 7/10 [01:15<00:32, 10.72s/it] 80%|████████  | 8/10 [01:25<00:21, 10.74s/it] 90%|█████████ | 9/10 [01:36<00:10, 10.70s/it]100%|██████████| 10/10 [01:47<00:00, 10.68s/it]100%|██████████| 10/10 [01:47<00:00, 10.71s/it]
iteration:  73
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 42.93it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.54766719601816
The final epsilon delta values after the training is over:  (1.54766719601816, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2241379310344827, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:38, 10.91s/it] 20%|██        | 2/10 [00:21<01:27, 10.92s/it] 30%|███       | 3/10 [00:32<01:16, 10.93s/it] 40%|████      | 4/10 [00:43<01:05, 10.89s/it] 50%|█████     | 5/10 [00:54<00:54, 10.81s/it] 60%|██████    | 6/10 [01:04<00:42, 10.74s/it] 70%|███████   | 7/10 [01:15<00:32, 10.73s/it] 80%|████████  | 8/10 [01:26<00:21, 10.73s/it] 90%|█████████ | 9/10 [01:37<00:10, 10.74s/it]100%|██████████| 10/10 [01:47<00:00, 10.74s/it]100%|██████████| 10/10 [01:47<00:00, 10.78s/it]
iteration:  74
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.44it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.54766719601816
The final epsilon delta values after the training is over:  (1.54766719601816, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2241379310344827, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:36, 10.77s/it] 20%|██        | 2/10 [00:21<01:25, 10.72s/it] 30%|███       | 3/10 [00:32<01:15, 10.72s/it] 40%|████      | 4/10 [00:42<01:04, 10.73s/it] 50%|█████     | 5/10 [00:53<00:53, 10.75s/it] 60%|██████    | 6/10 [01:04<00:43, 10.79s/it] 70%|███████   | 7/10 [01:15<00:32, 10.74s/it] 80%|████████  | 8/10 [01:25<00:21, 10.75s/it] 90%|█████████ | 9/10 [01:36<00:10, 10.71s/it]100%|██████████| 10/10 [01:47<00:00, 10.68s/it]100%|██████████| 10/10 [01:47<00:00, 10.72s/it]
iteration:  75
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 42.82it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.54766719601816
The final epsilon delta values after the training is over:  (1.54766719601816, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2241379310344827, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.87s/it] 20%|██        | 2/10 [00:21<01:26, 10.79s/it] 30%|███       | 3/10 [00:32<01:15, 10.83s/it] 40%|████      | 4/10 [00:43<01:04, 10.75s/it] 50%|█████     | 5/10 [00:53<00:53, 10.69s/it] 60%|██████    | 6/10 [01:04<00:42, 10.71s/it] 70%|███████   | 7/10 [01:15<00:32, 10.79s/it] 80%|████████  | 8/10 [01:26<00:21, 10.76s/it] 90%|█████████ | 9/10 [01:36<00:10, 10.73s/it]100%|██████████| 10/10 [01:47<00:00, 10.75s/it]100%|██████████| 10/10 [01:47<00:00, 10.76s/it]
iteration:  76
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.64it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.4304109951869581
The final epsilon delta values after the training is over:  (1.4304109951869581, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2758620689655173, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:36, 10.67s/it] 20%|██        | 2/10 [00:21<01:25, 10.65s/it] 30%|███       | 3/10 [00:31<01:14, 10.64s/it] 40%|████      | 4/10 [00:42<01:03, 10.65s/it] 50%|█████     | 5/10 [00:53<00:53, 10.67s/it] 60%|██████    | 6/10 [01:03<00:42, 10.67s/it] 70%|███████   | 7/10 [01:14<00:32, 10.67s/it] 80%|████████  | 8/10 [01:25<00:21, 10.67s/it] 90%|█████████ | 9/10 [01:36<00:10, 10.72s/it]100%|██████████| 10/10 [01:46<00:00, 10.74s/it]100%|██████████| 10/10 [01:46<00:00, 10.69s/it]
iteration:  77
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 42.03it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.4304109951869581
The final epsilon delta values after the training is over:  (1.4304109951869581, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2758620689655173, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.85s/it] 20%|██        | 2/10 [00:21<01:26, 10.80s/it] 30%|███       | 3/10 [00:32<01:15, 10.78s/it] 40%|████      | 4/10 [00:43<01:04, 10.78s/it] 50%|█████     | 5/10 [00:53<00:53, 10.74s/it] 60%|██████    | 6/10 [01:04<00:43, 10.82s/it] 70%|███████   | 7/10 [01:15<00:32, 10.81s/it] 80%|████████  | 8/10 [01:26<00:21, 10.80s/it] 90%|█████████ | 9/10 [01:37<00:10, 10.81s/it]100%|██████████| 10/10 [01:47<00:00, 10.81s/it]100%|██████████| 10/10 [01:47<00:00, 10.80s/it]
iteration:  78
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.55it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.4304109951869581
The final epsilon delta values after the training is over:  (1.4304109951869581, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2758620689655173, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.80s/it] 20%|██        | 2/10 [00:21<01:25, 10.74s/it] 30%|███       | 3/10 [00:32<01:14, 10.71s/it] 40%|████      | 4/10 [00:42<01:04, 10.73s/it] 50%|█████     | 5/10 [00:53<00:53, 10.72s/it] 60%|██████    | 6/10 [01:04<00:43, 10.77s/it] 70%|███████   | 7/10 [01:15<00:32, 10.77s/it] 80%|████████  | 8/10 [01:26<00:21, 10.79s/it] 90%|█████████ | 9/10 [01:36<00:10, 10.78s/it]100%|██████████| 10/10 [01:47<00:00, 10.75s/it]100%|██████████| 10/10 [01:47<00:00, 10.76s/it]
iteration:  79
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.66it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.4304109951869581
The final epsilon delta values after the training is over:  (1.4304109951869581, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2758620689655173, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:36, 10.69s/it] 20%|██        | 2/10 [00:21<01:25, 10.69s/it] 30%|███       | 3/10 [00:32<01:15, 10.76s/it] 40%|████      | 4/10 [00:43<01:04, 10.78s/it] 50%|█████     | 5/10 [00:53<00:53, 10.76s/it] 60%|██████    | 6/10 [01:04<00:42, 10.75s/it] 70%|███████   | 7/10 [01:15<00:32, 10.78s/it] 80%|████████  | 8/10 [01:26<00:21, 10.78s/it] 90%|█████████ | 9/10 [01:37<00:10, 10.83s/it]100%|██████████| 10/10 [01:47<00:00, 10.86s/it]100%|██████████| 10/10 [01:47<00:00, 10.80s/it]
iteration:  80
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.54it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.4304109951869581
The final epsilon delta values after the training is over:  (1.4304109951869581, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2758620689655173, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:36, 10.76s/it] 20%|██        | 2/10 [00:21<01:27, 10.88s/it] 30%|███       | 3/10 [00:32<01:16, 10.87s/it] 40%|████      | 4/10 [00:43<01:05, 10.92s/it] 50%|█████     | 5/10 [00:54<00:54, 10.88s/it] 60%|██████    | 6/10 [01:05<00:43, 10.84s/it] 70%|███████   | 7/10 [01:15<00:32, 10.80s/it] 80%|████████  | 8/10 [01:26<00:21, 10.81s/it] 90%|█████████ | 9/10 [01:37<00:10, 10.79s/it]100%|██████████| 10/10 [01:48<00:00, 10.78s/it]100%|██████████| 10/10 [01:48<00:00, 10.82s/it]
iteration:  81
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.67it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.3293639454188084
The final epsilon delta values after the training is over:  (1.3293639454188084, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3275862068965516, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.89s/it] 20%|██        | 2/10 [00:21<01:26, 10.80s/it] 30%|███       | 3/10 [00:32<01:15, 10.79s/it] 40%|████      | 4/10 [00:43<01:04, 10.77s/it] 50%|█████     | 5/10 [00:54<00:54, 10.82s/it] 60%|██████    | 6/10 [01:04<00:43, 10.82s/it] 70%|███████   | 7/10 [01:15<00:32, 10.82s/it] 80%|████████  | 8/10 [01:26<00:21, 10.81s/it] 90%|█████████ | 9/10 [01:37<00:10, 10.86s/it]100%|██████████| 10/10 [01:48<00:00, 10.82s/it]100%|██████████| 10/10 [01:48<00:00, 10.82s/it]
iteration:  82
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 42.47it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.3293639454188084
The final epsilon delta values after the training is over:  (1.3293639454188084, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3275862068965516, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.84s/it] 20%|██        | 2/10 [00:21<01:27, 10.89s/it] 30%|███       | 3/10 [00:32<01:15, 10.83s/it] 40%|████      | 4/10 [00:43<01:05, 10.94s/it] 50%|█████     | 5/10 [00:54<00:54, 10.87s/it] 60%|██████    | 6/10 [01:05<00:43, 10.88s/it] 70%|███████   | 7/10 [01:16<00:32, 10.92s/it] 80%|████████  | 8/10 [01:27<00:21, 10.90s/it] 90%|█████████ | 9/10 [01:38<00:10, 10.97s/it]100%|██████████| 10/10 [01:49<00:00, 10.93s/it]100%|██████████| 10/10 [01:49<00:00, 10.91s/it]
iteration:  83
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 42.08it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.3293639454188084
The final epsilon delta values after the training is over:  (1.3293639454188084, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3275862068965516, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:39, 11.11s/it] 20%|██        | 2/10 [00:21<01:27, 10.98s/it] 30%|███       | 3/10 [00:32<01:16, 10.93s/it] 40%|████      | 4/10 [00:43<01:05, 10.90s/it] 50%|█████     | 5/10 [00:54<00:54, 10.91s/it] 60%|██████    | 6/10 [01:05<00:43, 10.87s/it] 70%|███████   | 7/10 [01:16<00:32, 10.85s/it] 80%|████████  | 8/10 [01:27<00:21, 10.86s/it] 90%|█████████ | 9/10 [01:38<00:10, 10.94s/it]100%|██████████| 10/10 [01:49<00:00, 10.92s/it]100%|██████████| 10/10 [01:49<00:00, 10.91s/it]
iteration:  84
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.72it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.3293639454188084
The final epsilon delta values after the training is over:  (1.3293639454188084, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3275862068965516, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.83s/it] 20%|██        | 2/10 [00:21<01:27, 10.88s/it] 30%|███       | 3/10 [00:32<01:15, 10.84s/it] 40%|████      | 4/10 [00:43<01:04, 10.83s/it] 50%|█████     | 5/10 [00:54<00:54, 10.81s/it] 60%|██████    | 6/10 [01:04<00:43, 10.80s/it] 70%|███████   | 7/10 [01:15<00:32, 10.80s/it] 80%|████████  | 8/10 [01:26<00:21, 10.82s/it] 90%|█████████ | 9/10 [01:37<00:10, 10.89s/it]100%|██████████| 10/10 [01:48<00:00, 10.88s/it]100%|██████████| 10/10 [01:48<00:00, 10.85s/it]
iteration:  85
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 42.15it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.3293639454188084
The final epsilon delta values after the training is over:  (1.3293639454188084, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3275862068965516, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:38, 10.93s/it] 20%|██        | 2/10 [00:21<01:27, 10.95s/it] 30%|███       | 3/10 [00:32<01:16, 10.88s/it] 40%|████      | 4/10 [00:43<01:05, 10.85s/it] 50%|█████     | 5/10 [00:54<00:54, 10.85s/it] 60%|██████    | 6/10 [01:05<00:43, 10.85s/it] 70%|███████   | 7/10 [01:16<00:32, 10.94s/it] 80%|████████  | 8/10 [01:27<00:21, 10.91s/it] 90%|█████████ | 9/10 [01:38<00:10, 10.92s/it]100%|██████████| 10/10 [01:48<00:00, 10.91s/it]100%|██████████| 10/10 [01:48<00:00, 10.90s/it]
iteration:  86
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 41.73it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.2442729068833662
The final epsilon delta values after the training is over:  (1.2442729068833662, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3793103448275863, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:39, 11.04s/it] 20%|██        | 2/10 [00:21<01:27, 10.94s/it] 30%|███       | 3/10 [00:32<01:16, 10.99s/it] 40%|████      | 4/10 [00:43<01:05, 11.00s/it] 50%|█████     | 5/10 [00:54<00:54, 10.94s/it] 60%|██████    | 6/10 [01:05<00:43, 10.92s/it] 70%|███████   | 7/10 [01:16<00:32, 10.95s/it] 80%|████████  | 8/10 [01:27<00:21, 10.95s/it] 90%|█████████ | 9/10 [01:38<00:10, 10.93s/it]100%|██████████| 10/10 [01:49<00:00, 10.94s/it]100%|██████████| 10/10 [01:49<00:00, 10.95s/it]
iteration:  87
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 41.86it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.2442729068833662
The final epsilon delta values after the training is over:  (1.2442729068833662, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3793103448275863, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:41, 11.32s/it] 20%|██        | 2/10 [00:22<01:28, 11.03s/it] 30%|███       | 3/10 [00:32<01:16, 10.93s/it] 40%|████      | 4/10 [00:44<01:06, 11.01s/it] 50%|█████     | 5/10 [00:55<00:54, 10.99s/it] 60%|██████    | 6/10 [01:05<00:43, 10.96s/it] 70%|███████   | 7/10 [01:16<00:32, 10.98s/it] 80%|████████  | 8/10 [01:27<00:21, 10.93s/it] 90%|█████████ | 9/10 [01:38<00:10, 10.92s/it]100%|██████████| 10/10 [01:49<00:00, 10.90s/it]100%|██████████| 10/10 [01:49<00:00, 10.95s/it]
iteration:  88
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 35.17it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.2442729068833662
The final epsilon delta values after the training is over:  (1.2442729068833662, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3793103448275863, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:38, 10.93s/it] 20%|██        | 2/10 [00:21<01:26, 10.87s/it] 30%|███       | 3/10 [00:32<01:15, 10.85s/it] 40%|████      | 4/10 [00:43<01:05, 10.85s/it] 50%|█████     | 5/10 [00:54<00:54, 10.93s/it] 60%|██████    | 6/10 [01:05<00:43, 10.95s/it] 70%|███████   | 7/10 [01:16<00:32, 10.99s/it] 80%|████████  | 8/10 [01:27<00:21, 10.99s/it] 90%|█████████ | 9/10 [01:38<00:10, 10.98s/it]100%|██████████| 10/10 [01:49<00:00, 10.96s/it]100%|██████████| 10/10 [01:49<00:00, 10.94s/it]
iteration:  89
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.77it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.2442729068833662
The final epsilon delta values after the training is over:  (1.2442729068833662, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3793103448275863, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:38, 10.98s/it] 20%|██        | 2/10 [00:22<01:28, 11.09s/it] 30%|███       | 3/10 [00:33<01:16, 10.99s/it] 40%|████      | 4/10 [00:44<01:06, 11.02s/it] 50%|█████     | 5/10 [00:55<00:55, 11.03s/it] 60%|██████    | 6/10 [01:06<00:44, 11.04s/it] 70%|███████   | 7/10 [01:17<00:32, 10.98s/it] 80%|████████  | 8/10 [01:28<00:21, 10.98s/it] 90%|█████████ | 9/10 [01:38<00:10, 10.96s/it]100%|██████████| 10/10 [01:49<00:00, 10.96s/it]100%|██████████| 10/10 [01:49<00:00, 10.99s/it]
iteration:  90
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.66it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.2442729068833662
The final epsilon delta values after the training is over:  (1.2442729068833662, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3793103448275863, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:39, 11.03s/it] 20%|██        | 2/10 [00:21<01:27, 10.98s/it] 30%|███       | 3/10 [00:32<01:16, 10.92s/it] 40%|████      | 4/10 [00:44<01:06, 11.08s/it] 50%|█████     | 5/10 [00:55<00:55, 11.02s/it] 60%|██████    | 6/10 [01:06<00:44, 11.03s/it] 70%|███████   | 7/10 [01:17<00:33, 11.08s/it] 80%|████████  | 8/10 [01:28<00:22, 11.05s/it] 90%|█████████ | 9/10 [01:39<00:11, 11.05s/it]100%|██████████| 10/10 [01:50<00:00, 11.05s/it]100%|██████████| 10/10 [01:50<00:00, 11.04s/it]
iteration:  91
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.22it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1733379813769553
The final epsilon delta values after the training is over:  (1.1733379813769553, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4310344827586206, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:39, 11.10s/it] 20%|██        | 2/10 [00:21<01:27, 10.97s/it] 30%|███       | 3/10 [00:32<01:16, 10.96s/it] 40%|████      | 4/10 [00:43<01:05, 10.98s/it] 50%|█████     | 5/10 [00:54<00:54, 11.00s/it] 60%|██████    | 6/10 [01:05<00:43, 10.96s/it] 70%|███████   | 7/10 [01:16<00:32, 10.95s/it] 80%|████████  | 8/10 [01:27<00:21, 10.95s/it] 90%|█████████ | 9/10 [01:38<00:11, 11.02s/it]100%|██████████| 10/10 [01:49<00:00, 11.04s/it]100%|██████████| 10/10 [01:49<00:00, 11.00s/it]
iteration:  92
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 53.66it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1733379813769553
The final epsilon delta values after the training is over:  (1.1733379813769553, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4310344827586206, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:40, 11.16s/it] 20%|██        | 2/10 [00:22<01:29, 11.14s/it] 30%|███       | 3/10 [00:33<01:18, 11.22s/it] 40%|████      | 4/10 [00:44<01:06, 11.16s/it] 50%|█████     | 5/10 [00:55<00:56, 11.20s/it] 60%|██████    | 6/10 [01:07<00:44, 11.16s/it] 70%|███████   | 7/10 [01:17<00:33, 11.10s/it] 80%|████████  | 8/10 [01:28<00:22, 11.05s/it] 90%|█████████ | 9/10 [01:39<00:11, 11.02s/it]100%|██████████| 10/10 [01:51<00:00, 11.07s/it]100%|██████████| 10/10 [01:51<00:00, 11.11s/it]
iteration:  93
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 41.91it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1733379813769553
The final epsilon delta values after the training is over:  (1.1733379813769553, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4310344827586206, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.41s/it] 20%|██        | 2/10 [00:22<01:30, 11.35s/it] 30%|███       | 3/10 [00:33<01:19, 11.30s/it] 40%|████      | 4/10 [00:44<01:06, 11.17s/it] 50%|█████     | 5/10 [00:55<00:55, 11.13s/it] 60%|██████    | 6/10 [01:07<00:44, 11.12s/it] 70%|███████   | 7/10 [01:18<00:33, 11.06s/it] 80%|████████  | 8/10 [01:29<00:22, 11.08s/it] 90%|█████████ | 9/10 [01:40<00:11, 11.09s/it]100%|██████████| 10/10 [01:51<00:00, 11.09s/it]100%|██████████| 10/10 [01:51<00:00, 11.13s/it]
iteration:  94
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.20it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1733379813769553
The final epsilon delta values after the training is over:  (1.1733379813769553, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4310344827586206, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:41, 11.30s/it] 20%|██        | 2/10 [00:22<01:30, 11.31s/it] 30%|███       | 3/10 [00:33<01:18, 11.28s/it] 40%|████      | 4/10 [00:44<01:07, 11.22s/it] 50%|█████     | 5/10 [00:55<00:55, 11.14s/it] 60%|██████    | 6/10 [01:07<00:44, 11.13s/it] 70%|███████   | 7/10 [01:18<00:33, 11.11s/it] 80%|████████  | 8/10 [01:29<00:22, 11.08s/it] 90%|█████████ | 9/10 [01:40<00:11, 11.05s/it]100%|██████████| 10/10 [01:51<00:00, 11.04s/it]100%|██████████| 10/10 [01:51<00:00, 11.12s/it]
iteration:  95
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.26it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1733379813769553
The final epsilon delta values after the training is over:  (1.1733379813769553, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4310344827586206, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:40, 11.13s/it] 20%|██        | 2/10 [00:22<01:28, 11.08s/it] 30%|███       | 3/10 [00:33<01:17, 11.07s/it] 40%|████      | 4/10 [00:44<01:06, 11.04s/it] 50%|█████     | 5/10 [00:55<00:55, 11.10s/it] 60%|██████    | 6/10 [01:06<00:44, 11.15s/it] 70%|███████   | 7/10 [01:17<00:33, 11.11s/it] 80%|████████  | 8/10 [01:29<00:22, 11.19s/it] 90%|█████████ | 9/10 [01:40<00:11, 11.18s/it]100%|██████████| 10/10 [01:51<00:00, 11.14s/it]100%|██████████| 10/10 [01:51<00:00, 11.13s/it]
iteration:  96
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 41.80it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1138372721283347
The final epsilon delta values after the training is over:  (1.1138372721283347, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4827586206896552, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:39, 11.11s/it] 20%|██        | 2/10 [00:22<01:28, 11.09s/it] 30%|███       | 3/10 [00:33<01:18, 11.23s/it] 40%|████      | 4/10 [00:45<01:07, 11.32s/it] 50%|█████     | 5/10 [00:56<00:56, 11.28s/it] 60%|██████    | 6/10 [01:07<00:44, 11.20s/it] 70%|███████   | 7/10 [01:18<00:33, 11.20s/it] 80%|████████  | 8/10 [01:29<00:22, 11.18s/it] 90%|█████████ | 9/10 [01:40<00:11, 11.19s/it]100%|██████████| 10/10 [01:52<00:00, 11.20s/it]100%|██████████| 10/10 [01:52<00:00, 11.21s/it]
iteration:  97
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 41.39it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1138372721283347
The final epsilon delta values after the training is over:  (1.1138372721283347, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4827586206896552, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.38s/it] 20%|██        | 2/10 [00:22<01:29, 11.20s/it] 30%|███       | 3/10 [00:33<01:18, 11.25s/it] 40%|████      | 4/10 [00:44<01:07, 11.17s/it] 50%|█████     | 5/10 [00:55<00:55, 11.13s/it] 60%|██████    | 6/10 [01:06<00:44, 11.12s/it] 70%|███████   | 7/10 [01:18<00:33, 11.12s/it] 80%|████████  | 8/10 [01:29<00:22, 11.25s/it] 90%|█████████ | 9/10 [01:40<00:11, 11.23s/it]100%|██████████| 10/10 [01:51<00:00, 11.21s/it]100%|██████████| 10/10 [01:51<00:00, 11.20s/it]
iteration:  98
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.27it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1138372721283347
The final epsilon delta values after the training is over:  (1.1138372721283347, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4827586206896552, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:40, 11.19s/it] 20%|██        | 2/10 [00:22<01:29, 11.14s/it] 30%|███       | 3/10 [00:33<01:18, 11.17s/it] 40%|████      | 4/10 [00:44<01:06, 11.14s/it] 50%|█████     | 5/10 [00:55<00:56, 11.21s/it] 60%|██████    | 6/10 [01:07<00:44, 11.23s/it] 70%|███████   | 7/10 [01:18<00:33, 11.19s/it] 80%|████████  | 8/10 [01:29<00:22, 11.16s/it] 90%|█████████ | 9/10 [01:40<00:11, 11.14s/it]100%|██████████| 10/10 [01:51<00:00, 11.18s/it]100%|██████████| 10/10 [01:51<00:00, 11.18s/it]
iteration:  99
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 39.95it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1138372721283347
The final epsilon delta values after the training is over:  (1.1138372721283347, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4827586206896552, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:47, 11.90s/it] 20%|██        | 2/10 [00:22<01:31, 11.43s/it] 30%|███       | 3/10 [00:34<01:19, 11.29s/it] 40%|████      | 4/10 [00:45<01:07, 11.20s/it] 50%|█████     | 5/10 [00:56<00:55, 11.16s/it] 60%|██████    | 6/10 [01:07<00:44, 11.13s/it] 70%|███████   | 7/10 [01:18<00:33, 11.15s/it] 80%|████████  | 8/10 [01:30<00:22, 11.29s/it] 90%|█████████ | 9/10 [01:41<00:11, 11.26s/it]100%|██████████| 10/10 [01:52<00:00, 11.25s/it]100%|██████████| 10/10 [01:52<00:00, 11.26s/it]
iteration:  100
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.16it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1138372721283347
The final epsilon delta values after the training is over:  (1.1138372721283347, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4827586206896552, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:40, 11.11s/it] 20%|██        | 2/10 [00:22<01:29, 11.24s/it] 30%|███       | 3/10 [00:33<01:19, 11.31s/it] 40%|████      | 4/10 [00:45<01:07, 11.32s/it] 50%|█████     | 5/10 [00:56<00:56, 11.27s/it] 60%|██████    | 6/10 [01:07<00:45, 11.31s/it] 70%|███████   | 7/10 [01:19<00:33, 11.33s/it] 80%|████████  | 8/10 [01:30<00:22, 11.26s/it] 90%|█████████ | 9/10 [01:41<00:11, 11.23s/it]100%|██████████| 10/10 [01:52<00:00, 11.23s/it]100%|██████████| 10/10 [01:52<00:00, 11.26s/it]
iteration:  101
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.65it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0630957485927064
The final epsilon delta values after the training is over:  (1.0630957485927064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5344827586206897, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:41, 11.28s/it] 20%|██        | 2/10 [00:22<01:30, 11.31s/it] 30%|███       | 3/10 [00:33<01:18, 11.23s/it] 40%|████      | 4/10 [00:45<01:07, 11.29s/it] 50%|█████     | 5/10 [00:56<00:56, 11.23s/it] 60%|██████    | 6/10 [01:07<00:44, 11.23s/it] 70%|███████   | 7/10 [01:18<00:33, 11.21s/it] 80%|████████  | 8/10 [01:29<00:22, 11.23s/it] 90%|█████████ | 9/10 [01:41<00:11, 11.24s/it]100%|██████████| 10/10 [01:52<00:00, 11.23s/it]100%|██████████| 10/10 [01:52<00:00, 11.24s/it]
iteration:  102
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.35it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0630957485927064
The final epsilon delta values after the training is over:  (1.0630957485927064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5344827586206897, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:40, 11.13s/it] 20%|██        | 2/10 [00:22<01:29, 11.16s/it] 30%|███       | 3/10 [00:33<01:18, 11.22s/it] 40%|████      | 4/10 [00:44<01:07, 11.18s/it] 50%|█████     | 5/10 [00:55<00:55, 11.16s/it] 60%|██████    | 6/10 [01:07<00:45, 11.34s/it] 70%|███████   | 7/10 [01:18<00:33, 11.31s/it] 80%|████████  | 8/10 [01:30<00:22, 11.35s/it] 90%|█████████ | 9/10 [01:41<00:11, 11.31s/it]100%|██████████| 10/10 [01:52<00:00, 11.34s/it]100%|██████████| 10/10 [01:52<00:00, 11.28s/it]
iteration:  103
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.36it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0630957485927064
The final epsilon delta values after the training is over:  (1.0630957485927064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5344827586206897, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:41, 11.25s/it] 20%|██        | 2/10 [00:22<01:29, 11.21s/it] 30%|███       | 3/10 [00:33<01:18, 11.19s/it] 40%|████      | 4/10 [00:44<01:07, 11.19s/it] 50%|█████     | 5/10 [00:55<00:55, 11.19s/it] 60%|██████    | 6/10 [01:07<00:44, 11.19s/it] 70%|███████   | 7/10 [01:18<00:33, 11.19s/it] 80%|████████  | 8/10 [01:29<00:22, 11.19s/it] 90%|█████████ | 9/10 [01:40<00:11, 11.19s/it]100%|██████████| 10/10 [01:51<00:00, 11.18s/it]100%|██████████| 10/10 [01:51<00:00, 11.19s/it]
iteration:  104
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 55.27it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0630957485927064
The final epsilon delta values after the training is over:  (1.0630957485927064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5344827586206897, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.38s/it] 20%|██        | 2/10 [00:22<01:30, 11.36s/it] 30%|███       | 3/10 [00:34<01:19, 11.35s/it] 40%|████      | 4/10 [00:45<01:07, 11.33s/it] 50%|█████     | 5/10 [00:56<00:56, 11.28s/it] 60%|██████    | 6/10 [01:07<00:44, 11.24s/it] 70%|███████   | 7/10 [01:18<00:33, 11.22s/it] 80%|████████  | 8/10 [01:30<00:22, 11.25s/it] 90%|█████████ | 9/10 [01:41<00:11, 11.32s/it]100%|██████████| 10/10 [01:53<00:00, 11.32s/it]100%|██████████| 10/10 [01:53<00:00, 11.30s/it]
iteration:  105
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.86it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0630957485927064
The final epsilon delta values after the training is over:  (1.0630957485927064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5344827586206897, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:41, 11.22s/it] 20%|██        | 2/10 [00:22<01:31, 11.45s/it] 30%|███       | 3/10 [00:34<01:19, 11.40s/it] 40%|████      | 4/10 [00:45<01:08, 11.37s/it] 50%|█████     | 5/10 [00:56<00:56, 11.30s/it] 60%|██████    | 6/10 [01:08<00:45, 11.33s/it] 70%|███████   | 7/10 [01:19<00:33, 11.33s/it] 80%|████████  | 8/10 [01:30<00:22, 11.32s/it] 90%|█████████ | 9/10 [01:42<00:11, 11.34s/it]100%|██████████| 10/10 [01:53<00:00, 11.34s/it]100%|██████████| 10/10 [01:53<00:00, 11.34s/it]
iteration:  106
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 41.42it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0172588764126955
The final epsilon delta values after the training is over:  (1.0172588764126955, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5862068965517242, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.43s/it] 20%|██        | 2/10 [00:22<01:31, 11.47s/it] 30%|███       | 3/10 [00:34<01:19, 11.40s/it] 40%|████      | 4/10 [00:45<01:08, 11.40s/it] 50%|█████     | 5/10 [00:56<00:56, 11.35s/it] 60%|██████    | 6/10 [01:08<00:45, 11.34s/it] 70%|███████   | 7/10 [01:19<00:34, 11.38s/it] 80%|████████  | 8/10 [01:30<00:22, 11.33s/it] 90%|█████████ | 9/10 [01:42<00:11, 11.32s/it]100%|██████████| 10/10 [01:53<00:00, 11.30s/it]100%|██████████| 10/10 [01:53<00:00, 11.35s/it]
iteration:  107
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.60it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0172588764126955
The final epsilon delta values after the training is over:  (1.0172588764126955, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5862068965517242, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:41, 11.28s/it] 20%|██        | 2/10 [00:23<01:32, 11.56s/it] 30%|███       | 3/10 [00:34<01:19, 11.41s/it] 40%|████      | 4/10 [00:45<01:07, 11.33s/it] 50%|█████     | 5/10 [00:56<00:56, 11.30s/it] 60%|██████    | 6/10 [01:08<00:45, 11.30s/it] 70%|███████   | 7/10 [01:19<00:33, 11.32s/it] 80%|████████  | 8/10 [01:30<00:22, 11.29s/it] 90%|█████████ | 9/10 [01:41<00:11, 11.28s/it]100%|██████████| 10/10 [01:53<00:00, 11.27s/it]100%|██████████| 10/10 [01:53<00:00, 11.31s/it]
iteration:  108
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 41.31it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0172588764126955
The final epsilon delta values after the training is over:  (1.0172588764126955, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5862068965517242, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.44s/it] 20%|██        | 2/10 [00:22<01:31, 11.38s/it] 30%|███       | 3/10 [00:34<01:19, 11.34s/it] 40%|████      | 4/10 [00:45<01:07, 11.29s/it] 50%|█████     | 5/10 [00:56<00:56, 11.28s/it] 60%|██████    | 6/10 [01:07<00:45, 11.31s/it] 70%|███████   | 7/10 [01:19<00:33, 11.29s/it] 80%|████████  | 8/10 [01:30<00:22, 11.28s/it] 90%|█████████ | 9/10 [01:41<00:11, 11.36s/it]100%|██████████| 10/10 [01:53<00:00, 11.37s/it]100%|██████████| 10/10 [01:53<00:00, 11.33s/it]
iteration:  109
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.25it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0172588764126955
The final epsilon delta values after the training is over:  (1.0172588764126955, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5862068965517242, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:43, 11.54s/it] 20%|██        | 2/10 [00:22<01:31, 11.45s/it] 30%|███       | 3/10 [00:34<01:19, 11.36s/it] 40%|████      | 4/10 [00:45<01:08, 11.37s/it] 50%|█████     | 5/10 [00:57<00:57, 11.45s/it] 60%|██████    | 6/10 [01:08<00:45, 11.42s/it] 70%|███████   | 7/10 [01:19<00:34, 11.41s/it] 80%|████████  | 8/10 [01:31<00:22, 11.44s/it] 90%|█████████ | 9/10 [01:42<00:11, 11.47s/it]100%|██████████| 10/10 [01:54<00:00, 11.41s/it]100%|██████████| 10/10 [01:54<00:00, 11.42s/it]
iteration:  110
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 40.70it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0172588764126955
The final epsilon delta values after the training is over:  (1.0172588764126955, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5862068965517242, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.36s/it] 20%|██        | 2/10 [00:23<01:32, 11.60s/it] 30%|███       | 3/10 [00:34<01:20, 11.53s/it] 40%|████      | 4/10 [00:45<01:08, 11.43s/it] 50%|█████     | 5/10 [00:57<00:56, 11.37s/it] 60%|██████    | 6/10 [01:08<00:45, 11.34s/it] 70%|███████   | 7/10 [01:20<00:34, 11.45s/it] 80%|████████  | 8/10 [01:31<00:22, 11.44s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.49s/it]100%|██████████| 10/10 [01:54<00:00, 11.54s/it]100%|██████████| 10/10 [01:54<00:00, 11.47s/it]
iteration:  111
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.81it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9758025205260582
The final epsilon delta values after the training is over:  (0.9758025205260582, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6379310344827587, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.35s/it] 20%|██        | 2/10 [00:22<01:30, 11.37s/it] 30%|███       | 3/10 [00:34<01:20, 11.47s/it] 40%|████      | 4/10 [00:45<01:08, 11.40s/it] 50%|█████     | 5/10 [00:56<00:56, 11.37s/it] 60%|██████    | 6/10 [01:08<00:45, 11.34s/it] 70%|███████   | 7/10 [01:19<00:33, 11.31s/it] 80%|████████  | 8/10 [01:30<00:22, 11.30s/it] 90%|█████████ | 9/10 [01:42<00:11, 11.32s/it]100%|██████████| 10/10 [01:53<00:00, 11.40s/it]100%|██████████| 10/10 [01:53<00:00, 11.37s/it]
iteration:  112
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 39.35it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9758025205260582
The final epsilon delta values after the training is over:  (0.9758025205260582, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6379310344827587, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.41s/it] 20%|██        | 2/10 [00:22<01:31, 11.40s/it] 30%|███       | 3/10 [00:34<01:19, 11.39s/it] 40%|████      | 4/10 [00:45<01:08, 11.35s/it] 50%|█████     | 5/10 [00:56<00:56, 11.33s/it] 60%|██████    | 6/10 [01:08<00:45, 11.41s/it] 70%|███████   | 7/10 [01:19<00:34, 11.44s/it] 80%|████████  | 8/10 [01:31<00:22, 11.41s/it] 90%|█████████ | 9/10 [01:42<00:11, 11.49s/it]100%|██████████| 10/10 [01:54<00:00, 11.47s/it]100%|██████████| 10/10 [01:54<00:00, 11.43s/it]
iteration:  113
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 55.14it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9758025205260582
The final epsilon delta values after the training is over:  (0.9758025205260582, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6379310344827587, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:46, 11.81s/it] 20%|██        | 2/10 [00:23<01:32, 11.54s/it] 30%|███       | 3/10 [00:34<01:20, 11.46s/it] 40%|████      | 4/10 [00:45<01:08, 11.43s/it] 50%|█████     | 5/10 [00:57<00:56, 11.39s/it] 60%|██████    | 6/10 [01:08<00:45, 11.37s/it] 70%|███████   | 7/10 [01:20<00:34, 11.40s/it] 80%|████████  | 8/10 [01:31<00:22, 11.41s/it] 90%|█████████ | 9/10 [01:42<00:11, 11.41s/it]100%|██████████| 10/10 [01:54<00:00, 11.41s/it]100%|██████████| 10/10 [01:54<00:00, 11.43s/it]
iteration:  114
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 40.66it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9758025205260582
The final epsilon delta values after the training is over:  (0.9758025205260582, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6379310344827587, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.72s/it] 20%|██        | 2/10 [00:23<01:32, 11.52s/it] 30%|███       | 3/10 [00:34<01:20, 11.49s/it] 40%|████      | 4/10 [00:45<01:08, 11.47s/it] 50%|█████     | 5/10 [00:57<00:57, 11.45s/it] 60%|██████    | 6/10 [01:08<00:45, 11.48s/it] 70%|███████   | 7/10 [01:20<00:34, 11.46s/it] 80%|████████  | 8/10 [01:31<00:22, 11.46s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.44s/it]100%|██████████| 10/10 [01:54<00:00, 11.42s/it]100%|██████████| 10/10 [01:54<00:00, 11.46s/it]
iteration:  115
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 41.50it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9758025205260582
The final epsilon delta values after the training is over:  (0.9758025205260582, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6379310344827587, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.40s/it] 20%|██        | 2/10 [00:22<01:32, 11.50s/it] 30%|███       | 3/10 [00:34<01:20, 11.49s/it] 40%|████      | 4/10 [00:45<01:08, 11.46s/it] 50%|█████     | 5/10 [00:57<00:57, 11.55s/it] 60%|██████    | 6/10 [01:08<00:46, 11.50s/it] 70%|███████   | 7/10 [01:20<00:34, 11.46s/it] 80%|████████  | 8/10 [01:31<00:22, 11.48s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.45s/it]100%|██████████| 10/10 [01:55<00:00, 11.57s/it]100%|██████████| 10/10 [01:55<00:00, 11.51s/it]
iteration:  116
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.39it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.941564515213259
The final epsilon delta values after the training is over:  (0.941564515213259, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.75s/it] 20%|██        | 2/10 [00:23<01:32, 11.55s/it] 30%|███       | 3/10 [00:34<01:20, 11.52s/it] 40%|████      | 4/10 [00:46<01:08, 11.48s/it] 50%|█████     | 5/10 [00:57<00:57, 11.56s/it] 60%|██████    | 6/10 [01:09<00:46, 11.50s/it] 70%|███████   | 7/10 [01:20<00:34, 11.53s/it] 80%|████████  | 8/10 [01:32<00:23, 11.54s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.55s/it]100%|██████████| 10/10 [01:55<00:00, 11.58s/it]100%|██████████| 10/10 [01:55<00:00, 11.55s/it]
iteration:  117
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.16it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.941564515213259
The final epsilon delta values after the training is over:  (0.941564515213259, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.77s/it] 20%|██        | 2/10 [00:23<01:32, 11.62s/it] 30%|███       | 3/10 [00:34<01:20, 11.56s/it] 40%|████      | 4/10 [00:46<01:09, 11.54s/it] 50%|█████     | 5/10 [00:57<00:57, 11.48s/it] 60%|██████    | 6/10 [01:09<00:45, 11.47s/it] 70%|███████   | 7/10 [01:20<00:34, 11.45s/it] 80%|████████  | 8/10 [01:31<00:22, 11.44s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.48s/it]100%|██████████| 10/10 [01:55<00:00, 11.50s/it]100%|██████████| 10/10 [01:55<00:00, 11.50s/it]
iteration:  118
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.77it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.941564515213259
The final epsilon delta values after the training is over:  (0.941564515213259, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:43, 11.54s/it] 20%|██        | 2/10 [00:22<01:31, 11.46s/it] 30%|███       | 3/10 [00:34<01:20, 11.44s/it] 40%|████      | 4/10 [00:45<01:08, 11.43s/it] 50%|█████     | 5/10 [00:57<00:57, 11.41s/it] 60%|██████    | 6/10 [01:08<00:45, 11.41s/it] 70%|███████   | 7/10 [01:19<00:34, 11.40s/it] 80%|████████  | 8/10 [01:31<00:22, 11.45s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.50s/it]100%|██████████| 10/10 [01:54<00:00, 11.49s/it]100%|██████████| 10/10 [01:54<00:00, 11.46s/it]
iteration:  119
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.34it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.941564515213259
The final epsilon delta values after the training is over:  (0.941564515213259, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.75s/it] 20%|██        | 2/10 [00:23<01:33, 11.67s/it] 30%|███       | 3/10 [00:34<01:21, 11.62s/it] 40%|████      | 4/10 [00:46<01:09, 11.58s/it] 50%|█████     | 5/10 [00:58<00:57, 11.58s/it] 60%|██████    | 6/10 [01:09<00:46, 11.70s/it] 70%|███████   | 7/10 [01:21<00:34, 11.61s/it] 80%|████████  | 8/10 [01:32<00:23, 11.56s/it] 90%|█████████ | 9/10 [01:44<00:11, 11.52s/it]100%|██████████| 10/10 [01:55<00:00, 11.49s/it]100%|██████████| 10/10 [01:55<00:00, 11.57s/it]
iteration:  120
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 40.86it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.941564515213259
The final epsilon delta values after the training is over:  (0.941564515213259, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.74s/it] 20%|██        | 2/10 [00:23<01:32, 11.56s/it] 30%|███       | 3/10 [00:34<01:21, 11.60s/it] 40%|████      | 4/10 [00:46<01:09, 11.58s/it] 50%|█████     | 5/10 [00:57<00:57, 11.54s/it] 60%|██████    | 6/10 [01:09<00:46, 11.51s/it] 70%|███████   | 7/10 [01:20<00:34, 11.50s/it] 80%|████████  | 8/10 [01:32<00:23, 11.54s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.51s/it]100%|██████████| 10/10 [01:55<00:00, 11.48s/it]100%|██████████| 10/10 [01:55<00:00, 11.53s/it]
iteration:  121
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.20it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9116570771598174
The final epsilon delta values after the training is over:  (0.9116570771598174, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.7413793103448276, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:43, 11.49s/it] 20%|██        | 2/10 [00:23<01:32, 11.51s/it] 30%|███       | 3/10 [00:34<01:20, 11.54s/it] 40%|████      | 4/10 [00:46<01:08, 11.50s/it] 50%|█████     | 5/10 [00:57<00:57, 11.46s/it] 60%|██████    | 6/10 [01:09<00:46, 11.51s/it] 70%|███████   | 7/10 [01:20<00:34, 11.57s/it] 80%|████████  | 8/10 [01:32<00:23, 11.60s/it] 90%|█████████ | 9/10 [01:44<00:11, 11.61s/it]100%|██████████| 10/10 [01:55<00:00, 11.58s/it]100%|██████████| 10/10 [01:55<00:00, 11.55s/it]
iteration:  122
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 54.63it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9116570771598174
The final epsilon delta values after the training is over:  (0.9116570771598174, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.7413793103448276, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.69s/it] 20%|██        | 2/10 [00:23<01:32, 11.57s/it] 30%|███       | 3/10 [00:34<01:20, 11.52s/it] 40%|████      | 4/10 [00:46<01:09, 11.55s/it] 50%|█████     | 5/10 [00:57<00:57, 11.59s/it] 60%|██████    | 6/10 [01:09<00:46, 11.54s/it] 70%|███████   | 7/10 [01:20<00:34, 11.52s/it] 80%|████████  | 8/10 [01:32<00:23, 11.51s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.50s/it]100%|██████████| 10/10 [01:55<00:00, 11.53s/it]100%|██████████| 10/10 [01:55<00:00, 11.54s/it]
iteration:  123
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 48.66it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9116570771598174
The final epsilon delta values after the training is over:  (0.9116570771598174, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.7413793103448276, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.70s/it] 20%|██        | 2/10 [00:23<01:32, 11.59s/it] 30%|███       | 3/10 [00:34<01:20, 11.54s/it] 40%|████      | 4/10 [00:46<01:09, 11.63s/it] 50%|█████     | 5/10 [00:58<00:58, 11.60s/it] 60%|██████    | 6/10 [01:09<00:46, 11.57s/it] 70%|███████   | 7/10 [01:21<00:34, 11.66s/it] 80%|████████  | 8/10 [01:33<00:23, 11.65s/it] 90%|█████████ | 9/10 [01:44<00:11, 11.61s/it]100%|██████████| 10/10 [01:56<00:00, 11.58s/it]100%|██████████| 10/10 [01:56<00:00, 11.60s/it]
iteration:  124
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.71it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9116570771598174
The final epsilon delta values after the training is over:  (0.9116570771598174, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.7413793103448276, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:43, 11.54s/it] 20%|██        | 2/10 [00:22<01:31, 11.49s/it] 30%|███       | 3/10 [00:34<01:20, 11.53s/it] 40%|████      | 4/10 [00:46<01:09, 11.57s/it] 50%|█████     | 5/10 [00:57<00:57, 11.55s/it] 60%|██████    | 6/10 [01:09<00:46, 11.67s/it] 70%|███████   | 7/10 [01:21<00:34, 11.66s/it] 80%|████████  | 8/10 [01:32<00:23, 11.60s/it] 90%|█████████ | 9/10 [01:44<00:11, 11.64s/it]100%|██████████| 10/10 [01:56<00:00, 11.64s/it]100%|██████████| 10/10 [01:56<00:00, 11.61s/it]
iteration:  125
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.00it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9116570771598174
The final epsilon delta values after the training is over:  (0.9116570771598174, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.7413793103448276, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:44, 11.65s/it] 20%|██        | 2/10 [00:23<01:32, 11.62s/it] 30%|███       | 3/10 [00:34<01:21, 11.65s/it] 40%|████      | 4/10 [00:46<01:09, 11.60s/it] 50%|█████     | 5/10 [00:57<00:57, 11.56s/it] 60%|██████    | 6/10 [01:09<00:46, 11.54s/it] 70%|███████   | 7/10 [01:20<00:34, 11.53s/it] 80%|████████  | 8/10 [01:32<00:23, 11.58s/it] 90%|█████████ | 9/10 [01:44<00:11, 11.57s/it]100%|██████████| 10/10 [01:55<00:00, 11.61s/it]100%|██████████| 10/10 [01:55<00:00, 11.59s/it]
iteration:  126
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.94it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8849435341031682
The final epsilon delta values after the training is over:  (0.8849435341031682, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.793103448275862, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:47, 11.90s/it] 20%|██        | 2/10 [00:23<01:34, 11.78s/it] 30%|███       | 3/10 [00:35<01:21, 11.69s/it] 40%|████      | 4/10 [00:46<01:09, 11.64s/it] 50%|█████     | 5/10 [00:58<00:58, 11.66s/it] 60%|██████    | 6/10 [01:10<00:46, 11.64s/it] 70%|███████   | 7/10 [01:21<00:34, 11.61s/it] 80%|████████  | 8/10 [01:33<00:23, 11.59s/it] 90%|█████████ | 9/10 [01:44<00:11, 11.59s/it]100%|██████████| 10/10 [01:56<00:00, 11.61s/it]100%|██████████| 10/10 [01:56<00:00, 11.64s/it]
iteration:  127
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 40.01it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8849435341031682
The final epsilon delta values after the training is over:  (0.8849435341031682, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.793103448275862, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.69s/it] 20%|██        | 2/10 [00:23<01:33, 11.65s/it] 30%|███       | 3/10 [00:34<01:21, 11.62s/it] 40%|████      | 4/10 [00:46<01:09, 11.59s/it] 50%|█████     | 5/10 [00:58<00:57, 11.58s/it] 60%|██████    | 6/10 [01:09<00:46, 11.61s/it] 70%|███████   | 7/10 [01:21<00:34, 11.60s/it] 80%|████████  | 8/10 [01:33<00:23, 11.68s/it] 90%|█████████ | 9/10 [01:44<00:11, 11.70s/it]100%|██████████| 10/10 [01:56<00:00, 11.68s/it]100%|██████████| 10/10 [01:56<00:00, 11.65s/it]
iteration:  128
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 40.79it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8849435341031682
The final epsilon delta values after the training is over:  (0.8849435341031682, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.793103448275862, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.67s/it] 20%|██        | 2/10 [00:23<01:32, 11.61s/it] 30%|███       | 3/10 [00:34<01:21, 11.62s/it] 40%|████      | 4/10 [00:46<01:09, 11.59s/it] 50%|█████     | 5/10 [00:58<00:57, 11.60s/it] 60%|██████    | 6/10 [01:09<00:46, 11.66s/it] 70%|███████   | 7/10 [01:21<00:35, 11.68s/it] 80%|████████  | 8/10 [01:33<00:23, 11.67s/it] 90%|█████████ | 9/10 [01:44<00:11, 11.64s/it]100%|██████████| 10/10 [01:56<00:00, 11.63s/it]100%|██████████| 10/10 [01:56<00:00, 11.63s/it]
iteration:  129
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 40.72it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8849435341031682
The final epsilon delta values after the training is over:  (0.8849435341031682, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.793103448275862, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:46, 11.79s/it] 20%|██        | 2/10 [00:23<01:34, 11.76s/it] 30%|███       | 3/10 [00:35<01:21, 11.68s/it] 40%|████      | 4/10 [00:46<01:10, 11.76s/it] 50%|█████     | 5/10 [00:58<00:58, 11.70s/it] 60%|██████    | 6/10 [01:10<00:46, 11.74s/it] 70%|███████   | 7/10 [01:22<00:35, 11.73s/it] 80%|████████  | 8/10 [01:33<00:23, 11.73s/it] 90%|█████████ | 9/10 [01:45<00:11, 11.73s/it]100%|██████████| 10/10 [01:57<00:00, 11.74s/it]100%|██████████| 10/10 [01:57<00:00, 11.73s/it]
iteration:  130
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 39.63it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8849435341031682
The final epsilon delta values after the training is over:  (0.8849435341031682, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.793103448275862, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:44, 11.63s/it] 20%|██        | 2/10 [00:23<01:32, 11.60s/it] 30%|███       | 3/10 [00:34<01:21, 11.64s/it] 40%|████      | 4/10 [00:46<01:09, 11.66s/it] 50%|█████     | 5/10 [00:58<00:58, 11.64s/it] 60%|██████    | 6/10 [01:09<00:46, 11.64s/it] 70%|███████   | 7/10 [01:21<00:34, 11.62s/it] 80%|████████  | 8/10 [01:33<00:23, 11.64s/it] 90%|█████████ | 9/10 [01:45<00:11, 11.73s/it]100%|██████████| 10/10 [01:56<00:00, 11.71s/it]100%|██████████| 10/10 [01:56<00:00, 11.67s/it]
iteration:  131
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 40.15it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8608852958452982
The final epsilon delta values after the training is over:  (0.8608852958452982, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.8448275862068966, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:46, 11.80s/it] 20%|██        | 2/10 [00:23<01:34, 11.77s/it] 30%|███       | 3/10 [00:35<01:22, 11.72s/it] 40%|████      | 4/10 [00:46<01:10, 11.74s/it] 50%|█████     | 5/10 [00:58<00:58, 11.75s/it] 60%|██████    | 6/10 [01:10<00:46, 11.71s/it] 70%|███████   | 7/10 [01:22<00:35, 11.68s/it] 80%|████████  | 8/10 [01:33<00:23, 11.66s/it] 90%|█████████ | 9/10 [01:45<00:11, 11.66s/it]100%|██████████| 10/10 [01:56<00:00, 11.68s/it]100%|██████████| 10/10 [01:56<00:00, 11.70s/it]
iteration:  132
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.75it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8608852958452982
The final epsilon delta values after the training is over:  (0.8608852958452982, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.8448275862068966, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:47, 11.91s/it] 20%|██        | 2/10 [00:23<01:34, 11.78s/it] 30%|███       | 3/10 [00:35<01:22, 11.74s/it] 40%|████      | 4/10 [00:47<01:10, 11.78s/it] 50%|█████     | 5/10 [00:58<00:58, 11.77s/it] 60%|██████    | 6/10 [01:10<00:46, 11.72s/it] 70%|███████   | 7/10 [01:22<00:35, 11.70s/it] 80%|████████  | 8/10 [01:34<00:23, 11.74s/it] 90%|█████████ | 9/10 [01:45<00:11, 11.75s/it]100%|██████████| 10/10 [01:57<00:00, 11.73s/it]100%|██████████| 10/10 [01:57<00:00, 11.75s/it]
iteration:  133
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.48it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8608852958452982
The final epsilon delta values after the training is over:  (0.8608852958452982, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.8448275862068966, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:50, 12.26s/it] 20%|██        | 2/10 [00:23<01:35, 11.94s/it] 30%|███       | 3/10 [00:35<01:23, 11.90s/it] 40%|████      | 4/10 [00:47<01:10, 11.83s/it] 50%|█████     | 5/10 [00:59<00:59, 11.82s/it] 60%|██████    | 6/10 [01:11<00:47, 11.84s/it] 70%|███████   | 7/10 [01:22<00:35, 11.81s/it] 80%|████████  | 8/10 [01:34<00:23, 11.77s/it] 90%|█████████ | 9/10 [01:46<00:11, 11.82s/it]100%|██████████| 10/10 [01:58<00:00, 11.84s/it]100%|██████████| 10/10 [01:58<00:00, 11.85s/it]
iteration:  134
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.24it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8608852958452982
The final epsilon delta values after the training is over:  (0.8608852958452982, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.8448275862068966, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:46, 11.82s/it] 20%|██        | 2/10 [00:23<01:34, 11.87s/it] 30%|███       | 3/10 [00:35<01:22, 11.82s/it] 40%|████      | 4/10 [00:47<01:11, 11.84s/it] 50%|█████     | 5/10 [00:59<00:59, 11.82s/it] 60%|██████    | 6/10 [01:10<00:47, 11.81s/it] 70%|███████   | 7/10 [01:22<00:35, 11.81s/it] 80%|████████  | 8/10 [01:34<00:23, 11.80s/it] 90%|█████████ | 9/10 [01:46<00:11, 11.82s/it]100%|██████████| 10/10 [01:58<00:00, 11.88s/it]100%|██████████| 10/10 [01:58<00:00, 11.84s/it]
iteration:  135
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 40.76it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8608852958452982
The final epsilon delta values after the training is over:  (0.8608852958452982, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.8448275862068966, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:47, 11.93s/it] 20%|██        | 2/10 [00:23<01:34, 11.84s/it] 30%|███       | 3/10 [00:35<01:22, 11.78s/it] 40%|████      | 4/10 [00:47<01:10, 11.76s/it] 50%|█████     | 5/10 [00:58<00:58, 11.73s/it] 60%|██████    | 6/10 [01:10<00:46, 11.74s/it] 70%|███████   | 7/10 [01:22<00:35, 11.72s/it] 80%|████████  | 8/10 [01:33<00:23, 11.72s/it] 90%|█████████ | 9/10 [01:45<00:11, 11.71s/it]100%|██████████| 10/10 [01:57<00:00, 11.71s/it]100%|██████████| 10/10 [01:57<00:00, 11.74s/it]
iteration:  136
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.44it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8391466687807205
The final epsilon delta values after the training is over:  (0.8391466687807205, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:47, 11.96s/it] 20%|██        | 2/10 [00:23<01:35, 11.92s/it] 30%|███       | 3/10 [00:35<01:23, 11.89s/it] 40%|████      | 4/10 [00:47<01:11, 11.88s/it] 50%|█████     | 5/10 [00:59<00:59, 11.90s/it] 60%|██████    | 6/10 [01:11<00:47, 11.92s/it] 70%|███████   | 7/10 [01:23<00:35, 11.85s/it] 80%|████████  | 8/10 [01:34<00:23, 11.81s/it] 90%|█████████ | 9/10 [01:46<00:11, 11.78s/it]100%|██████████| 10/10 [01:58<00:00, 11.81s/it]100%|██████████| 10/10 [01:58<00:00, 11.85s/it]
iteration:  137
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.12it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8391466687807205
The final epsilon delta values after the training is over:  (0.8391466687807205, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:46, 11.88s/it] 20%|██        | 2/10 [00:23<01:34, 11.85s/it] 30%|███       | 3/10 [00:35<01:22, 11.81s/it] 40%|████      | 4/10 [00:47<01:11, 11.91s/it] 50%|█████     | 5/10 [00:59<00:59, 11.89s/it] 60%|██████    | 6/10 [01:11<00:47, 11.84s/it] 70%|███████   | 7/10 [01:22<00:35, 11.82s/it] 80%|████████  | 8/10 [01:34<00:23, 11.84s/it] 90%|█████████ | 9/10 [01:46<00:11, 11.85s/it]100%|██████████| 10/10 [01:58<00:00, 11.86s/it]100%|██████████| 10/10 [01:58<00:00, 11.86s/it]
iteration:  138
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 40.18it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8391466687807205
The final epsilon delta values after the training is over:  (0.8391466687807205, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:46, 11.86s/it] 20%|██        | 2/10 [00:23<01:34, 11.82s/it] 30%|███       | 3/10 [00:35<01:22, 11.84s/it] 40%|████      | 4/10 [00:47<01:11, 11.88s/it] 50%|█████     | 5/10 [00:59<00:59, 11.84s/it] 60%|██████    | 6/10 [01:11<00:47, 11.86s/it] 70%|███████   | 7/10 [01:22<00:35, 11.83s/it] 80%|████████  | 8/10 [01:34<00:23, 11.81s/it] 90%|█████████ | 9/10 [01:46<00:11, 11.86s/it]100%|██████████| 10/10 [01:58<00:00, 11.91s/it]100%|██████████| 10/10 [01:58<00:00, 11.87s/it]
iteration:  139
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.43it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8391466687807205
The final epsilon delta values after the training is over:  (0.8391466687807205, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.75s/it] 20%|██        | 2/10 [00:23<01:34, 11.78s/it] 30%|███       | 3/10 [00:35<01:22, 11.79s/it] 40%|████      | 4/10 [00:47<01:10, 11.78s/it] 50%|█████     | 5/10 [00:58<00:58, 11.77s/it] 60%|██████    | 6/10 [01:10<00:47, 11.77s/it] 70%|███████   | 7/10 [01:22<00:35, 11.77s/it] 80%|████████  | 8/10 [01:34<00:23, 11.77s/it] 90%|█████████ | 9/10 [01:45<00:11, 11.77s/it]100%|██████████| 10/10 [01:57<00:00, 11.84s/it]100%|██████████| 10/10 [01:57<00:00, 11.79s/it]
iteration:  140
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 54.17it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8391466687807205
The final epsilon delta values after the training is over:  (0.8391466687807205, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:49, 12.21s/it] 20%|██        | 2/10 [00:24<01:36, 12.01s/it] 30%|███       | 3/10 [00:36<01:24, 12.02s/it] 40%|████      | 4/10 [00:48<01:11, 11.99s/it] 50%|█████     | 5/10 [01:00<01:00, 12.00s/it] 60%|██████    | 6/10 [01:11<00:47, 11.94s/it] 70%|███████   | 7/10 [01:23<00:35, 11.91s/it] 80%|████████  | 8/10 [01:36<00:24, 12.03s/it] 90%|█████████ | 9/10 [01:48<00:12, 12.07s/it]100%|██████████| 10/10 [02:00<00:00, 12.03s/it]100%|██████████| 10/10 [02:00<00:00, 12.01s/it]
iteration:  141
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.56it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8187543443065453
The final epsilon delta values after the training is over:  (0.8187543443065453, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.9482758620689655, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:47, 11.93s/it] 20%|██        | 2/10 [00:24<01:37, 12.17s/it] 30%|███       | 3/10 [00:36<01:24, 12.01s/it] 40%|████      | 4/10 [00:47<01:11, 11.95s/it] 50%|█████     | 5/10 [00:59<00:59, 11.90s/it] 60%|██████    | 6/10 [01:11<00:47, 11.86s/it] 70%|███████   | 7/10 [01:23<00:35, 11.84s/it] 80%|████████  | 8/10 [01:35<00:23, 11.83s/it] 90%|█████████ | 9/10 [01:46<00:11, 11.84s/it]100%|██████████| 10/10 [01:58<00:00, 11.86s/it]100%|██████████| 10/10 [01:58<00:00, 11.89s/it]
iteration:  142
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 40.68it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8187543443065453
The final epsilon delta values after the training is over:  (0.8187543443065453, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.9482758620689655, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:46, 11.86s/it] 20%|██        | 2/10 [00:23<01:34, 11.87s/it] 30%|███       | 3/10 [00:35<01:23, 11.90s/it] 40%|████      | 4/10 [00:47<01:11, 11.87s/it] 50%|█████     | 5/10 [00:59<00:59, 11.86s/it] 60%|██████    | 6/10 [01:11<00:47, 11.84s/it] 70%|███████   | 7/10 [01:22<00:35, 11.83s/it] 80%|████████  | 8/10 [01:34<00:23, 11.86s/it] 90%|█████████ | 9/10 [01:46<00:11, 11.86s/it]100%|██████████| 10/10 [01:58<00:00, 11.85s/it]100%|██████████| 10/10 [01:58<00:00, 11.86s/it]
iteration:  143
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.82it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8187543443065453
The final epsilon delta values after the training is over:  (0.8187543443065453, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.9482758620689655, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:47, 11.97s/it] 20%|██        | 2/10 [00:23<01:35, 11.90s/it] 30%|███       | 3/10 [00:35<01:23, 11.91s/it] 40%|████      | 4/10 [00:47<01:11, 11.87s/it] 50%|█████     | 5/10 [00:59<00:59, 11.91s/it] 60%|██████    | 6/10 [01:11<00:47, 11.90s/it] 70%|███████   | 7/10 [01:23<00:35, 11.89s/it] 80%|████████  | 8/10 [01:35<00:23, 11.88s/it] 90%|█████████ | 9/10 [01:47<00:11, 11.87s/it]100%|██████████| 10/10 [01:58<00:00, 11.87s/it]100%|██████████| 10/10 [01:58<00:00, 11.89s/it]
iteration:  144
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.55it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8187543443065453
The final epsilon delta values after the training is over:  (0.8187543443065453, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.9482758620689655, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:52, 12.46s/it] 20%|██        | 2/10 [00:24<01:39, 12.43s/it] 30%|███       | 3/10 [00:36<01:25, 12.18s/it] 40%|████      | 4/10 [00:48<01:12, 12.09s/it] 50%|█████     | 5/10 [01:00<01:00, 12.01s/it] 60%|██████    | 6/10 [01:12<00:47, 11.97s/it] 70%|███████   | 7/10 [01:24<00:36, 12.05s/it] 80%|████████  | 8/10 [01:36<00:24, 12.02s/it] 90%|█████████ | 9/10 [01:48<00:12, 12.02s/it]100%|██████████| 10/10 [02:00<00:00, 11.98s/it]100%|██████████| 10/10 [02:00<00:00, 12.06s/it]
iteration:  145
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.33it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8187543443065453
The final epsilon delta values after the training is over:  (0.8187543443065453, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.9482758620689655, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:47, 11.90s/it] 20%|██        | 2/10 [00:23<01:34, 11.87s/it] 30%|███       | 3/10 [00:35<01:23, 11.97s/it] 40%|████      | 4/10 [00:47<01:11, 11.94s/it] 50%|█████     | 5/10 [00:59<00:59, 11.92s/it] 60%|██████    | 6/10 [01:11<00:47, 11.90s/it] 70%|███████   | 7/10 [01:23<00:35, 11.95s/it] 80%|████████  | 8/10 [01:35<00:23, 11.95s/it] 90%|█████████ | 9/10 [01:47<00:11, 11.95s/it]100%|██████████| 10/10 [01:59<00:00, 11.94s/it]100%|██████████| 10/10 [01:59<00:00, 11.93s/it]
iteration:  146
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 39.30it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:47, 11.97s/it] 20%|██        | 2/10 [00:23<01:35, 11.99s/it] 30%|███       | 3/10 [00:36<01:24, 12.02s/it] 40%|████      | 4/10 [00:47<01:11, 12.00s/it] 50%|█████     | 5/10 [01:00<01:00, 12.13s/it] 60%|██████    | 6/10 [01:12<00:48, 12.12s/it] 70%|███████   | 7/10 [01:24<00:36, 12.10s/it] 80%|████████  | 8/10 [01:36<00:24, 12.05s/it] 90%|█████████ | 9/10 [01:48<00:12, 12.05s/it]100%|██████████| 10/10 [02:00<00:00, 12.05s/it]100%|██████████| 10/10 [02:00<00:00, 12.05s/it]
iteration:  147
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.98it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:51, 12.36s/it] 20%|██        | 2/10 [00:24<01:36, 12.12s/it] 30%|███       | 3/10 [00:36<01:24, 12.03s/it] 40%|████      | 4/10 [00:48<01:11, 11.98s/it] 50%|█████     | 5/10 [01:00<00:59, 11.98s/it] 60%|██████    | 6/10 [01:12<00:47, 11.97s/it] 70%|███████   | 7/10 [01:24<00:36, 12.14s/it] 80%|████████  | 8/10 [01:36<00:24, 12.13s/it] 90%|█████████ | 9/10 [01:48<00:12, 12.08s/it]100%|██████████| 10/10 [02:00<00:00, 12.04s/it]100%|██████████| 10/10 [02:00<00:00, 12.06s/it]
iteration:  148
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.49it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:47, 12.00s/it] 20%|██        | 2/10 [00:23<01:35, 11.94s/it] 30%|███       | 3/10 [00:35<01:23, 11.95s/it] 40%|████      | 4/10 [00:47<01:11, 11.93s/it] 50%|█████     | 5/10 [01:00<01:00, 12.11s/it] 60%|██████    | 6/10 [01:12<00:48, 12.09s/it] 70%|███████   | 7/10 [01:24<00:36, 12.06s/it] 80%|████████  | 8/10 [01:36<00:24, 12.04s/it] 90%|█████████ | 9/10 [01:48<00:12, 12.02s/it]100%|██████████| 10/10 [02:00<00:00, 12.04s/it]100%|██████████| 10/10 [02:00<00:00, 12.03s/it]
iteration:  149
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.00it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:48, 12.04s/it] 20%|██        | 2/10 [00:24<01:36, 12.00s/it] 30%|███       | 3/10 [00:35<01:23, 11.96s/it] 40%|████      | 4/10 [00:47<01:11, 11.95s/it] 50%|█████     | 5/10 [00:59<00:59, 11.95s/it] 60%|██████    | 6/10 [01:11<00:47, 11.95s/it] 70%|███████   | 7/10 [01:23<00:35, 11.96s/it] 80%|████████  | 8/10 [01:35<00:23, 11.96s/it] 90%|█████████ | 9/10 [01:47<00:12, 12.02s/it]100%|██████████| 10/10 [01:59<00:00, 12.05s/it]100%|██████████| 10/10 [01:59<00:00, 12.00s/it]
iteration:  150
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 39.70it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:49, 12.13s/it] 20%|██        | 2/10 [00:24<01:36, 12.12s/it] 30%|███       | 3/10 [00:36<01:24, 12.11s/it] 40%|████      | 4/10 [00:48<01:12, 12.12s/it] 50%|█████     | 5/10 [01:00<01:00, 12.13s/it] 60%|██████    | 6/10 [01:12<00:48, 12.08s/it] 70%|███████   | 7/10 [01:25<00:36, 12.19s/it] 80%|████████  | 8/10 [01:37<00:24, 12.20s/it] 90%|█████████ | 9/10 [01:49<00:12, 12.25s/it]100%|██████████| 10/10 [02:01<00:00, 12.18s/it]100%|██████████| 10/10 [02:01<00:00, 12.16s/it]
2023-02-07 04:25:53.502602: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-07 04:25:53.626694: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-07 04:25:54.142977: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-02-07 04:25:54.143042: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-02-07 04:25:54.143050: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
WARNING: this experiment is not being saved.
Loading mnist dataset.
Creating default-fc model.
iteration:  1
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.52it/s]100%|██████████| 1/1 [00:00<00:00,  7.51it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:08<01:20,  8.92s/it] 20%|██        | 2/10 [00:17<01:09,  8.71s/it] 30%|███       | 3/10 [00:26<01:00,  8.66s/it] 40%|████      | 4/10 [00:34<00:51,  8.63s/it] 50%|█████     | 5/10 [00:43<00:43,  8.61s/it] 60%|██████    | 6/10 [00:51<00:34,  8.63s/it] 70%|███████   | 7/10 [01:00<00:25,  8.67s/it] 80%|████████  | 8/10 [01:09<00:17,  8.62s/it] 90%|█████████ | 9/10 [01:17<00:08,  8.64s/it]100%|██████████| 10/10 [01:26<00:00,  8.63s/it]100%|██████████| 10/10 [01:26<00:00,  8.65s/it]
iteration:  2
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 69.90it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:08<01:19,  8.86s/it] 20%|██        | 2/10 [00:17<01:11,  8.88s/it] 30%|███       | 3/10 [00:26<01:03,  9.01s/it] 40%|████      | 4/10 [00:36<00:54,  9.11s/it] 50%|█████     | 5/10 [00:45<00:45,  9.10s/it] 60%|██████    | 6/10 [00:54<00:36,  9.08s/it] 70%|███████   | 7/10 [01:03<00:27,  9.11s/it] 80%|████████  | 8/10 [01:12<00:18,  9.17s/it] 90%|█████████ | 9/10 [01:21<00:09,  9.13s/it]100%|██████████| 10/10 [01:30<00:00,  9.05s/it]100%|██████████| 10/10 [01:30<00:00,  9.07s/it]
iteration:  3
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 46.12it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:29,  9.99s/it] 20%|██        | 2/10 [00:19<01:17,  9.67s/it] 30%|███       | 3/10 [00:28<01:05,  9.42s/it] 40%|████      | 4/10 [00:37<00:55,  9.27s/it] 50%|█████     | 5/10 [00:46<00:45,  9.17s/it] 60%|██████    | 6/10 [00:55<00:36,  9.12s/it] 70%|███████   | 7/10 [01:04<00:27,  9.11s/it] 80%|████████  | 8/10 [01:13<00:18,  9.08s/it] 90%|█████████ | 9/10 [01:22<00:09,  9.07s/it]100%|██████████| 10/10 [01:32<00:00,  9.16s/it]100%|██████████| 10/10 [01:32<00:00,  9.21s/it]
iteration:  4
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.08it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:21,  9.02s/it] 20%|██        | 2/10 [00:18<01:12,  9.03s/it] 30%|███       | 3/10 [00:27<01:03,  9.02s/it] 40%|████      | 4/10 [00:36<00:54,  9.03s/it] 50%|█████     | 5/10 [00:45<00:45,  9.13s/it] 60%|██████    | 6/10 [00:54<00:36,  9.11s/it] 70%|███████   | 7/10 [01:03<00:27,  9.06s/it] 80%|████████  | 8/10 [01:12<00:18,  9.04s/it] 90%|█████████ | 9/10 [01:21<00:09,  9.03s/it]100%|██████████| 10/10 [01:30<00:00,  9.07s/it]100%|██████████| 10/10 [01:30<00:00,  9.06s/it]
iteration:  5
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 69.93it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:21,  9.01s/it] 20%|██        | 2/10 [00:18<01:12,  9.00s/it] 30%|███       | 3/10 [00:27<01:03,  9.02s/it] 40%|████      | 4/10 [00:35<00:53,  8.99s/it] 50%|█████     | 5/10 [00:44<00:44,  8.99s/it] 60%|██████    | 6/10 [00:54<00:36,  9.03s/it] 70%|███████   | 7/10 [01:03<00:27,  9.01s/it] 80%|████████  | 8/10 [01:12<00:18,  9.00s/it] 90%|█████████ | 9/10 [01:21<00:09,  9.00s/it]100%|██████████| 10/10 [01:30<00:00,  9.00s/it]100%|██████████| 10/10 [01:30<00:00,  9.00s/it]
iteration:  6
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 46.46it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:21,  9.01s/it] 20%|██        | 2/10 [00:18<01:12,  9.00s/it] 30%|███       | 3/10 [00:27<01:04,  9.17s/it] 40%|████      | 4/10 [00:36<00:54,  9.12s/it] 50%|█████     | 5/10 [00:45<00:45,  9.12s/it] 60%|██████    | 6/10 [00:54<00:36,  9.09s/it] 70%|███████   | 7/10 [01:03<00:27,  9.06s/it] 80%|████████  | 8/10 [01:12<00:18,  9.08s/it] 90%|█████████ | 9/10 [01:21<00:09,  9.04s/it]100%|██████████| 10/10 [01:30<00:00,  9.02s/it]100%|██████████| 10/10 [01:30<00:00,  9.06s/it]
iteration:  7
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 69.75it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:22,  9.13s/it] 20%|██        | 2/10 [00:18<01:12,  9.07s/it] 30%|███       | 3/10 [00:27<01:03,  9.08s/it] 40%|████      | 4/10 [00:36<00:54,  9.02s/it] 50%|█████     | 5/10 [00:45<00:45,  9.05s/it] 60%|██████    | 6/10 [00:54<00:36,  9.08s/it] 70%|███████   | 7/10 [01:03<00:27,  9.09s/it] 80%|████████  | 8/10 [01:12<00:18,  9.09s/it] 90%|█████████ | 9/10 [01:21<00:09,  9.07s/it]100%|██████████| 10/10 [01:30<00:00,  9.05s/it]100%|██████████| 10/10 [01:30<00:00,  9.06s/it]
iteration:  8
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 70.04it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:21,  9.04s/it] 20%|██        | 2/10 [00:18<01:12,  9.03s/it] 30%|███       | 3/10 [00:27<01:03,  9.04s/it] 40%|████      | 4/10 [00:36<00:54,  9.03s/it] 50%|█████     | 5/10 [00:45<00:45,  9.04s/it] 60%|██████    | 6/10 [00:54<00:36,  9.04s/it] 70%|███████   | 7/10 [01:03<00:27,  9.02s/it] 80%|████████  | 8/10 [01:12<00:18,  9.05s/it] 90%|█████████ | 9/10 [01:21<00:09,  9.05s/it]100%|██████████| 10/10 [01:30<00:00,  9.06s/it]100%|██████████| 10/10 [01:30<00:00,  9.05s/it]
iteration:  9
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.64it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:22,  9.13s/it] 20%|██        | 2/10 [00:18<01:12,  9.09s/it] 30%|███       | 3/10 [00:27<01:03,  9.10s/it] 40%|████      | 4/10 [00:36<00:54,  9.08s/it] 50%|█████     | 5/10 [00:45<00:45,  9.05s/it] 60%|██████    | 6/10 [00:54<00:36,  9.09s/it] 70%|███████   | 7/10 [01:03<00:27,  9.15s/it] 80%|████████  | 8/10 [01:12<00:18,  9.14s/it] 90%|█████████ | 9/10 [01:22<00:09,  9.17s/it]100%|██████████| 10/10 [01:31<00:00,  9.22s/it]100%|██████████| 10/10 [01:31<00:00,  9.15s/it]
iteration:  10
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.94it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:22,  9.20s/it] 20%|██        | 2/10 [00:18<01:13,  9.18s/it] 30%|███       | 3/10 [00:27<01:04,  9.23s/it] 40%|████      | 4/10 [00:36<00:55,  9.24s/it] 50%|█████     | 5/10 [00:46<00:46,  9.23s/it] 60%|██████    | 6/10 [00:55<00:36,  9.22s/it] 70%|███████   | 7/10 [01:04<00:27,  9.29s/it] 80%|████████  | 8/10 [01:14<00:18,  9.30s/it] 90%|█████████ | 9/10 [01:23<00:09,  9.31s/it]100%|██████████| 10/10 [01:32<00:00,  9.30s/it]100%|██████████| 10/10 [01:32<00:00,  9.27s/it]
iteration:  11
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 46.25it/s]
Number of steps:  64
[ 64 ]Privacy loss is 11.17647147989064
The final epsilon delta values after the training is over:  (11.17647147989064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5517241379310345, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:24,  9.43s/it] 20%|██        | 2/10 [00:19<01:16,  9.52s/it] 30%|███       | 3/10 [00:28<01:06,  9.45s/it] 40%|████      | 4/10 [00:38<00:57,  9.58s/it] 50%|█████     | 5/10 [00:47<00:47,  9.59s/it] 60%|██████    | 6/10 [00:57<00:38,  9.57s/it] 70%|███████   | 7/10 [01:06<00:28,  9.52s/it] 80%|████████  | 8/10 [01:16<00:19,  9.51s/it] 90%|█████████ | 9/10 [01:25<00:09,  9.48s/it]100%|██████████| 10/10 [01:35<00:00,  9.53s/it]100%|██████████| 10/10 [01:35<00:00,  9.53s/it]
iteration:  12
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.14it/s]
Number of steps:  64
[ 64 ]Privacy loss is 11.17647147989064
The final epsilon delta values after the training is over:  (11.17647147989064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5517241379310345, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:27,  9.77s/it] 20%|██        | 2/10 [00:19<01:16,  9.56s/it] 30%|███       | 3/10 [00:28<01:06,  9.50s/it] 40%|████      | 4/10 [00:38<00:56,  9.49s/it] 50%|█████     | 5/10 [00:47<00:47,  9.50s/it] 60%|██████    | 6/10 [00:57<00:37,  9.48s/it] 70%|███████   | 7/10 [01:06<00:28,  9.48s/it] 80%|████████  | 8/10 [01:17<00:19,  9.91s/it] 90%|█████████ | 9/10 [01:26<00:09,  9.82s/it]100%|██████████| 10/10 [01:36<00:00,  9.74s/it]100%|██████████| 10/10 [01:36<00:00,  9.65s/it]
iteration:  13
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 44.84it/s]
Number of steps:  64
[ 64 ]Privacy loss is 11.17647147989064
The final epsilon delta values after the training is over:  (11.17647147989064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5517241379310345, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:31, 10.13s/it] 20%|██        | 2/10 [00:19<01:18,  9.85s/it] 30%|███       | 3/10 [00:29<01:08,  9.77s/it] 40%|████      | 4/10 [00:38<00:57,  9.66s/it] 50%|█████     | 5/10 [00:48<00:47,  9.59s/it] 60%|██████    | 6/10 [00:57<00:38,  9.55s/it] 70%|███████   | 7/10 [01:07<00:28,  9.53s/it] 80%|████████  | 8/10 [01:16<00:19,  9.51s/it] 90%|█████████ | 9/10 [01:26<00:09,  9.51s/it]100%|██████████| 10/10 [01:35<00:00,  9.55s/it]100%|██████████| 10/10 [01:35<00:00,  9.60s/it]
iteration:  14
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.86it/s]
Number of steps:  64
[ 64 ]Privacy loss is 11.17647147989064
The final epsilon delta values after the training is over:  (11.17647147989064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5517241379310345, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:26,  9.65s/it] 20%|██        | 2/10 [00:19<01:16,  9.60s/it] 30%|███       | 3/10 [00:28<01:07,  9.62s/it] 40%|████      | 4/10 [00:38<00:57,  9.61s/it] 50%|█████     | 5/10 [00:48<00:48,  9.63s/it] 60%|██████    | 6/10 [00:57<00:38,  9.62s/it] 70%|███████   | 7/10 [01:07<00:28,  9.65s/it] 80%|████████  | 8/10 [01:16<00:19,  9.61s/it] 90%|█████████ | 9/10 [01:26<00:09,  9.61s/it]100%|██████████| 10/10 [01:36<00:00,  9.65s/it]100%|██████████| 10/10 [01:36<00:00,  9.63s/it]
iteration:  15
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.85it/s]
Number of steps:  64
[ 64 ]Privacy loss is 11.17647147989064
The final epsilon delta values after the training is over:  (11.17647147989064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5517241379310345, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:29,  9.90s/it] 20%|██        | 2/10 [00:19<01:17,  9.71s/it] 30%|███       | 3/10 [00:29<01:07,  9.66s/it] 40%|████      | 4/10 [00:38<00:57,  9.62s/it] 50%|█████     | 5/10 [00:48<00:47,  9.59s/it] 60%|██████    | 6/10 [00:57<00:38,  9.59s/it] 70%|███████   | 7/10 [01:07<00:29,  9.68s/it] 80%|████████  | 8/10 [01:17<00:19,  9.71s/it] 90%|█████████ | 9/10 [01:27<00:09,  9.78s/it]100%|██████████| 10/10 [01:37<00:00,  9.74s/it]100%|██████████| 10/10 [01:37<00:00,  9.70s/it]
iteration:  16
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.87it/s]
Number of steps:  64
[ 64 ]Privacy loss is 11.17647147989064
The final epsilon delta values after the training is over:  (11.17647147989064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5517241379310345, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:27,  9.77s/it] 20%|██        | 2/10 [00:19<01:18,  9.86s/it] 30%|███       | 3/10 [00:29<01:08,  9.78s/it] 40%|████      | 4/10 [00:38<00:58,  9.70s/it] 50%|█████     | 5/10 [00:48<00:48,  9.65s/it] 60%|██████    | 6/10 [00:58<00:38,  9.62s/it] 70%|███████   | 7/10 [01:07<00:28,  9.60s/it] 80%|████████  | 8/10 [01:17<00:19,  9.62s/it] 90%|█████████ | 9/10 [01:26<00:09,  9.63s/it]100%|██████████| 10/10 [01:36<00:00,  9.69s/it]100%|██████████| 10/10 [01:36<00:00,  9.68s/it]
iteration:  17
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.60it/s]
Number of steps:  64
[ 64 ]Privacy loss is 11.17647147989064
The final epsilon delta values after the training is over:  (11.17647147989064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5517241379310345, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:27,  9.72s/it] 20%|██        | 2/10 [00:19<01:17,  9.71s/it] 30%|███       | 3/10 [00:29<01:07,  9.67s/it] 40%|████      | 4/10 [00:39<00:58,  9.80s/it] 50%|█████     | 5/10 [00:48<00:48,  9.76s/it] 60%|██████    | 6/10 [00:58<00:38,  9.75s/it] 70%|███████   | 7/10 [01:08<00:29,  9.71s/it] 80%|████████  | 8/10 [01:17<00:19,  9.71s/it] 90%|█████████ | 9/10 [01:27<00:09,  9.71s/it]100%|██████████| 10/10 [01:37<00:00,  9.72s/it]100%|██████████| 10/10 [01:37<00:00,  9.72s/it]
iteration:  18
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.56it/s]
Number of steps:  64
[ 64 ]Privacy loss is 11.17647147989064
The final epsilon delta values after the training is over:  (11.17647147989064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5517241379310345, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:30, 10.04s/it] 20%|██        | 2/10 [00:19<01:18,  9.86s/it] 30%|███       | 3/10 [00:29<01:08,  9.78s/it] 40%|████      | 4/10 [00:39<00:58,  9.76s/it] 50%|█████     | 5/10 [00:48<00:48,  9.72s/it] 60%|██████    | 6/10 [00:58<00:38,  9.70s/it] 70%|███████   | 7/10 [01:08<00:29,  9.70s/it] 80%|████████  | 8/10 [01:17<00:19,  9.72s/it] 90%|█████████ | 9/10 [01:27<00:09,  9.82s/it]100%|██████████| 10/10 [01:38<00:00,  9.91s/it]100%|██████████| 10/10 [01:38<00:00,  9.81s/it]
iteration:  19
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.27it/s]
Number of steps:  64
[ 64 ]Privacy loss is 11.17647147989064
The final epsilon delta values after the training is over:  (11.17647147989064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5517241379310345, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:27,  9.73s/it] 20%|██        | 2/10 [00:19<01:18,  9.82s/it] 30%|███       | 3/10 [00:29<01:08,  9.80s/it] 40%|████      | 4/10 [00:39<00:58,  9.81s/it] 50%|█████     | 5/10 [00:48<00:48,  9.79s/it] 60%|██████    | 6/10 [00:58<00:38,  9.75s/it] 70%|███████   | 7/10 [01:08<00:29,  9.75s/it] 80%|████████  | 8/10 [01:18<00:19,  9.79s/it] 90%|█████████ | 9/10 [01:28<00:09,  9.87s/it]100%|██████████| 10/10 [01:38<00:00,  9.85s/it]100%|██████████| 10/10 [01:38<00:00,  9.81s/it]
iteration:  20
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.33it/s]
Number of steps:  64
[ 64 ]Privacy loss is 11.17647147989064
The final epsilon delta values after the training is over:  (11.17647147989064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5517241379310345, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:29,  9.98s/it] 20%|██        | 2/10 [00:19<01:18,  9.84s/it] 30%|███       | 3/10 [00:29<01:08,  9.83s/it] 40%|████      | 4/10 [00:39<00:58,  9.80s/it] 50%|█████     | 5/10 [00:49<00:48,  9.77s/it] 60%|██████    | 6/10 [00:58<00:39,  9.81s/it] 70%|███████   | 7/10 [01:08<00:29,  9.80s/it] 80%|████████  | 8/10 [01:18<00:19,  9.78s/it] 90%|█████████ | 9/10 [01:28<00:09,  9.77s/it]100%|██████████| 10/10 [01:37<00:00,  9.76s/it]100%|██████████| 10/10 [01:37<00:00,  9.79s/it]
iteration:  21
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.11it/s]
Number of steps:  64
[ 64 ]Privacy loss is 7.369218646919686
The final epsilon delta values after the training is over:  (7.369218646919686, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.603448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:31, 10.14s/it] 20%|██        | 2/10 [00:20<01:20, 10.06s/it] 30%|███       | 3/10 [00:29<01:09,  9.90s/it] 40%|████      | 4/10 [00:39<00:59,  9.91s/it] 50%|█████     | 5/10 [00:49<00:49,  9.95s/it] 60%|██████    | 6/10 [00:59<00:39,  9.91s/it] 70%|███████   | 7/10 [01:09<00:29,  9.85s/it] 80%|████████  | 8/10 [01:19<00:19,  9.82s/it] 90%|█████████ | 9/10 [01:28<00:09,  9.80s/it]100%|██████████| 10/10 [01:38<00:00,  9.77s/it]100%|██████████| 10/10 [01:38<00:00,  9.86s/it]
iteration:  22
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 45.37it/s]
Number of steps:  64
[ 64 ]Privacy loss is 7.369218646919686
The final epsilon delta values after the training is over:  (7.369218646919686, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.603448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:29,  9.91s/it] 20%|██        | 2/10 [00:19<01:19,  9.89s/it] 30%|███       | 3/10 [00:29<01:08,  9.83s/it] 40%|████      | 4/10 [00:39<00:58,  9.81s/it] 50%|█████     | 5/10 [00:49<00:49,  9.81s/it] 60%|██████    | 6/10 [00:59<00:39,  9.93s/it] 70%|███████   | 7/10 [01:09<00:29,  9.86s/it] 80%|████████  | 8/10 [01:18<00:19,  9.81s/it] 90%|█████████ | 9/10 [01:28<00:09,  9.77s/it]100%|██████████| 10/10 [01:38<00:00,  9.80s/it]100%|██████████| 10/10 [01:38<00:00,  9.83s/it]
iteration:  23
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.45it/s]
Number of steps:  64
[ 64 ]Privacy loss is 7.369218646919686
The final epsilon delta values after the training is over:  (7.369218646919686, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.603448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:32, 10.29s/it] 20%|██        | 2/10 [00:20<01:21, 10.21s/it] 30%|███       | 3/10 [00:30<01:10, 10.08s/it] 40%|████      | 4/10 [00:40<01:00, 10.01s/it] 50%|█████     | 5/10 [00:50<00:49,  9.98s/it] 60%|██████    | 6/10 [01:00<00:39,  9.95s/it] 70%|███████   | 7/10 [01:10<00:29,  9.97s/it] 80%|████████  | 8/10 [01:20<00:19,  9.99s/it] 90%|█████████ | 9/10 [01:30<00:09,  9.96s/it]100%|██████████| 10/10 [01:39<00:00,  9.93s/it]100%|██████████| 10/10 [01:39<00:00,  9.99s/it]
iteration:  24
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.79it/s]
Number of steps:  64
[ 64 ]Privacy loss is 7.369218646919686
The final epsilon delta values after the training is over:  (7.369218646919686, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.603448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:29,  9.96s/it] 20%|██        | 2/10 [00:19<01:19,  9.89s/it] 30%|███       | 3/10 [00:29<01:09,  9.86s/it] 40%|████      | 4/10 [00:39<00:59,  9.85s/it] 50%|█████     | 5/10 [00:49<00:49,  9.81s/it] 60%|██████    | 6/10 [00:58<00:39,  9.79s/it] 70%|███████   | 7/10 [01:08<00:29,  9.80s/it] 80%|████████  | 8/10 [01:18<00:19,  9.81s/it] 90%|█████████ | 9/10 [01:28<00:09,  9.79s/it]100%|██████████| 10/10 [01:38<00:00,  9.84s/it]100%|██████████| 10/10 [01:38<00:00,  9.83s/it]
iteration:  25
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.10it/s]
Number of steps:  64
[ 64 ]Privacy loss is 7.369218646919686
The final epsilon delta values after the training is over:  (7.369218646919686, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.603448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:28,  9.89s/it] 20%|██        | 2/10 [00:19<01:18,  9.87s/it] 30%|███       | 3/10 [00:29<01:09,  9.89s/it] 40%|████      | 4/10 [00:39<00:59,  9.87s/it] 50%|█████     | 5/10 [00:49<00:49,  9.85s/it] 60%|██████    | 6/10 [00:59<00:39,  9.82s/it] 70%|███████   | 7/10 [01:09<00:29,  9.86s/it] 80%|████████  | 8/10 [01:19<00:19,  9.95s/it] 90%|█████████ | 9/10 [01:28<00:09,  9.91s/it]100%|██████████| 10/10 [01:38<00:00,  9.92s/it]100%|██████████| 10/10 [01:38<00:00,  9.89s/it]
iteration:  26
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.40it/s]
Number of steps:  64
[ 64 ]Privacy loss is 7.369218646919686
The final epsilon delta values after the training is over:  (7.369218646919686, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.603448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:29,  9.95s/it] 20%|██        | 2/10 [00:19<01:19,  9.94s/it] 30%|███       | 3/10 [00:29<01:09,  9.98s/it] 40%|████      | 4/10 [00:39<00:59,  9.95s/it] 50%|█████     | 5/10 [00:49<00:49,  9.92s/it] 60%|██████    | 6/10 [00:59<00:39,  9.87s/it] 70%|███████   | 7/10 [01:09<00:29,  9.85s/it] 80%|████████  | 8/10 [01:19<00:19,  9.86s/it] 90%|█████████ | 9/10 [01:29<00:09,  9.87s/it]100%|██████████| 10/10 [01:38<00:00,  9.90s/it]100%|██████████| 10/10 [01:38<00:00,  9.90s/it]
iteration:  27
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.36it/s]
Number of steps:  64
[ 64 ]Privacy loss is 7.369218646919686
The final epsilon delta values after the training is over:  (7.369218646919686, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.603448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:29,  9.99s/it] 20%|██        | 2/10 [00:19<01:19,  9.99s/it] 30%|███       | 3/10 [00:30<01:10, 10.06s/it] 40%|████      | 4/10 [00:40<01:00, 10.03s/it] 50%|█████     | 5/10 [00:50<00:49,  9.99s/it] 60%|██████    | 6/10 [00:59<00:39,  9.94s/it] 70%|███████   | 7/10 [01:09<00:29,  9.93s/it] 80%|████████  | 8/10 [01:19<00:19,  9.93s/it] 90%|█████████ | 9/10 [01:29<00:09,  9.91s/it]100%|██████████| 10/10 [01:39<00:00,  9.90s/it]100%|██████████| 10/10 [01:39<00:00,  9.95s/it]
iteration:  28
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.20it/s]
Number of steps:  64
[ 64 ]Privacy loss is 7.369218646919686
The final epsilon delta values after the training is over:  (7.369218646919686, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.603448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:28,  9.86s/it] 20%|██        | 2/10 [00:19<01:19,  9.98s/it] 30%|███       | 3/10 [00:29<01:09,  9.92s/it] 40%|████      | 4/10 [00:39<00:59,  9.87s/it] 50%|█████     | 5/10 [00:49<00:49,  9.85s/it] 60%|██████    | 6/10 [00:59<00:39,  9.84s/it] 70%|███████   | 7/10 [01:09<00:29,  9.84s/it] 80%|████████  | 8/10 [01:18<00:19,  9.83s/it] 90%|█████████ | 9/10 [01:28<00:09,  9.85s/it]100%|██████████| 10/10 [01:38<00:00,  9.89s/it]100%|██████████| 10/10 [01:38<00:00,  9.87s/it]
iteration:  29
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.87it/s]
Number of steps:  64
[ 64 ]Privacy loss is 7.369218646919686
The final epsilon delta values after the training is over:  (7.369218646919686, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.603448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:28,  9.89s/it] 20%|██        | 2/10 [00:19<01:18,  9.83s/it] 30%|███       | 3/10 [00:29<01:08,  9.83s/it] 40%|████      | 4/10 [00:39<00:59,  9.84s/it] 50%|█████     | 5/10 [00:49<00:49,  9.84s/it] 60%|██████    | 6/10 [00:59<00:39,  9.84s/it] 70%|███████   | 7/10 [01:08<00:29,  9.87s/it] 80%|████████  | 8/10 [01:18<00:19,  9.86s/it] 90%|█████████ | 9/10 [01:28<00:09,  9.94s/it]100%|██████████| 10/10 [01:38<00:00,  9.92s/it]100%|██████████| 10/10 [01:38<00:00,  9.88s/it]
iteration:  30
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.49it/s]
Number of steps:  64
[ 64 ]Privacy loss is 7.369218646919686
The final epsilon delta values after the training is over:  (7.369218646919686, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.603448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:30, 10.09s/it] 20%|██        | 2/10 [00:20<01:20, 10.01s/it] 30%|███       | 3/10 [00:30<01:10, 10.03s/it] 40%|████      | 4/10 [00:40<01:00, 10.06s/it] 50%|█████     | 5/10 [00:50<00:50, 10.17s/it] 60%|██████    | 6/10 [01:00<00:40, 10.09s/it] 70%|███████   | 7/10 [01:10<00:30, 10.02s/it] 80%|████████  | 8/10 [01:20<00:19,  9.96s/it] 90%|█████████ | 9/10 [01:30<00:10, 10.03s/it]100%|██████████| 10/10 [01:40<00:00, 10.02s/it]100%|██████████| 10/10 [01:40<00:00, 10.04s/it]
iteration:  31
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.30it/s]
Number of steps:  64
[ 64 ]Privacy loss is 6.494281640688786
The final epsilon delta values after the training is over:  (6.494281640688786, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.6551724137931034, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:28,  9.88s/it] 20%|██        | 2/10 [00:19<01:19,  9.93s/it] 30%|███       | 3/10 [00:29<01:09,  9.96s/it] 40%|████      | 4/10 [00:39<00:59,  9.92s/it] 50%|█████     | 5/10 [00:49<00:49,  9.92s/it] 60%|██████    | 6/10 [00:59<00:39,  9.90s/it] 70%|███████   | 7/10 [01:09<00:29,  9.91s/it] 80%|████████  | 8/10 [01:19<00:19,  9.95s/it] 90%|█████████ | 9/10 [01:29<00:09,  9.96s/it]100%|██████████| 10/10 [01:39<00:00, 10.05s/it]100%|██████████| 10/10 [01:39<00:00,  9.97s/it]
iteration:  32
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.59it/s]
Number of steps:  64
[ 64 ]Privacy loss is 6.494281640688786
The final epsilon delta values after the training is over:  (6.494281640688786, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.6551724137931034, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:33, 10.36s/it] 20%|██        | 2/10 [00:20<01:21, 10.16s/it] 30%|███       | 3/10 [00:30<01:10, 10.04s/it] 40%|████      | 4/10 [00:40<00:59, 10.00s/it] 50%|█████     | 5/10 [00:50<00:50, 10.02s/it] 60%|██████    | 6/10 [01:00<00:39,  9.97s/it] 70%|███████   | 7/10 [01:10<00:29,  9.96s/it] 80%|████████  | 8/10 [01:19<00:19,  9.94s/it] 90%|█████████ | 9/10 [01:29<00:09,  9.96s/it]100%|██████████| 10/10 [01:40<00:00, 10.00s/it]100%|██████████| 10/10 [01:40<00:00, 10.01s/it]
iteration:  33
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 45.26it/s]
Number of steps:  64
[ 64 ]Privacy loss is 6.494281640688786
The final epsilon delta values after the training is over:  (6.494281640688786, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.6551724137931034, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:32, 10.25s/it] 20%|██        | 2/10 [00:20<01:20, 10.06s/it] 30%|███       | 3/10 [00:30<01:10, 10.06s/it] 40%|████      | 4/10 [00:40<01:00, 10.02s/it] 50%|█████     | 5/10 [00:50<00:50, 10.04s/it] 60%|██████    | 6/10 [01:00<00:40, 10.04s/it] 70%|███████   | 7/10 [01:10<00:30, 10.01s/it] 80%|████████  | 8/10 [01:20<00:20, 10.03s/it] 90%|█████████ | 9/10 [01:30<00:10, 10.01s/it]100%|██████████| 10/10 [01:40<00:00, 10.11s/it]100%|██████████| 10/10 [01:40<00:00, 10.06s/it]
iteration:  34
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.02it/s]
Number of steps:  64
[ 64 ]Privacy loss is 6.494281640688786
The final epsilon delta values after the training is over:  (6.494281640688786, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.6551724137931034, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:29,  9.96s/it] 20%|██        | 2/10 [00:20<01:22, 10.26s/it] 30%|███       | 3/10 [00:30<01:11, 10.24s/it] 40%|████      | 4/10 [00:40<01:01, 10.23s/it] 50%|█████     | 5/10 [00:50<00:50, 10.15s/it] 60%|██████    | 6/10 [01:00<00:40, 10.12s/it] 70%|███████   | 7/10 [01:11<00:30, 10.13s/it] 80%|████████  | 8/10 [01:21<00:20, 10.11s/it] 90%|█████████ | 9/10 [01:31<00:10, 10.19s/it]100%|██████████| 10/10 [01:41<00:00, 10.12s/it]100%|██████████| 10/10 [01:41<00:00, 10.15s/it]
iteration:  35
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.04it/s]
Number of steps:  64
[ 64 ]Privacy loss is 6.494281640688786
The final epsilon delta values after the training is over:  (6.494281640688786, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.6551724137931034, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:31, 10.15s/it] 20%|██        | 2/10 [00:20<01:22, 10.29s/it] 30%|███       | 3/10 [00:30<01:11, 10.15s/it] 40%|████      | 4/10 [00:40<01:01, 10.22s/it] 50%|█████     | 5/10 [00:50<00:50, 10.11s/it] 60%|██████    | 6/10 [01:00<00:40, 10.07s/it] 70%|███████   | 7/10 [01:11<00:30, 10.13s/it] 80%|████████  | 8/10 [01:21<00:20, 10.15s/it] 90%|█████████ | 9/10 [01:31<00:10, 10.13s/it]100%|██████████| 10/10 [01:41<00:00, 10.10s/it]100%|██████████| 10/10 [01:41<00:00, 10.13s/it]
iteration:  36
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 44.80it/s]
Number of steps:  64
[ 64 ]Privacy loss is 6.494281640688786
The final epsilon delta values after the training is over:  (6.494281640688786, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.6551724137931034, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:30, 10.01s/it] 20%|██        | 2/10 [00:20<01:20, 10.01s/it] 30%|███       | 3/10 [00:30<01:10, 10.04s/it] 40%|████      | 4/10 [00:40<01:00, 10.05s/it] 50%|█████     | 5/10 [00:50<00:50, 10.03s/it] 60%|██████    | 6/10 [01:00<00:40, 10.02s/it] 70%|███████   | 7/10 [01:10<00:30, 10.01s/it] 80%|████████  | 8/10 [01:20<00:20, 10.00s/it] 90%|█████████ | 9/10 [01:30<00:10, 10.03s/it]100%|██████████| 10/10 [01:40<00:00, 10.02s/it]100%|██████████| 10/10 [01:40<00:00, 10.02s/it]
iteration:  37
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.96it/s]
Number of steps:  64
[ 64 ]Privacy loss is 6.494281640688786
The final epsilon delta values after the training is over:  (6.494281640688786, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.6551724137931034, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:30, 10.03s/it] 20%|██        | 2/10 [00:20<01:20, 10.03s/it] 30%|███       | 3/10 [00:30<01:11, 10.21s/it] 40%|████      | 4/10 [00:40<01:00, 10.12s/it] 50%|█████     | 5/10 [00:50<00:50, 10.07s/it] 60%|██████    | 6/10 [01:00<00:40, 10.04s/it] 70%|███████   | 7/10 [01:10<00:30, 10.05s/it] 80%|████████  | 8/10 [01:20<00:20, 10.04s/it] 90%|█████████ | 9/10 [01:30<00:10, 10.06s/it]100%|██████████| 10/10 [01:40<00:00, 10.11s/it]100%|██████████| 10/10 [01:40<00:00, 10.09s/it]
iteration:  38
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.00it/s]
Number of steps:  64
[ 64 ]Privacy loss is 6.494281640688786
The final epsilon delta values after the training is over:  (6.494281640688786, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.6551724137931034, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:33, 10.44s/it] 20%|██        | 2/10 [00:20<01:22, 10.34s/it] 30%|███       | 3/10 [00:30<01:11, 10.19s/it] 40%|████      | 4/10 [00:40<01:01, 10.19s/it] 50%|█████     | 5/10 [00:51<00:50, 10.18s/it] 60%|██████    | 6/10 [01:01<00:40, 10.12s/it] 70%|███████   | 7/10 [01:11<00:30, 10.28s/it] 80%|████████  | 8/10 [01:21<00:20, 10.23s/it] 90%|█████████ | 9/10 [01:32<00:10, 10.24s/it]100%|██████████| 10/10 [01:42<00:00, 10.18s/it]100%|██████████| 10/10 [01:42<00:00, 10.21s/it]
iteration:  39
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.69it/s]
Number of steps:  64
[ 64 ]Privacy loss is 6.494281640688786
The final epsilon delta values after the training is over:  (6.494281640688786, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.6551724137931034, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:30, 10.11s/it] 20%|██        | 2/10 [00:20<01:20, 10.08s/it] 30%|███       | 3/10 [00:30<01:10, 10.09s/it] 40%|████      | 4/10 [00:40<01:00, 10.07s/it] 50%|█████     | 5/10 [00:50<00:50, 10.09s/it] 60%|██████    | 6/10 [01:00<00:40, 10.10s/it] 70%|███████   | 7/10 [01:10<00:30, 10.11s/it] 80%|████████  | 8/10 [01:20<00:20, 10.08s/it] 90%|█████████ | 9/10 [01:30<00:10, 10.15s/it]100%|██████████| 10/10 [01:41<00:00, 10.22s/it]100%|██████████| 10/10 [01:41<00:00, 10.14s/it]
iteration:  40
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.54it/s]
Number of steps:  64
[ 64 ]Privacy loss is 6.494281640688786
The final epsilon delta values after the training is over:  (6.494281640688786, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.6551724137931034, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:33, 10.34s/it] 20%|██        | 2/10 [00:20<01:21, 10.17s/it] 30%|███       | 3/10 [00:30<01:11, 10.22s/it] 40%|████      | 4/10 [00:40<01:01, 10.26s/it] 50%|█████     | 5/10 [00:51<00:50, 10.18s/it] 60%|██████    | 6/10 [01:01<00:40, 10.18s/it] 70%|███████   | 7/10 [01:11<00:30, 10.18s/it] 80%|████████  | 8/10 [01:21<00:20, 10.18s/it] 90%|█████████ | 9/10 [01:31<00:10, 10.24s/it]100%|██████████| 10/10 [01:42<00:00, 10.20s/it]100%|██████████| 10/10 [01:42<00:00, 10.20s/it]
iteration:  41
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 44.38it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.950910242291995
The final epsilon delta values after the training is over:  (4.950910242291995, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7068965517241379, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:31, 10.20s/it] 20%|██        | 2/10 [00:20<01:22, 10.36s/it] 30%|███       | 3/10 [00:30<01:11, 10.26s/it] 40%|████      | 4/10 [00:41<01:01, 10.25s/it] 50%|█████     | 5/10 [00:51<00:50, 10.20s/it] 60%|██████    | 6/10 [01:01<00:40, 10.19s/it] 70%|███████   | 7/10 [01:11<00:30, 10.18s/it] 80%|████████  | 8/10 [01:21<00:20, 10.19s/it] 90%|█████████ | 9/10 [01:31<00:10, 10.16s/it]100%|██████████| 10/10 [01:41<00:00, 10.17s/it]100%|██████████| 10/10 [01:41<00:00, 10.20s/it]
iteration:  42
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 43.70it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.950910242291995
The final epsilon delta values after the training is over:  (4.950910242291995, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7068965517241379, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:33, 10.35s/it] 20%|██        | 2/10 [00:20<01:23, 10.42s/it] 30%|███       | 3/10 [00:31<01:12, 10.37s/it] 40%|████      | 4/10 [00:41<01:01, 10.28s/it] 50%|█████     | 5/10 [00:51<00:51, 10.25s/it] 60%|██████    | 6/10 [01:01<00:40, 10.20s/it] 70%|███████   | 7/10 [01:11<00:30, 10.21s/it] 80%|████████  | 8/10 [01:21<00:20, 10.20s/it] 90%|█████████ | 9/10 [01:32<00:10, 10.20s/it]100%|██████████| 10/10 [01:42<00:00, 10.17s/it]100%|██████████| 10/10 [01:42<00:00, 10.23s/it]
iteration:  43
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.31it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.950910242291995
The final epsilon delta values after the training is over:  (4.950910242291995, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7068965517241379, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:32, 10.29s/it] 20%|██        | 2/10 [00:20<01:21, 10.19s/it] 30%|███       | 3/10 [00:30<01:11, 10.17s/it] 40%|████      | 4/10 [00:40<01:01, 10.18s/it] 50%|█████     | 5/10 [00:50<00:50, 10.17s/it] 60%|██████    | 6/10 [01:01<00:41, 10.31s/it] 70%|███████   | 7/10 [01:11<00:30, 10.24s/it] 80%|████████  | 8/10 [01:22<00:20, 10.34s/it] 90%|█████████ | 9/10 [01:32<00:10, 10.26s/it]100%|██████████| 10/10 [01:42<00:00, 10.22s/it]100%|██████████| 10/10 [01:42<00:00, 10.24s/it]
iteration:  44
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.16it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.950910242291995
The final epsilon delta values after the training is over:  (4.950910242291995, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7068965517241379, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:32, 10.23s/it] 20%|██        | 2/10 [00:20<01:22, 10.26s/it] 30%|███       | 3/10 [00:30<01:11, 10.23s/it] 40%|████      | 4/10 [00:40<01:01, 10.18s/it] 50%|█████     | 5/10 [00:50<00:50, 10.15s/it] 60%|██████    | 6/10 [01:01<00:40, 10.16s/it] 70%|███████   | 7/10 [01:11<00:30, 10.25s/it] 80%|████████  | 8/10 [01:22<00:20, 10.33s/it] 90%|█████████ | 9/10 [01:32<00:10, 10.31s/it]100%|██████████| 10/10 [01:42<00:00, 10.39s/it]100%|██████████| 10/10 [01:42<00:00, 10.28s/it]
iteration:  45
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.07it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.950910242291995
The final epsilon delta values after the training is over:  (4.950910242291995, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7068965517241379, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:33, 10.40s/it] 20%|██        | 2/10 [00:20<01:22, 10.25s/it] 30%|███       | 3/10 [00:30<01:11, 10.22s/it] 40%|████      | 4/10 [00:40<01:01, 10.20s/it] 50%|█████     | 5/10 [00:51<00:51, 10.38s/it] 60%|██████    | 6/10 [01:01<00:41, 10.35s/it] 70%|███████   | 7/10 [01:12<00:30, 10.30s/it] 80%|████████  | 8/10 [01:22<00:20, 10.30s/it] 90%|█████████ | 9/10 [01:32<00:10, 10.33s/it]100%|██████████| 10/10 [01:43<00:00, 10.31s/it]100%|██████████| 10/10 [01:43<00:00, 10.30s/it]
iteration:  46
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.00it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.950910242291995
The final epsilon delta values after the training is over:  (4.950910242291995, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7068965517241379, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:31, 10.21s/it] 20%|██        | 2/10 [00:21<01:24, 10.59s/it] 30%|███       | 3/10 [00:31<01:13, 10.50s/it] 40%|████      | 4/10 [00:41<01:02, 10.40s/it] 50%|█████     | 5/10 [00:51<00:51, 10.32s/it] 60%|██████    | 6/10 [01:02<00:41, 10.28s/it] 70%|███████   | 7/10 [01:12<00:30, 10.26s/it] 80%|████████  | 8/10 [01:22<00:20, 10.26s/it] 90%|█████████ | 9/10 [01:33<00:10, 10.36s/it]100%|██████████| 10/10 [01:43<00:00, 10.35s/it]100%|██████████| 10/10 [01:43<00:00, 10.35s/it]
iteration:  47
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.77it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.950910242291995
The final epsilon delta values after the training is over:  (4.950910242291995, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7068965517241379, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:35, 10.58s/it] 20%|██        | 2/10 [00:20<01:23, 10.45s/it] 30%|███       | 3/10 [00:31<01:13, 10.43s/it] 40%|████      | 4/10 [00:41<01:02, 10.37s/it] 50%|█████     | 5/10 [00:51<00:51, 10.37s/it] 60%|██████    | 6/10 [01:02<00:41, 10.38s/it] 70%|███████   | 7/10 [01:12<00:31, 10.34s/it] 80%|████████  | 8/10 [01:22<00:20, 10.29s/it] 90%|█████████ | 9/10 [01:33<00:10, 10.27s/it]100%|██████████| 10/10 [01:43<00:00, 10.24s/it]100%|██████████| 10/10 [01:43<00:00, 10.32s/it]
iteration:  48
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.07it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.950910242291995
The final epsilon delta values after the training is over:  (4.950910242291995, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7068965517241379, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:31, 10.19s/it] 20%|██        | 2/10 [00:20<01:21, 10.24s/it] 30%|███       | 3/10 [00:30<01:12, 10.32s/it] 40%|████      | 4/10 [00:41<01:01, 10.32s/it] 50%|█████     | 5/10 [00:51<00:51, 10.30s/it] 60%|██████    | 6/10 [01:01<00:41, 10.29s/it] 70%|███████   | 7/10 [01:12<00:30, 10.32s/it] 80%|████████  | 8/10 [01:22<00:20, 10.33s/it] 90%|█████████ | 9/10 [01:32<00:10, 10.29s/it]100%|██████████| 10/10 [01:43<00:00, 10.32s/it]100%|██████████| 10/10 [01:43<00:00, 10.31s/it]
iteration:  49
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 44.31it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.950910242291995
The final epsilon delta values after the training is over:  (4.950910242291995, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7068965517241379, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:33, 10.40s/it] 20%|██        | 2/10 [00:20<01:22, 10.31s/it] 30%|███       | 3/10 [00:30<01:12, 10.31s/it] 40%|████      | 4/10 [00:41<01:01, 10.28s/it] 50%|█████     | 5/10 [00:51<00:51, 10.28s/it] 60%|██████    | 6/10 [01:02<00:41, 10.48s/it] 70%|███████   | 7/10 [01:12<00:31, 10.51s/it] 80%|████████  | 8/10 [01:23<00:20, 10.45s/it] 90%|█████████ | 9/10 [01:33<00:10, 10.41s/it]100%|██████████| 10/10 [01:44<00:00, 10.43s/it]100%|██████████| 10/10 [01:44<00:00, 10.40s/it]
iteration:  50
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.75it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.950910242291995
The final epsilon delta values after the training is over:  (4.950910242291995, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7068965517241379, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:33, 10.35s/it] 20%|██        | 2/10 [00:20<01:22, 10.27s/it] 30%|███       | 3/10 [00:30<01:11, 10.27s/it] 40%|████      | 4/10 [00:41<01:01, 10.25s/it] 50%|█████     | 5/10 [00:51<00:51, 10.25s/it] 60%|██████    | 6/10 [01:01<00:41, 10.31s/it] 70%|███████   | 7/10 [01:12<00:30, 10.32s/it] 80%|████████  | 8/10 [01:22<00:20, 10.31s/it] 90%|█████████ | 9/10 [01:32<00:10, 10.30s/it]100%|██████████| 10/10 [01:43<00:00, 10.38s/it]100%|██████████| 10/10 [01:43<00:00, 10.32s/it]
iteration:  51
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.95it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.390909639865212
The final epsilon delta values after the training is over:  (4.390909639865212, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7586206896551724, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:34, 10.46s/it] 20%|██        | 2/10 [00:20<01:22, 10.35s/it] 30%|███       | 3/10 [00:31<01:12, 10.32s/it] 40%|████      | 4/10 [00:41<01:02, 10.42s/it] 50%|█████     | 5/10 [00:51<00:51, 10.36s/it] 60%|██████    | 6/10 [01:02<00:41, 10.41s/it] 70%|███████   | 7/10 [01:12<00:31, 10.38s/it] 80%|████████  | 8/10 [01:23<00:20, 10.47s/it] 90%|█████████ | 9/10 [01:34<00:10, 10.61s/it]100%|██████████| 10/10 [01:44<00:00, 10.58s/it]100%|██████████| 10/10 [01:44<00:00, 10.48s/it]
iteration:  52
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.35it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.390909639865212
The final epsilon delta values after the training is over:  (4.390909639865212, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7586206896551724, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:33, 10.37s/it] 20%|██        | 2/10 [00:20<01:22, 10.32s/it] 30%|███       | 3/10 [00:31<01:12, 10.41s/it] 40%|████      | 4/10 [00:41<01:02, 10.38s/it] 50%|█████     | 5/10 [00:52<00:52, 10.42s/it] 60%|██████    | 6/10 [01:02<00:41, 10.39s/it] 70%|███████   | 7/10 [01:12<00:31, 10.36s/it] 80%|████████  | 8/10 [01:22<00:20, 10.36s/it] 90%|█████████ | 9/10 [01:33<00:10, 10.35s/it]100%|██████████| 10/10 [01:43<00:00, 10.34s/it]100%|██████████| 10/10 [01:43<00:00, 10.36s/it]
iteration:  53
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.03it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.390909639865212
The final epsilon delta values after the training is over:  (4.390909639865212, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7586206896551724, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:34, 10.46s/it] 20%|██        | 2/10 [00:21<01:24, 10.60s/it] 30%|███       | 3/10 [00:31<01:13, 10.50s/it] 40%|████      | 4/10 [00:41<01:02, 10.43s/it] 50%|█████     | 5/10 [00:52<00:52, 10.43s/it] 60%|██████    | 6/10 [01:02<00:41, 10.49s/it] 70%|███████   | 7/10 [01:13<00:31, 10.47s/it] 80%|████████  | 8/10 [01:23<00:20, 10.46s/it] 90%|█████████ | 9/10 [01:34<00:10, 10.43s/it]100%|██████████| 10/10 [01:44<00:00, 10.42s/it]100%|██████████| 10/10 [01:44<00:00, 10.45s/it]
iteration:  54
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 42.96it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.390909639865212
The final epsilon delta values after the training is over:  (4.390909639865212, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7586206896551724, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:32, 10.33s/it] 20%|██        | 2/10 [00:20<01:23, 10.39s/it] 30%|███       | 3/10 [00:31<01:12, 10.41s/it] 40%|████      | 4/10 [00:41<01:02, 10.38s/it] 50%|█████     | 5/10 [00:51<00:51, 10.37s/it] 60%|██████    | 6/10 [01:02<00:41, 10.35s/it] 70%|███████   | 7/10 [01:12<00:31, 10.38s/it] 80%|████████  | 8/10 [01:22<00:20, 10.36s/it] 90%|█████████ | 9/10 [01:33<00:10, 10.37s/it]100%|██████████| 10/10 [01:43<00:00, 10.37s/it]100%|██████████| 10/10 [01:43<00:00, 10.37s/it]
iteration:  55
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.33it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.390909639865212
The final epsilon delta values after the training is over:  (4.390909639865212, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7586206896551724, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:34, 10.51s/it] 20%|██        | 2/10 [00:20<01:23, 10.48s/it] 30%|███       | 3/10 [00:31<01:13, 10.52s/it] 40%|████      | 4/10 [00:42<01:03, 10.50s/it] 50%|█████     | 5/10 [00:52<00:52, 10.51s/it] 60%|██████    | 6/10 [01:03<00:42, 10.55s/it] 70%|███████   | 7/10 [01:13<00:31, 10.51s/it] 80%|████████  | 8/10 [01:24<00:21, 10.54s/it] 90%|█████████ | 9/10 [01:34<00:10, 10.50s/it]100%|██████████| 10/10 [01:45<00:00, 10.52s/it]100%|██████████| 10/10 [01:45<00:00, 10.52s/it]
iteration:  56
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.10it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.390909639865212
The final epsilon delta values after the training is over:  (4.390909639865212, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7586206896551724, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:35, 10.66s/it] 20%|██        | 2/10 [00:21<01:23, 10.50s/it] 30%|███       | 3/10 [00:31<01:13, 10.48s/it] 40%|████      | 4/10 [00:41<01:02, 10.45s/it] 50%|█████     | 5/10 [00:52<00:52, 10.48s/it] 60%|██████    | 6/10 [01:02<00:41, 10.47s/it] 70%|███████   | 7/10 [01:13<00:31, 10.46s/it] 80%|████████  | 8/10 [01:23<00:20, 10.47s/it] 90%|█████████ | 9/10 [01:34<00:10, 10.44s/it]100%|██████████| 10/10 [01:44<00:00, 10.41s/it]100%|██████████| 10/10 [01:44<00:00, 10.45s/it]
iteration:  57
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.20it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.390909639865212
The final epsilon delta values after the training is over:  (4.390909639865212, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7586206896551724, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:35, 10.61s/it] 20%|██        | 2/10 [00:21<01:24, 10.56s/it] 30%|███       | 3/10 [00:31<01:13, 10.49s/it] 40%|████      | 4/10 [00:42<01:03, 10.62s/it] 50%|█████     | 5/10 [00:52<00:52, 10.59s/it] 60%|██████    | 6/10 [01:03<00:42, 10.52s/it] 70%|███████   | 7/10 [01:13<00:31, 10.50s/it] 80%|████████  | 8/10 [01:24<00:20, 10.47s/it] 90%|█████████ | 9/10 [01:34<00:10, 10.45s/it]100%|██████████| 10/10 [01:44<00:00, 10.44s/it]100%|██████████| 10/10 [01:44<00:00, 10.50s/it]
iteration:  58
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.28it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.390909639865212
The final epsilon delta values after the training is over:  (4.390909639865212, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7586206896551724, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:33, 10.43s/it] 20%|██        | 2/10 [00:20<01:23, 10.43s/it] 30%|███       | 3/10 [00:31<01:13, 10.55s/it] 40%|████      | 4/10 [00:41<01:02, 10.49s/it] 50%|█████     | 5/10 [00:52<00:52, 10.44s/it] 60%|██████    | 6/10 [01:02<00:41, 10.41s/it] 70%|███████   | 7/10 [01:13<00:31, 10.53s/it] 80%|████████  | 8/10 [01:24<00:21, 10.55s/it] 90%|█████████ | 9/10 [01:34<00:10, 10.52s/it]100%|██████████| 10/10 [01:45<00:00, 10.54s/it]100%|██████████| 10/10 [01:45<00:00, 10.51s/it]
iteration:  59
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.71it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.390909639865212
The final epsilon delta values after the training is over:  (4.390909639865212, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7586206896551724, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:34, 10.46s/it] 20%|██        | 2/10 [00:21<01:25, 10.73s/it] 30%|███       | 3/10 [00:31<01:14, 10.61s/it] 40%|████      | 4/10 [00:42<01:03, 10.53s/it] 50%|█████     | 5/10 [00:52<00:52, 10.47s/it] 60%|██████    | 6/10 [01:03<00:42, 10.55s/it] 70%|███████   | 7/10 [01:14<00:31, 10.59s/it] 80%|████████  | 8/10 [01:24<00:21, 10.55s/it] 90%|█████████ | 9/10 [01:34<00:10, 10.53s/it]100%|██████████| 10/10 [01:45<00:00, 10.52s/it]100%|██████████| 10/10 [01:45<00:00, 10.54s/it]
iteration:  60
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 43.78it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.390909639865212
The final epsilon delta values after the training is over:  (4.390909639865212, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7586206896551724, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:34, 10.47s/it] 20%|██        | 2/10 [00:20<01:23, 10.44s/it] 30%|███       | 3/10 [00:31<01:13, 10.48s/it] 40%|████      | 4/10 [00:42<01:03, 10.52s/it] 50%|█████     | 5/10 [00:52<00:52, 10.54s/it] 60%|██████    | 6/10 [01:02<00:41, 10.49s/it] 70%|███████   | 7/10 [01:13<00:31, 10.47s/it] 80%|████████  | 8/10 [01:23<00:20, 10.47s/it] 90%|█████████ | 9/10 [01:34<00:10, 10.55s/it]100%|██████████| 10/10 [01:45<00:00, 10.52s/it]100%|██████████| 10/10 [01:45<00:00, 10.50s/it]
iteration:  61
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.14it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.5508920214596684
The final epsilon delta values after the training is over:  (3.5508920214596684, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8103448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:34, 10.50s/it] 20%|██        | 2/10 [00:21<01:24, 10.58s/it] 30%|███       | 3/10 [00:31<01:14, 10.60s/it] 40%|████      | 4/10 [00:42<01:03, 10.56s/it] 50%|█████     | 5/10 [00:52<00:52, 10.56s/it] 60%|██████    | 6/10 [01:03<00:42, 10.53s/it] 70%|███████   | 7/10 [01:13<00:31, 10.55s/it] 80%|████████  | 8/10 [01:24<00:21, 10.58s/it] 90%|█████████ | 9/10 [01:34<00:10, 10.54s/it]100%|██████████| 10/10 [01:45<00:00, 10.68s/it]100%|██████████| 10/10 [01:45<00:00, 10.60s/it]
iteration:  62
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 43.50it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.5508920214596684
The final epsilon delta values after the training is over:  (3.5508920214596684, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8103448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:34, 10.51s/it] 20%|██        | 2/10 [00:21<01:24, 10.57s/it] 30%|███       | 3/10 [00:31<01:14, 10.60s/it] 40%|████      | 4/10 [00:42<01:03, 10.56s/it] 50%|█████     | 5/10 [00:52<00:52, 10.54s/it] 60%|██████    | 6/10 [01:03<00:42, 10.52s/it] 70%|███████   | 7/10 [01:13<00:31, 10.51s/it] 80%|████████  | 8/10 [01:24<00:21, 10.50s/it] 90%|█████████ | 9/10 [01:34<00:10, 10.51s/it]100%|██████████| 10/10 [01:45<00:00, 10.55s/it]100%|██████████| 10/10 [01:45<00:00, 10.54s/it]
iteration:  63
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.53it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.5508920214596684
The final epsilon delta values after the training is over:  (3.5508920214596684, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8103448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:35, 10.61s/it] 20%|██        | 2/10 [00:21<01:26, 10.84s/it] 30%|███       | 3/10 [00:32<01:14, 10.69s/it] 40%|████      | 4/10 [00:42<01:04, 10.69s/it] 50%|█████     | 5/10 [00:53<00:53, 10.68s/it] 60%|██████    | 6/10 [01:04<00:42, 10.65s/it] 70%|███████   | 7/10 [01:14<00:31, 10.59s/it] 80%|████████  | 8/10 [01:24<00:21, 10.55s/it] 90%|█████████ | 9/10 [01:35<00:10, 10.59s/it]100%|██████████| 10/10 [01:46<00:00, 10.58s/it]100%|██████████| 10/10 [01:46<00:00, 10.62s/it]
iteration:  64
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.99it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.5508920214596684
The final epsilon delta values after the training is over:  (3.5508920214596684, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8103448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:36, 10.69s/it] 20%|██        | 2/10 [00:21<01:24, 10.58s/it] 30%|███       | 3/10 [00:31<01:13, 10.54s/it] 40%|████      | 4/10 [00:42<01:03, 10.51s/it] 50%|█████     | 5/10 [00:52<00:52, 10.60s/it] 60%|██████    | 6/10 [01:03<00:42, 10.61s/it] 70%|███████   | 7/10 [01:14<00:31, 10.66s/it] 80%|████████  | 8/10 [01:24<00:21, 10.65s/it] 90%|█████████ | 9/10 [01:35<00:10, 10.62s/it]100%|██████████| 10/10 [01:46<00:00, 10.62s/it]100%|██████████| 10/10 [01:46<00:00, 10.61s/it]
iteration:  65
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.90it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.5508920214596684
The final epsilon delta values after the training is over:  (3.5508920214596684, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8103448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:35, 10.63s/it] 20%|██        | 2/10 [00:21<01:25, 10.68s/it] 30%|███       | 3/10 [00:31<01:14, 10.61s/it] 40%|████      | 4/10 [00:42<01:03, 10.58s/it] 50%|█████     | 5/10 [00:52<00:52, 10.56s/it] 60%|██████    | 6/10 [01:03<00:42, 10.62s/it] 70%|███████   | 7/10 [01:14<00:32, 10.68s/it] 80%|████████  | 8/10 [01:25<00:21, 10.73s/it] 90%|█████████ | 9/10 [01:35<00:10, 10.69s/it]100%|██████████| 10/10 [01:46<00:00, 10.68s/it]100%|██████████| 10/10 [01:46<00:00, 10.66s/it]
iteration:  66
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 43.54it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.5508920214596684
The final epsilon delta values after the training is over:  (3.5508920214596684, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8103448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:34, 10.55s/it] 20%|██        | 2/10 [00:21<01:25, 10.67s/it] 30%|███       | 3/10 [00:32<01:15, 10.72s/it] 40%|████      | 4/10 [00:42<01:03, 10.66s/it] 50%|█████     | 5/10 [00:53<00:53, 10.68s/it] 60%|██████    | 6/10 [01:04<00:42, 10.70s/it] 70%|███████   | 7/10 [01:14<00:31, 10.66s/it] 80%|████████  | 8/10 [01:25<00:21, 10.63s/it] 90%|█████████ | 9/10 [01:35<00:10, 10.63s/it]100%|██████████| 10/10 [01:46<00:00, 10.68s/it]100%|██████████| 10/10 [01:46<00:00, 10.67s/it]
iteration:  67
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.60it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.5508920214596684
The final epsilon delta values after the training is over:  (3.5508920214596684, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8103448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:38, 10.93s/it] 20%|██        | 2/10 [00:21<01:26, 10.84s/it] 30%|███       | 3/10 [00:32<01:15, 10.77s/it] 40%|████      | 4/10 [00:43<01:04, 10.73s/it] 50%|█████     | 5/10 [00:53<00:53, 10.74s/it] 60%|██████    | 6/10 [01:04<00:42, 10.69s/it] 70%|███████   | 7/10 [01:14<00:31, 10.66s/it] 80%|████████  | 8/10 [01:25<00:21, 10.64s/it] 90%|█████████ | 9/10 [01:36<00:10, 10.61s/it]100%|██████████| 10/10 [01:46<00:00, 10.68s/it]100%|██████████| 10/10 [01:46<00:00, 10.70s/it]
iteration:  68
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 42.91it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.5508920214596684
The final epsilon delta values after the training is over:  (3.5508920214596684, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8103448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:38, 10.94s/it] 20%|██        | 2/10 [00:21<01:26, 10.78s/it] 30%|███       | 3/10 [00:32<01:15, 10.74s/it] 40%|████      | 4/10 [00:42<01:04, 10.72s/it] 50%|█████     | 5/10 [00:53<00:53, 10.69s/it] 60%|██████    | 6/10 [01:04<00:42, 10.65s/it] 70%|███████   | 7/10 [01:14<00:31, 10.62s/it] 80%|████████  | 8/10 [01:25<00:21, 10.60s/it] 90%|█████████ | 9/10 [01:36<00:10, 10.68s/it]100%|██████████| 10/10 [01:46<00:00, 10.66s/it]100%|██████████| 10/10 [01:46<00:00, 10.68s/it]
iteration:  69
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.33it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.5508920214596684
The final epsilon delta values after the training is over:  (3.5508920214596684, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8103448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:36, 10.70s/it] 20%|██        | 2/10 [00:21<01:25, 10.67s/it] 30%|███       | 3/10 [00:32<01:15, 10.72s/it] 40%|████      | 4/10 [00:42<01:04, 10.68s/it] 50%|█████     | 5/10 [00:53<00:53, 10.69s/it] 60%|██████    | 6/10 [01:04<00:42, 10.72s/it] 70%|███████   | 7/10 [01:14<00:31, 10.66s/it] 80%|████████  | 8/10 [01:25<00:21, 10.71s/it] 90%|█████████ | 9/10 [01:36<00:10, 10.80s/it]100%|██████████| 10/10 [01:51<00:00, 12.11s/it]100%|██████████| 10/10 [01:51<00:00, 11.16s/it]
iteration:  70
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.48it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.5508920214596684
The final epsilon delta values after the training is over:  (3.5508920214596684, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8103448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:53, 12.60s/it] 20%|██        | 2/10 [00:24<01:37, 12.20s/it] 30%|███       | 3/10 [00:35<01:22, 11.72s/it] 40%|████      | 4/10 [00:46<01:07, 11.28s/it] 50%|█████     | 5/10 [00:57<00:55, 11.16s/it] 60%|██████    | 6/10 [01:08<00:44, 11.10s/it] 70%|███████   | 7/10 [01:18<00:32, 10.95s/it] 80%|████████  | 8/10 [01:30<00:22, 11.09s/it] 90%|█████████ | 9/10 [01:41<00:11, 11.25s/it]100%|██████████| 10/10 [01:52<00:00, 11.10s/it]100%|██████████| 10/10 [01:52<00:00, 11.26s/it]
iteration:  71
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 42.31it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.136072318576378
The final epsilon delta values after the training is over:  (3.136072318576378, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8620689655172413, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.83s/it] 20%|██        | 2/10 [00:21<01:26, 10.79s/it] 30%|███       | 3/10 [00:32<01:14, 10.71s/it] 40%|████      | 4/10 [00:42<01:04, 10.72s/it] 50%|█████     | 5/10 [00:53<00:53, 10.74s/it] 60%|██████    | 6/10 [01:04<00:43, 10.76s/it] 70%|███████   | 7/10 [01:15<00:32, 10.76s/it] 80%|████████  | 8/10 [01:26<00:21, 10.75s/it] 90%|█████████ | 9/10 [01:36<00:10, 10.72s/it]100%|██████████| 10/10 [01:47<00:00, 10.72s/it]100%|██████████| 10/10 [01:47<00:00, 10.74s/it]
iteration:  72
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 43.06it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.136072318576378
The final epsilon delta values after the training is over:  (3.136072318576378, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8620689655172413, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:40, 11.16s/it] 20%|██        | 2/10 [00:21<01:27, 10.97s/it] 30%|███       | 3/10 [00:32<01:16, 10.93s/it] 40%|████      | 4/10 [00:43<01:05, 10.89s/it] 50%|█████     | 5/10 [00:54<00:54, 10.82s/it] 60%|██████    | 6/10 [01:05<00:43, 10.76s/it] 70%|███████   | 7/10 [01:15<00:32, 10.73s/it] 80%|████████  | 8/10 [01:26<00:21, 10.72s/it] 90%|█████████ | 9/10 [01:37<00:10, 10.75s/it]100%|██████████| 10/10 [01:47<00:00, 10.72s/it]100%|██████████| 10/10 [01:47<00:00, 10.79s/it]
iteration:  73
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.79it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.136072318576378
The final epsilon delta values after the training is over:  (3.136072318576378, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8620689655172413, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:36, 10.74s/it] 20%|██        | 2/10 [00:21<01:25, 10.75s/it] 30%|███       | 3/10 [00:32<01:15, 10.76s/it] 40%|████      | 4/10 [00:42<01:04, 10.72s/it] 50%|█████     | 5/10 [00:53<00:53, 10.78s/it] 60%|██████    | 6/10 [01:04<00:43, 10.78s/it] 70%|███████   | 7/10 [01:15<00:32, 10.74s/it] 80%|████████  | 8/10 [01:25<00:21, 10.73s/it] 90%|█████████ | 9/10 [01:36<00:10, 10.72s/it]100%|██████████| 10/10 [01:47<00:00, 10.74s/it]100%|██████████| 10/10 [01:47<00:00, 10.74s/it]
iteration:  74
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.51it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.136072318576378
The final epsilon delta values after the training is over:  (3.136072318576378, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8620689655172413, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.81s/it] 20%|██        | 2/10 [00:21<01:26, 10.80s/it] 30%|███       | 3/10 [00:32<01:15, 10.76s/it] 40%|████      | 4/10 [00:43<01:05, 10.86s/it] 50%|█████     | 5/10 [00:55<00:55, 11.16s/it] 60%|██████    | 6/10 [01:06<00:44, 11.10s/it] 70%|███████   | 7/10 [01:16<00:32, 10.98s/it] 80%|████████  | 8/10 [01:27<00:21, 10.95s/it] 90%|█████████ | 9/10 [01:38<00:10, 10.91s/it]100%|██████████| 10/10 [01:49<00:00, 10.85s/it]100%|██████████| 10/10 [01:49<00:00, 10.92s/it]
iteration:  75
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.07it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.136072318576378
The final epsilon delta values after the training is over:  (3.136072318576378, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8620689655172413, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:39, 11.01s/it] 20%|██        | 2/10 [00:21<01:26, 10.82s/it] 30%|███       | 3/10 [00:32<01:15, 10.77s/it] 40%|████      | 4/10 [00:43<01:05, 10.89s/it] 50%|█████     | 5/10 [00:54<00:54, 10.85s/it] 60%|██████    | 6/10 [01:05<00:43, 10.88s/it] 70%|███████   | 7/10 [01:15<00:32, 10.82s/it] 80%|████████  | 8/10 [01:26<00:21, 10.79s/it] 90%|█████████ | 9/10 [01:37<00:10, 10.77s/it]100%|██████████| 10/10 [01:48<00:00, 10.77s/it]100%|██████████| 10/10 [01:48<00:00, 10.81s/it]
iteration:  76
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 42.75it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.136072318576378
The final epsilon delta values after the training is over:  (3.136072318576378, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8620689655172413, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.82s/it] 20%|██        | 2/10 [00:21<01:26, 10.77s/it] 30%|███       | 3/10 [00:32<01:15, 10.82s/it] 40%|████      | 4/10 [00:43<01:05, 10.87s/it] 50%|█████     | 5/10 [00:54<00:54, 10.87s/it] 60%|██████    | 6/10 [01:05<00:43, 10.86s/it] 70%|███████   | 7/10 [01:16<00:32, 10.89s/it] 80%|████████  | 8/10 [01:26<00:21, 10.88s/it] 90%|█████████ | 9/10 [01:37<00:10, 10.88s/it]100%|██████████| 10/10 [01:48<00:00, 10.91s/it]100%|██████████| 10/10 [01:48<00:00, 10.87s/it]
iteration:  77
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.26it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.136072318576378
The final epsilon delta values after the training is over:  (3.136072318576378, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8620689655172413, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:38, 10.96s/it] 20%|██        | 2/10 [00:21<01:26, 10.82s/it] 30%|███       | 3/10 [00:32<01:15, 10.81s/it] 40%|████      | 4/10 [00:43<01:05, 10.88s/it] 50%|█████     | 5/10 [00:54<00:54, 10.88s/it] 60%|██████    | 6/10 [01:05<00:43, 10.87s/it] 70%|███████   | 7/10 [01:16<00:32, 10.86s/it] 80%|████████  | 8/10 [01:26<00:21, 10.84s/it] 90%|█████████ | 9/10 [01:37<00:10, 10.85s/it]100%|██████████| 10/10 [01:48<00:00, 10.88s/it]100%|██████████| 10/10 [01:48<00:00, 10.86s/it]
iteration:  78
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.80it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.136072318576378
The final epsilon delta values after the training is over:  (3.136072318576378, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8620689655172413, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.89s/it] 20%|██        | 2/10 [00:21<01:26, 10.82s/it] 30%|███       | 3/10 [00:32<01:15, 10.79s/it] 40%|████      | 4/10 [00:43<01:04, 10.80s/it] 50%|█████     | 5/10 [00:54<00:54, 10.83s/it] 60%|██████    | 6/10 [01:05<00:43, 10.94s/it] 70%|███████   | 7/10 [01:16<00:32, 10.89s/it] 80%|████████  | 8/10 [01:26<00:21, 10.88s/it] 90%|█████████ | 9/10 [01:37<00:10, 10.85s/it]100%|██████████| 10/10 [01:48<00:00, 10.83s/it]100%|██████████| 10/10 [01:48<00:00, 10.85s/it]
iteration:  79
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.73it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.136072318576378
The final epsilon delta values after the training is over:  (3.136072318576378, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8620689655172413, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:39, 11.04s/it] 20%|██        | 2/10 [00:22<01:28, 11.02s/it] 30%|███       | 3/10 [00:32<01:16, 10.94s/it] 40%|████      | 4/10 [00:43<01:05, 10.92s/it] 50%|█████     | 5/10 [00:54<00:54, 10.97s/it] 60%|██████    | 6/10 [01:05<00:43, 10.98s/it] 70%|███████   | 7/10 [01:16<00:32, 10.93s/it] 80%|████████  | 8/10 [01:27<00:21, 10.92s/it] 90%|█████████ | 9/10 [01:38<00:10, 10.91s/it]100%|██████████| 10/10 [01:49<00:00, 10.92s/it]100%|██████████| 10/10 [01:49<00:00, 10.94s/it]
iteration:  80
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.01it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.136072318576378
The final epsilon delta values after the training is over:  (3.136072318576378, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8620689655172413, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:38, 10.95s/it] 20%|██        | 2/10 [00:21<01:27, 10.89s/it] 30%|███       | 3/10 [00:32<01:16, 10.93s/it] 40%|████      | 4/10 [00:43<01:05, 10.99s/it] 50%|█████     | 5/10 [00:54<00:54, 10.94s/it] 60%|██████    | 6/10 [01:05<00:43, 10.89s/it] 70%|███████   | 7/10 [01:16<00:32, 10.92s/it] 80%|████████  | 8/10 [01:27<00:21, 10.91s/it] 90%|█████████ | 9/10 [01:38<00:10, 10.90s/it]100%|██████████| 10/10 [01:49<00:00, 10.91s/it]100%|██████████| 10/10 [01:49<00:00, 10.92s/it]
iteration:  81
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.21it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.7525821481728774
The final epsilon delta values after the training is over:  (2.7525821481728774, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9137931034482758, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:39, 11.03s/it] 20%|██        | 2/10 [00:21<01:27, 10.97s/it] 30%|███       | 3/10 [00:32<01:16, 10.89s/it] 40%|████      | 4/10 [00:43<01:05, 10.85s/it] 50%|█████     | 5/10 [00:54<00:54, 10.85s/it] 60%|██████    | 6/10 [01:05<00:43, 10.84s/it] 70%|███████   | 7/10 [01:16<00:32, 10.94s/it] 80%|████████  | 8/10 [01:27<00:21, 10.97s/it] 90%|█████████ | 9/10 [01:38<00:10, 10.99s/it]100%|██████████| 10/10 [01:49<00:00, 11.00s/it]100%|██████████| 10/10 [01:49<00:00, 10.95s/it]
iteration:  82
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.59it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.7525821481728774
The final epsilon delta values after the training is over:  (2.7525821481728774, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9137931034482758, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:39, 11.05s/it] 20%|██        | 2/10 [00:21<01:27, 10.95s/it] 30%|███       | 3/10 [00:32<01:16, 10.93s/it] 40%|████      | 4/10 [00:43<01:05, 10.95s/it] 50%|█████     | 5/10 [00:54<00:54, 10.99s/it] 60%|██████    | 6/10 [01:06<00:44, 11.04s/it] 70%|███████   | 7/10 [01:17<00:33, 11.20s/it] 80%|████████  | 8/10 [01:28<00:22, 11.15s/it] 90%|█████████ | 9/10 [01:39<00:11, 11.13s/it]100%|██████████| 10/10 [01:50<00:00, 11.13s/it]100%|██████████| 10/10 [01:50<00:00, 11.08s/it]
iteration:  83
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.00it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.7525821481728774
The final epsilon delta values after the training is over:  (2.7525821481728774, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9137931034482758, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:39, 11.03s/it] 20%|██        | 2/10 [00:21<01:27, 10.98s/it] 30%|███       | 3/10 [00:32<01:16, 10.94s/it] 40%|████      | 4/10 [00:43<01:06, 11.00s/it] 50%|█████     | 5/10 [00:54<00:54, 10.94s/it] 60%|██████    | 6/10 [01:05<00:43, 10.91s/it] 70%|███████   | 7/10 [01:16<00:32, 10.89s/it] 80%|████████  | 8/10 [01:27<00:21, 10.91s/it] 90%|█████████ | 9/10 [01:38<00:10, 10.89s/it]100%|██████████| 10/10 [01:49<00:00, 10.90s/it]100%|██████████| 10/10 [01:49<00:00, 10.92s/it]
iteration:  84
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 42.67it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.7525821481728774
The final epsilon delta values after the training is over:  (2.7525821481728774, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9137931034482758, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:38, 10.98s/it] 20%|██        | 2/10 [00:22<01:28, 11.10s/it] 30%|███       | 3/10 [00:33<01:17, 11.09s/it] 40%|████      | 4/10 [00:44<01:06, 11.02s/it] 50%|█████     | 5/10 [00:55<00:54, 10.98s/it] 60%|██████    | 6/10 [01:06<00:44, 11.05s/it] 70%|███████   | 7/10 [01:17<00:33, 11.03s/it] 80%|████████  | 8/10 [01:28<00:22, 11.01s/it] 90%|█████████ | 9/10 [01:39<00:10, 10.99s/it]100%|██████████| 10/10 [01:50<00:00, 10.97s/it]100%|██████████| 10/10 [01:50<00:00, 11.01s/it]
iteration:  85
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.99it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.7525821481728774
The final epsilon delta values after the training is over:  (2.7525821481728774, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9137931034482758, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:41, 11.23s/it] 20%|██        | 2/10 [00:22<01:28, 11.04s/it] 30%|███       | 3/10 [00:33<01:16, 10.97s/it] 40%|████      | 4/10 [00:43<01:05, 10.94s/it] 50%|█████     | 5/10 [00:54<00:54, 10.90s/it] 60%|██████    | 6/10 [01:06<00:44, 11.09s/it] 70%|███████   | 7/10 [01:17<00:33, 11.03s/it] 80%|████████  | 8/10 [01:28<00:22, 11.16s/it] 90%|█████████ | 9/10 [01:39<00:11, 11.14s/it]100%|██████████| 10/10 [01:50<00:00, 11.11s/it]100%|██████████| 10/10 [01:50<00:00, 11.07s/it]
iteration:  86
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.73it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.7525821481728774
The final epsilon delta values after the training is over:  (2.7525821481728774, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9137931034482758, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:39, 11.09s/it] 20%|██        | 2/10 [00:22<01:28, 11.01s/it] 30%|███       | 3/10 [00:33<01:17, 11.00s/it] 40%|████      | 4/10 [00:43<01:05, 10.96s/it] 50%|█████     | 5/10 [00:54<00:54, 10.96s/it] 60%|██████    | 6/10 [01:06<00:44, 11.11s/it] 70%|███████   | 7/10 [01:17<00:33, 11.05s/it] 80%|████████  | 8/10 [01:28<00:22, 11.00s/it] 90%|█████████ | 9/10 [01:39<00:10, 10.99s/it]100%|██████████| 10/10 [01:50<00:00, 11.01s/it]100%|██████████| 10/10 [01:50<00:00, 11.01s/it]
iteration:  87
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.87it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.7525821481728774
The final epsilon delta values after the training is over:  (2.7525821481728774, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9137931034482758, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:39, 11.10s/it] 20%|██        | 2/10 [00:22<01:28, 11.06s/it] 30%|███       | 3/10 [00:33<01:16, 11.00s/it] 40%|████      | 4/10 [00:44<01:06, 11.07s/it] 50%|█████     | 5/10 [00:55<00:55, 11.07s/it] 60%|██████    | 6/10 [01:06<00:44, 11.05s/it] 70%|███████   | 7/10 [01:17<00:33, 11.14s/it] 80%|████████  | 8/10 [01:28<00:22, 11.10s/it] 90%|█████████ | 9/10 [01:39<00:11, 11.07s/it]100%|██████████| 10/10 [01:50<00:00, 11.05s/it]100%|██████████| 10/10 [01:50<00:00, 11.07s/it]
iteration:  88
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.20it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.7525821481728774
The final epsilon delta values after the training is over:  (2.7525821481728774, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9137931034482758, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:39, 11.03s/it] 20%|██        | 2/10 [00:21<01:27, 10.99s/it] 30%|███       | 3/10 [00:33<01:17, 11.07s/it] 40%|████      | 4/10 [00:44<01:06, 11.02s/it] 50%|█████     | 5/10 [00:55<00:54, 10.99s/it] 60%|██████    | 6/10 [01:06<00:44, 11.04s/it] 70%|███████   | 7/10 [01:17<00:33, 11.03s/it] 80%|████████  | 8/10 [01:28<00:22, 11.05s/it] 90%|█████████ | 9/10 [01:39<00:11, 11.03s/it]100%|██████████| 10/10 [01:50<00:00, 11.09s/it]100%|██████████| 10/10 [01:50<00:00, 11.05s/it]
iteration:  89
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.85it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.7525821481728774
The final epsilon delta values after the training is over:  (2.7525821481728774, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9137931034482758, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:39, 11.00s/it] 20%|██        | 2/10 [00:22<01:29, 11.14s/it] 30%|███       | 3/10 [00:33<01:17, 11.04s/it] 40%|████      | 4/10 [00:44<01:05, 11.00s/it] 50%|█████     | 5/10 [00:55<00:54, 10.99s/it] 60%|██████    | 6/10 [01:06<00:44, 11.04s/it] 70%|███████   | 7/10 [01:17<00:33, 11.12s/it] 80%|████████  | 8/10 [01:28<00:22, 11.13s/it] 90%|█████████ | 9/10 [01:39<00:11, 11.12s/it]100%|██████████| 10/10 [01:50<00:00, 11.10s/it]100%|██████████| 10/10 [01:50<00:00, 11.08s/it]
iteration:  90
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.85it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.7525821481728774
The final epsilon delta values after the training is over:  (2.7525821481728774, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9137931034482758, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:40, 11.20s/it] 20%|██        | 2/10 [00:22<01:29, 11.14s/it] 30%|███       | 3/10 [00:33<01:17, 11.13s/it] 40%|████      | 4/10 [00:44<01:06, 11.10s/it] 50%|█████     | 5/10 [00:55<00:55, 11.09s/it] 60%|██████    | 6/10 [01:06<00:44, 11.07s/it] 70%|███████   | 7/10 [01:17<00:33, 11.04s/it] 80%|████████  | 8/10 [01:28<00:22, 11.04s/it] 90%|█████████ | 9/10 [01:39<00:11, 11.02s/it]100%|██████████| 10/10 [01:50<00:00, 11.09s/it]100%|██████████| 10/10 [01:50<00:00, 11.08s/it]
iteration:  91
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.37it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.3962381625999214
The final epsilon delta values after the training is over:  (2.3962381625999214, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9655172413793103, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:40, 11.14s/it] 20%|██        | 2/10 [00:22<01:29, 11.13s/it] 30%|███       | 3/10 [00:33<01:17, 11.07s/it] 40%|████      | 4/10 [00:44<01:06, 11.10s/it] 50%|█████     | 5/10 [00:55<00:55, 11.17s/it] 60%|██████    | 6/10 [01:06<00:44, 11.10s/it] 70%|███████   | 7/10 [01:17<00:33, 11.07s/it] 80%|████████  | 8/10 [01:28<00:22, 11.06s/it] 90%|█████████ | 9/10 [01:39<00:11, 11.10s/it]100%|██████████| 10/10 [01:51<00:00, 11.12s/it]100%|██████████| 10/10 [01:51<00:00, 11.11s/it]
iteration:  92
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.87it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.3962381625999214
The final epsilon delta values after the training is over:  (2.3962381625999214, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9655172413793103, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:40, 11.20s/it] 20%|██        | 2/10 [00:22<01:29, 11.19s/it] 30%|███       | 3/10 [00:33<01:18, 11.15s/it] 40%|████      | 4/10 [00:44<01:06, 11.12s/it] 50%|█████     | 5/10 [00:55<00:55, 11.11s/it] 60%|██████    | 6/10 [01:06<00:44, 11.12s/it] 70%|███████   | 7/10 [01:17<00:33, 11.14s/it] 80%|████████  | 8/10 [01:29<00:22, 11.14s/it] 90%|█████████ | 9/10 [01:40<00:11, 11.14s/it]100%|██████████| 10/10 [01:51<00:00, 11.18s/it]100%|██████████| 10/10 [01:51<00:00, 11.15s/it]
iteration:  93
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.81it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.3962381625999214
The final epsilon delta values after the training is over:  (2.3962381625999214, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9655172413793103, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:40, 11.11s/it] 20%|██        | 2/10 [00:22<01:29, 11.14s/it] 30%|███       | 3/10 [00:33<01:17, 11.11s/it] 40%|████      | 4/10 [00:44<01:06, 11.10s/it] 50%|█████     | 5/10 [00:55<00:55, 11.07s/it] 60%|██████    | 6/10 [01:06<00:44, 11.10s/it] 70%|███████   | 7/10 [01:17<00:33, 11.12s/it] 80%|████████  | 8/10 [01:28<00:22, 11.12s/it] 90%|█████████ | 9/10 [01:39<00:11, 11.09s/it]100%|██████████| 10/10 [01:51<00:00, 11.15s/it]100%|██████████| 10/10 [01:51<00:00, 11.12s/it]
iteration:  94
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 42.43it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.3962381625999214
The final epsilon delta values after the training is over:  (2.3962381625999214, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9655172413793103, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.35s/it] 20%|██        | 2/10 [00:22<01:30, 11.29s/it] 30%|███       | 3/10 [00:33<01:18, 11.23s/it] 40%|████      | 4/10 [00:44<01:07, 11.18s/it] 50%|█████     | 5/10 [00:55<00:55, 11.14s/it] 60%|██████    | 6/10 [01:06<00:44, 11.12s/it] 70%|███████   | 7/10 [01:18<00:33, 11.10s/it] 80%|████████  | 8/10 [01:29<00:22, 11.14s/it] 90%|█████████ | 9/10 [01:40<00:11, 11.21s/it]100%|██████████| 10/10 [01:51<00:00, 11.21s/it]100%|██████████| 10/10 [01:51<00:00, 11.19s/it]
iteration:  95
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.43it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.3962381625999214
The final epsilon delta values after the training is over:  (2.3962381625999214, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9655172413793103, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:39, 11.10s/it] 20%|██        | 2/10 [00:22<01:28, 11.10s/it] 30%|███       | 3/10 [00:33<01:17, 11.13s/it] 40%|████      | 4/10 [00:44<01:07, 11.22s/it] 50%|█████     | 5/10 [00:55<00:56, 11.22s/it] 60%|██████    | 6/10 [01:07<00:44, 11.19s/it] 70%|███████   | 7/10 [01:18<00:33, 11.18s/it] 80%|████████  | 8/10 [01:29<00:22, 11.26s/it] 90%|█████████ | 9/10 [01:40<00:11, 11.23s/it]100%|██████████| 10/10 [01:51<00:00, 11.20s/it]100%|██████████| 10/10 [01:51<00:00, 11.20s/it]
iteration:  96
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 41.92it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.3962381625999214
The final epsilon delta values after the training is over:  (2.3962381625999214, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9655172413793103, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:40, 11.19s/it] 20%|██        | 2/10 [00:22<01:30, 11.28s/it] 30%|███       | 3/10 [00:33<01:18, 11.27s/it] 40%|████      | 4/10 [00:45<01:07, 11.26s/it] 50%|█████     | 5/10 [00:56<00:56, 11.31s/it] 60%|██████    | 6/10 [01:07<00:45, 11.25s/it] 70%|███████   | 7/10 [01:18<00:33, 11.19s/it] 80%|████████  | 8/10 [01:29<00:22, 11.16s/it] 90%|█████████ | 9/10 [01:41<00:11, 11.19s/it]100%|██████████| 10/10 [01:52<00:00, 11.21s/it]100%|██████████| 10/10 [01:52<00:00, 11.23s/it]
iteration:  97
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.03it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.3962381625999214
The final epsilon delta values after the training is over:  (2.3962381625999214, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9655172413793103, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:41, 11.26s/it] 20%|██        | 2/10 [00:22<01:29, 11.22s/it] 30%|███       | 3/10 [00:33<01:18, 11.16s/it] 40%|████      | 4/10 [00:44<01:07, 11.22s/it] 50%|█████     | 5/10 [00:56<00:56, 11.22s/it] 60%|██████    | 6/10 [01:07<00:44, 11.21s/it] 70%|███████   | 7/10 [01:18<00:33, 11.28s/it] 80%|████████  | 8/10 [01:29<00:22, 11.26s/it] 90%|█████████ | 9/10 [01:41<00:11, 11.28s/it]100%|██████████| 10/10 [01:52<00:00, 11.24s/it]100%|██████████| 10/10 [01:52<00:00, 11.24s/it]
iteration:  98
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.98it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.3962381625999214
The final epsilon delta values after the training is over:  (2.3962381625999214, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9655172413793103, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:47, 11.90s/it] 20%|██        | 2/10 [00:23<01:32, 11.57s/it] 30%|███       | 3/10 [00:34<01:20, 11.44s/it] 40%|████      | 4/10 [00:45<01:08, 11.36s/it] 50%|█████     | 5/10 [00:56<00:56, 11.32s/it] 60%|██████    | 6/10 [01:08<00:45, 11.27s/it] 70%|███████   | 7/10 [01:19<00:33, 11.24s/it] 80%|████████  | 8/10 [01:30<00:22, 11.24s/it] 90%|█████████ | 9/10 [01:41<00:11, 11.25s/it]100%|██████████| 10/10 [01:53<00:00, 11.32s/it]100%|██████████| 10/10 [01:53<00:00, 11.34s/it]
iteration:  99
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.36it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.3962381625999214
The final epsilon delta values after the training is over:  (2.3962381625999214, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9655172413793103, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.38s/it] 20%|██        | 2/10 [00:23<01:32, 11.58s/it] 30%|███       | 3/10 [00:34<01:19, 11.41s/it] 40%|████      | 4/10 [00:45<01:08, 11.38s/it] 50%|█████     | 5/10 [00:56<00:56, 11.34s/it] 60%|██████    | 6/10 [01:08<00:45, 11.42s/it] 70%|███████   | 7/10 [01:19<00:34, 11.37s/it] 80%|████████  | 8/10 [01:30<00:22, 11.31s/it] 90%|█████████ | 9/10 [01:42<00:11, 11.30s/it]100%|██████████| 10/10 [01:53<00:00, 11.30s/it]100%|██████████| 10/10 [01:53<00:00, 11.35s/it]
iteration:  100
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.50it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.3962381625999214
The final epsilon delta values after the training is over:  (2.3962381625999214, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9655172413793103, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:43, 11.44s/it] 20%|██        | 2/10 [00:22<01:30, 11.36s/it] 30%|███       | 3/10 [00:34<01:19, 11.33s/it] 40%|████      | 4/10 [00:45<01:07, 11.31s/it] 50%|█████     | 5/10 [00:56<00:56, 11.32s/it] 60%|██████    | 6/10 [01:07<00:45, 11.31s/it] 70%|███████   | 7/10 [01:19<00:33, 11.32s/it] 80%|████████  | 8/10 [01:30<00:22, 11.28s/it] 90%|█████████ | 9/10 [01:41<00:11, 11.27s/it]100%|██████████| 10/10 [01:52<00:00, 11.25s/it]100%|██████████| 10/10 [01:52<00:00, 11.29s/it]
iteration:  101
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 41.73it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.143529429767139
The final epsilon delta values after the training is over:  (2.143529429767139, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0172413793103448, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.35s/it] 20%|██        | 2/10 [00:22<01:30, 11.31s/it] 30%|███       | 3/10 [00:33<01:18, 11.26s/it] 40%|████      | 4/10 [00:45<01:07, 11.28s/it] 50%|█████     | 5/10 [00:56<00:56, 11.34s/it] 60%|██████    | 6/10 [01:07<00:45, 11.32s/it] 70%|███████   | 7/10 [01:19<00:33, 11.31s/it] 80%|████████  | 8/10 [01:30<00:22, 11.31s/it] 90%|█████████ | 9/10 [01:42<00:11, 11.38s/it]100%|██████████| 10/10 [01:53<00:00, 11.34s/it]100%|██████████| 10/10 [01:53<00:00, 11.33s/it]
iteration:  102
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.48it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.143529429767139
The final epsilon delta values after the training is over:  (2.143529429767139, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0172413793103448, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:41, 11.27s/it] 20%|██        | 2/10 [00:22<01:30, 11.29s/it] 30%|███       | 3/10 [00:33<01:18, 11.28s/it] 40%|████      | 4/10 [00:45<01:07, 11.30s/it] 50%|█████     | 5/10 [00:56<00:56, 11.29s/it] 60%|██████    | 6/10 [01:07<00:45, 11.29s/it] 70%|███████   | 7/10 [01:19<00:34, 11.34s/it] 80%|████████  | 8/10 [01:30<00:22, 11.37s/it] 90%|█████████ | 9/10 [01:41<00:11, 11.35s/it]100%|██████████| 10/10 [01:53<00:00, 11.32s/it]100%|██████████| 10/10 [01:53<00:00, 11.32s/it]
iteration:  103
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 41.96it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.143529429767139
The final epsilon delta values after the training is over:  (2.143529429767139, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0172413793103448, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:41, 11.33s/it] 20%|██        | 2/10 [00:22<01:32, 11.52s/it] 30%|███       | 3/10 [00:34<01:19, 11.39s/it] 40%|████      | 4/10 [00:45<01:07, 11.33s/it] 50%|█████     | 5/10 [00:56<00:56, 11.30s/it] 60%|██████    | 6/10 [01:07<00:45, 11.28s/it] 70%|███████   | 7/10 [01:19<00:33, 11.30s/it] 80%|████████  | 8/10 [01:30<00:22, 11.31s/it] 90%|█████████ | 9/10 [01:41<00:11, 11.32s/it]100%|██████████| 10/10 [01:53<00:00, 11.33s/it]100%|██████████| 10/10 [01:53<00:00, 11.33s/it]
iteration:  104
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.87it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.143529429767139
The final epsilon delta values after the training is over:  (2.143529429767139, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0172413793103448, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:41, 11.33s/it] 20%|██        | 2/10 [00:22<01:31, 11.42s/it] 30%|███       | 3/10 [00:34<01:19, 11.41s/it] 40%|████      | 4/10 [00:45<01:08, 11.41s/it] 50%|█████     | 5/10 [00:56<00:56, 11.36s/it] 60%|██████    | 6/10 [01:08<00:45, 11.34s/it] 70%|███████   | 7/10 [01:19<00:34, 11.37s/it] 80%|████████  | 8/10 [01:30<00:22, 11.34s/it] 90%|█████████ | 9/10 [01:42<00:11, 11.33s/it]100%|██████████| 10/10 [01:53<00:00, 11.37s/it]100%|██████████| 10/10 [01:53<00:00, 11.36s/it]
iteration:  105
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.60it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.143529429767139
The final epsilon delta values after the training is over:  (2.143529429767139, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0172413793103448, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:44, 11.58s/it] 20%|██        | 2/10 [00:23<01:34, 11.76s/it] 30%|███       | 3/10 [00:34<01:21, 11.62s/it] 40%|████      | 4/10 [00:46<01:09, 11.51s/it] 50%|█████     | 5/10 [00:57<00:57, 11.45s/it] 60%|██████    | 6/10 [01:09<00:45, 11.43s/it] 70%|███████   | 7/10 [01:20<00:34, 11.37s/it] 80%|████████  | 8/10 [01:31<00:22, 11.36s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.43s/it]100%|██████████| 10/10 [01:54<00:00, 11.45s/it]100%|██████████| 10/10 [01:54<00:00, 11.47s/it]
iteration:  106
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 41.56it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.143529429767139
The final epsilon delta values after the training is over:  (2.143529429767139, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0172413793103448, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:43, 11.50s/it] 20%|██        | 2/10 [00:22<01:31, 11.50s/it] 30%|███       | 3/10 [00:34<01:19, 11.42s/it] 40%|████      | 4/10 [00:45<01:08, 11.37s/it] 50%|█████     | 5/10 [00:56<00:56, 11.33s/it] 60%|██████    | 6/10 [01:08<00:45, 11.36s/it] 70%|███████   | 7/10 [01:19<00:34, 11.36s/it] 80%|████████  | 8/10 [01:31<00:22, 11.41s/it] 90%|█████████ | 9/10 [01:42<00:11, 11.44s/it]100%|██████████| 10/10 [01:54<00:00, 11.44s/it]100%|██████████| 10/10 [01:54<00:00, 11.41s/it]
iteration:  107
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 41.50it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.143529429767139
The final epsilon delta values after the training is over:  (2.143529429767139, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0172413793103448, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.36s/it] 20%|██        | 2/10 [00:22<01:31, 11.45s/it] 30%|███       | 3/10 [00:34<01:19, 11.41s/it] 40%|████      | 4/10 [00:45<01:08, 11.34s/it] 50%|█████     | 5/10 [00:56<00:56, 11.32s/it] 60%|██████    | 6/10 [01:08<00:45, 11.33s/it] 70%|███████   | 7/10 [01:19<00:33, 11.32s/it] 80%|████████  | 8/10 [01:31<00:22, 11.41s/it] 90%|█████████ | 9/10 [01:42<00:11, 11.40s/it]100%|██████████| 10/10 [01:53<00:00, 11.39s/it]100%|██████████| 10/10 [01:53<00:00, 11.37s/it]
iteration:  108
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 41.25it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.143529429767139
The final epsilon delta values after the training is over:  (2.143529429767139, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0172413793103448, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.41s/it] 20%|██        | 2/10 [00:22<01:31, 11.38s/it] 30%|███       | 3/10 [00:34<01:19, 11.41s/it] 40%|████      | 4/10 [00:45<01:08, 11.44s/it] 50%|█████     | 5/10 [00:57<00:57, 11.49s/it] 60%|██████    | 6/10 [01:08<00:45, 11.46s/it] 70%|███████   | 7/10 [01:20<00:34, 11.43s/it] 80%|████████  | 8/10 [01:31<00:22, 11.43s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.49s/it]100%|██████████| 10/10 [01:54<00:00, 11.48s/it]100%|██████████| 10/10 [01:54<00:00, 11.46s/it]
iteration:  109
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.53it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.143529429767139
The final epsilon delta values after the training is over:  (2.143529429767139, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0172413793103448, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.43s/it] 20%|██        | 2/10 [00:22<01:31, 11.40s/it] 30%|███       | 3/10 [00:34<01:19, 11.37s/it] 40%|████      | 4/10 [00:45<01:08, 11.35s/it] 50%|█████     | 5/10 [00:57<00:57, 11.43s/it] 60%|██████    | 6/10 [01:08<00:45, 11.39s/it] 70%|███████   | 7/10 [01:20<00:34, 11.48s/it] 80%|████████  | 8/10 [01:31<00:23, 11.54s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.59s/it]100%|██████████| 10/10 [01:54<00:00, 11.56s/it]100%|██████████| 10/10 [01:54<00:00, 11.49s/it]
iteration:  110
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 41.61it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.143529429767139
The final epsilon delta values after the training is over:  (2.143529429767139, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0172413793103448, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.39s/it] 20%|██        | 2/10 [00:22<01:31, 11.48s/it] 30%|███       | 3/10 [00:34<01:20, 11.45s/it] 40%|████      | 4/10 [00:45<01:08, 11.42s/it] 50%|█████     | 5/10 [00:57<00:57, 11.41s/it] 60%|██████    | 6/10 [01:08<00:45, 11.43s/it] 70%|███████   | 7/10 [01:20<00:34, 11.46s/it] 80%|████████  | 8/10 [01:31<00:22, 11.43s/it] 90%|█████████ | 9/10 [01:42<00:11, 11.42s/it]100%|██████████| 10/10 [01:54<00:00, 11.41s/it]100%|██████████| 10/10 [01:54<00:00, 11.43s/it]
iteration:  111
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 41.54it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.9527687632759303
The final epsilon delta values after the training is over:  (1.9527687632759303, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0689655172413794, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:43, 11.45s/it] 20%|██        | 2/10 [00:22<01:31, 11.38s/it] 30%|███       | 3/10 [00:34<01:19, 11.35s/it] 40%|████      | 4/10 [00:45<01:08, 11.47s/it] 50%|█████     | 5/10 [00:57<00:57, 11.45s/it] 60%|██████    | 6/10 [01:08<00:45, 11.45s/it] 70%|███████   | 7/10 [01:20<00:34, 11.50s/it] 80%|████████  | 8/10 [01:31<00:23, 11.53s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.48s/it]100%|██████████| 10/10 [01:54<00:00, 11.46s/it]100%|██████████| 10/10 [01:54<00:00, 11.46s/it]
iteration:  112
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.47it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.9527687632759303
The final epsilon delta values after the training is over:  (1.9527687632759303, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0689655172413794, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.69s/it] 20%|██        | 2/10 [00:23<01:32, 11.61s/it] 30%|███       | 3/10 [00:34<01:20, 11.56s/it] 40%|████      | 4/10 [00:46<01:09, 11.66s/it] 50%|█████     | 5/10 [00:58<00:58, 11.67s/it] 60%|██████    | 6/10 [01:09<00:46, 11.58s/it] 70%|███████   | 7/10 [01:21<00:34, 11.52s/it] 80%|████████  | 8/10 [01:32<00:23, 11.51s/it] 90%|█████████ | 9/10 [01:44<00:11, 11.56s/it]100%|██████████| 10/10 [01:55<00:00, 11.60s/it]100%|██████████| 10/10 [01:55<00:00, 11.59s/it]
iteration:  113
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 50.30it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.9527687632759303
The final epsilon delta values after the training is over:  (1.9527687632759303, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0689655172413794, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:43, 11.51s/it] 20%|██        | 2/10 [00:22<01:31, 11.44s/it] 30%|███       | 3/10 [00:34<01:20, 11.46s/it] 40%|████      | 4/10 [00:45<01:09, 11.50s/it] 50%|█████     | 5/10 [00:57<00:57, 11.53s/it] 60%|██████    | 6/10 [01:09<00:46, 11.53s/it] 70%|███████   | 7/10 [01:20<00:34, 11.48s/it] 80%|████████  | 8/10 [01:31<00:22, 11.46s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.44s/it]100%|██████████| 10/10 [01:54<00:00, 11.42s/it]100%|██████████| 10/10 [01:54<00:00, 11.46s/it]
iteration:  114
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 41.37it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.9527687632759303
The final epsilon delta values after the training is over:  (1.9527687632759303, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0689655172413794, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:43, 11.56s/it] 20%|██        | 2/10 [00:23<01:32, 11.51s/it] 30%|███       | 3/10 [00:34<01:20, 11.54s/it] 40%|████      | 4/10 [00:46<01:09, 11.52s/it] 50%|█████     | 5/10 [00:57<00:57, 11.48s/it] 60%|██████    | 6/10 [01:09<00:45, 11.49s/it] 70%|███████   | 7/10 [01:20<00:34, 11.60s/it] 80%|████████  | 8/10 [01:32<00:23, 11.55s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.52s/it]100%|██████████| 10/10 [01:55<00:00, 11.50s/it]100%|██████████| 10/10 [01:55<00:00, 11.52s/it]
iteration:  115
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.54it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.9527687632759303
The final epsilon delta values after the training is over:  (1.9527687632759303, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0689655172413794, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:43, 11.55s/it] 20%|██        | 2/10 [00:23<01:32, 11.57s/it] 30%|███       | 3/10 [00:34<01:20, 11.55s/it] 40%|████      | 4/10 [00:46<01:08, 11.49s/it] 50%|█████     | 5/10 [00:57<00:57, 11.45s/it] 60%|██████    | 6/10 [01:08<00:45, 11.44s/it] 70%|███████   | 7/10 [01:20<00:34, 11.49s/it] 80%|████████  | 8/10 [01:31<00:23, 11.50s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.53s/it]100%|██████████| 10/10 [01:55<00:00, 11.69s/it]100%|██████████| 10/10 [01:55<00:00, 11.56s/it]
iteration:  116
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.06it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.9527687632759303
The final epsilon delta values after the training is over:  (1.9527687632759303, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0689655172413794, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:46, 11.82s/it] 20%|██        | 2/10 [00:23<01:33, 11.72s/it] 30%|███       | 3/10 [00:35<01:21, 11.69s/it] 40%|████      | 4/10 [00:46<01:10, 11.67s/it] 50%|█████     | 5/10 [00:58<00:58, 11.66s/it] 60%|██████    | 6/10 [01:10<00:46, 11.66s/it] 70%|███████   | 7/10 [01:21<00:34, 11.63s/it] 80%|████████  | 8/10 [01:33<00:23, 11.61s/it] 90%|█████████ | 9/10 [01:45<00:11, 11.69s/it]100%|██████████| 10/10 [01:56<00:00, 11.62s/it]100%|██████████| 10/10 [01:56<00:00, 11.65s/it]
iteration:  117
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 41.71it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.9527687632759303
The final epsilon delta values after the training is over:  (1.9527687632759303, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0689655172413794, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.43s/it] 20%|██        | 2/10 [00:22<01:31, 11.44s/it] 30%|███       | 3/10 [00:34<01:19, 11.42s/it] 40%|████      | 4/10 [00:45<01:08, 11.43s/it] 50%|█████     | 5/10 [00:57<00:57, 11.46s/it] 60%|██████    | 6/10 [01:08<00:46, 11.52s/it] 70%|███████   | 7/10 [01:20<00:34, 11.52s/it] 80%|████████  | 8/10 [01:31<00:23, 11.52s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.53s/it]100%|██████████| 10/10 [01:55<00:00, 11.55s/it]100%|██████████| 10/10 [01:55<00:00, 11.51s/it]
iteration:  118
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 41.00it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.9527687632759303
The final epsilon delta values after the training is over:  (1.9527687632759303, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0689655172413794, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:44, 11.58s/it] 20%|██        | 2/10 [00:23<01:32, 11.57s/it] 30%|███       | 3/10 [00:34<01:20, 11.53s/it] 40%|████      | 4/10 [00:46<01:09, 11.52s/it] 50%|█████     | 5/10 [00:57<00:57, 11.53s/it] 60%|██████    | 6/10 [01:09<00:46, 11.61s/it] 70%|███████   | 7/10 [01:21<00:34, 11.65s/it] 80%|████████  | 8/10 [01:32<00:23, 11.59s/it] 90%|█████████ | 9/10 [01:44<00:11, 11.54s/it]100%|██████████| 10/10 [01:55<00:00, 11.62s/it]100%|██████████| 10/10 [01:55<00:00, 11.59s/it]
iteration:  119
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 41.67it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.9527687632759303
The final epsilon delta values after the training is over:  (1.9527687632759303, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0689655172413794, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.71s/it] 20%|██        | 2/10 [00:23<01:33, 11.65s/it] 30%|███       | 3/10 [00:34<01:21, 11.61s/it] 40%|████      | 4/10 [00:46<01:09, 11.60s/it] 50%|█████     | 5/10 [00:58<00:58, 11.67s/it] 60%|██████    | 6/10 [01:09<00:46, 11.59s/it] 70%|███████   | 7/10 [01:21<00:34, 11.56s/it] 80%|████████  | 8/10 [01:32<00:23, 11.53s/it] 90%|█████████ | 9/10 [01:44<00:11, 11.51s/it]100%|██████████| 10/10 [01:55<00:00, 11.52s/it]100%|██████████| 10/10 [01:55<00:00, 11.57s/it]
iteration:  120
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.82it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.9527687632759303
The final epsilon delta values after the training is over:  (1.9527687632759303, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0689655172413794, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:50, 12.22s/it] 20%|██        | 2/10 [00:23<01:35, 11.92s/it] 30%|███       | 3/10 [00:35<01:22, 11.79s/it] 40%|████      | 4/10 [00:47<01:10, 11.72s/it] 50%|█████     | 5/10 [00:58<00:58, 11.64s/it] 60%|██████    | 6/10 [01:10<00:46, 11.61s/it] 70%|███████   | 7/10 [01:21<00:34, 11.61s/it] 80%|████████  | 8/10 [01:33<00:23, 11.58s/it] 90%|█████████ | 9/10 [01:45<00:11, 11.63s/it]100%|██████████| 10/10 [01:56<00:00, 11.59s/it]100%|██████████| 10/10 [01:56<00:00, 11.66s/it]
iteration:  121
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.22it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.7995410093407855
The final epsilon delta values after the training is over:  (1.7995410093407855, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1206896551724137, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:44, 11.62s/it] 20%|██        | 2/10 [00:23<01:32, 11.59s/it] 30%|███       | 3/10 [00:34<01:20, 11.55s/it] 40%|████      | 4/10 [00:46<01:09, 11.54s/it] 50%|█████     | 5/10 [00:57<00:57, 11.59s/it] 60%|██████    | 6/10 [01:09<00:46, 11.57s/it] 70%|███████   | 7/10 [01:20<00:34, 11.56s/it] 80%|████████  | 8/10 [01:32<00:23, 11.55s/it] 90%|█████████ | 9/10 [01:44<00:11, 11.56s/it]100%|██████████| 10/10 [01:55<00:00, 11.57s/it]100%|██████████| 10/10 [01:55<00:00, 11.57s/it]
iteration:  122
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 41.18it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.7995410093407855
The final epsilon delta values after the training is over:  (1.7995410093407855, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1206896551724137, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:47, 11.98s/it] 20%|██        | 2/10 [00:23<01:34, 11.76s/it] 30%|███       | 3/10 [00:35<01:22, 11.74s/it] 40%|████      | 4/10 [00:46<01:10, 11.71s/it] 50%|█████     | 5/10 [00:58<00:58, 11.74s/it] 60%|██████    | 6/10 [01:10<00:46, 11.69s/it] 70%|███████   | 7/10 [01:21<00:35, 11.67s/it] 80%|████████  | 8/10 [01:33<00:23, 11.65s/it] 90%|█████████ | 9/10 [01:45<00:11, 11.68s/it]100%|██████████| 10/10 [01:57<00:00, 11.71s/it]100%|██████████| 10/10 [01:57<00:00, 11.71s/it]
iteration:  123
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.99it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.7995410093407855
The final epsilon delta values after the training is over:  (1.7995410093407855, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1206896551724137, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.69s/it] 20%|██        | 2/10 [00:23<01:32, 11.61s/it] 30%|███       | 3/10 [00:34<01:21, 11.65s/it] 40%|████      | 4/10 [00:46<01:09, 11.65s/it] 50%|█████     | 5/10 [00:58<00:58, 11.68s/it] 60%|██████    | 6/10 [01:09<00:46, 11.67s/it] 70%|███████   | 7/10 [01:21<00:34, 11.66s/it] 80%|████████  | 8/10 [01:33<00:23, 11.66s/it] 90%|█████████ | 9/10 [01:45<00:11, 11.77s/it]100%|██████████| 10/10 [01:57<00:00, 11.76s/it]100%|██████████| 10/10 [01:57<00:00, 11.70s/it]
iteration:  124
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 40.99it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.7995410093407855
The final epsilon delta values after the training is over:  (1.7995410093407855, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1206896551724137, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:47, 11.98s/it] 20%|██        | 2/10 [00:23<01:35, 11.93s/it] 30%|███       | 3/10 [00:35<01:22, 11.82s/it] 40%|████      | 4/10 [00:47<01:10, 11.78s/it] 50%|█████     | 5/10 [00:59<00:58, 11.79s/it] 60%|██████    | 6/10 [01:10<00:46, 11.73s/it] 70%|███████   | 7/10 [01:22<00:35, 11.72s/it] 80%|████████  | 8/10 [01:34<00:23, 11.73s/it] 90%|█████████ | 9/10 [01:45<00:11, 11.74s/it]100%|██████████| 10/10 [01:57<00:00, 11.73s/it]100%|██████████| 10/10 [01:57<00:00, 11.76s/it]
iteration:  125
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 49.97it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.7995410093407855
The final epsilon delta values after the training is over:  (1.7995410093407855, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1206896551724137, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:46, 11.83s/it] 20%|██        | 2/10 [00:23<01:34, 11.78s/it] 30%|███       | 3/10 [00:35<01:22, 11.81s/it] 40%|████      | 4/10 [00:47<01:10, 11.78s/it] 50%|█████     | 5/10 [00:59<00:59, 11.83s/it] 60%|██████    | 6/10 [01:10<00:47, 11.84s/it] 70%|███████   | 7/10 [01:22<00:35, 11.84s/it] 80%|████████  | 8/10 [01:34<00:23, 11.83s/it] 90%|█████████ | 9/10 [01:46<00:11, 11.86s/it]100%|██████████| 10/10 [01:58<00:00, 11.87s/it]100%|██████████| 10/10 [01:58<00:00, 11.84s/it]
iteration:  126
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.19it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.7995410093407855
The final epsilon delta values after the training is over:  (1.7995410093407855, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1206896551724137, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:06, 14.02s/it] 20%|██        | 2/10 [00:26<01:45, 13.25s/it] 30%|███       | 3/10 [00:38<01:28, 12.69s/it] 40%|████      | 4/10 [00:50<01:13, 12.32s/it] 50%|█████     | 5/10 [01:02<01:00, 12.14s/it] 60%|██████    | 6/10 [01:14<00:48, 12.07s/it] 70%|███████   | 7/10 [01:26<00:36, 12.04s/it] 80%|████████  | 8/10 [01:37<00:23, 11.93s/it] 90%|█████████ | 9/10 [01:49<00:11, 11.97s/it]100%|██████████| 10/10 [02:01<00:00, 11.90s/it]100%|██████████| 10/10 [02:01<00:00, 12.17s/it]
iteration:  127
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 40.30it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.7995410093407855
The final epsilon delta values after the training is over:  (1.7995410093407855, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1206896551724137, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:51, 12.41s/it] 20%|██        | 2/10 [00:24<01:36, 12.12s/it] 30%|███       | 3/10 [00:36<01:23, 11.98s/it] 40%|████      | 4/10 [00:49<01:14, 12.38s/it] 50%|█████     | 5/10 [01:01<01:01, 12.39s/it] 60%|██████    | 6/10 [01:13<00:48, 12.14s/it] 70%|███████   | 7/10 [01:24<00:35, 11.99s/it] 80%|████████  | 8/10 [01:36<00:23, 11.93s/it] 90%|█████████ | 9/10 [01:48<00:11, 11.84s/it]100%|██████████| 10/10 [02:00<00:00, 11.79s/it]100%|██████████| 10/10 [02:00<00:00, 12.00s/it]
iteration:  128
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.16it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.7995410093407855
The final epsilon delta values after the training is over:  (1.7995410093407855, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1206896551724137, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.68s/it] 20%|██        | 2/10 [00:23<01:33, 11.69s/it] 30%|███       | 3/10 [00:35<01:21, 11.67s/it] 40%|████      | 4/10 [00:46<01:10, 11.70s/it] 50%|█████     | 5/10 [00:58<00:58, 11.72s/it] 60%|██████    | 6/10 [01:10<00:46, 11.73s/it] 70%|███████   | 7/10 [01:21<00:35, 11.71s/it] 80%|████████  | 8/10 [01:33<00:23, 11.69s/it] 90%|█████████ | 9/10 [01:45<00:11, 11.69s/it]100%|██████████| 10/10 [01:56<00:00, 11.69s/it]100%|██████████| 10/10 [01:56<00:00, 11.70s/it]
iteration:  129
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.68it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.7995410093407855
The final epsilon delta values after the training is over:  (1.7995410093407855, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1206896551724137, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:44, 11.63s/it] 20%|██        | 2/10 [00:23<01:33, 11.64s/it] 30%|███       | 3/10 [00:34<01:21, 11.66s/it] 40%|████      | 4/10 [00:46<01:09, 11.66s/it] 50%|█████     | 5/10 [00:58<00:58, 11.66s/it] 60%|██████    | 6/10 [01:09<00:46, 11.65s/it] 70%|███████   | 7/10 [01:21<00:34, 11.65s/it] 80%|████████  | 8/10 [01:33<00:23, 11.65s/it] 90%|█████████ | 9/10 [01:44<00:11, 11.66s/it]100%|██████████| 10/10 [01:56<00:00, 11.67s/it]100%|██████████| 10/10 [01:56<00:00, 11.66s/it]
iteration:  130
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.52it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.7995410093407855
The final epsilon delta values after the training is over:  (1.7995410093407855, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1206896551724137, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.74s/it] 20%|██        | 2/10 [00:23<01:33, 11.74s/it] 30%|███       | 3/10 [00:35<01:22, 11.74s/it] 40%|████      | 4/10 [00:46<01:10, 11.73s/it] 50%|█████     | 5/10 [00:58<00:58, 11.72s/it] 60%|██████    | 6/10 [01:10<00:46, 11.71s/it] 70%|███████   | 7/10 [01:22<00:35, 11.70s/it] 80%|████████  | 8/10 [01:33<00:23, 11.70s/it] 90%|█████████ | 9/10 [01:45<00:11, 11.70s/it]100%|██████████| 10/10 [01:57<00:00, 11.70s/it]100%|██████████| 10/10 [01:57<00:00, 11.71s/it]
iteration:  131
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.24it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.6696234071796798
The final epsilon delta values after the training is over:  (1.6696234071796798, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1724137931034484, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.69s/it] 20%|██        | 2/10 [00:23<01:33, 11.68s/it] 30%|███       | 3/10 [00:35<01:21, 11.67s/it] 40%|████      | 4/10 [00:46<01:10, 11.68s/it] 50%|█████     | 5/10 [00:58<00:58, 11.71s/it] 60%|██████    | 6/10 [01:10<00:47, 11.75s/it] 70%|███████   | 7/10 [01:22<00:35, 11.80s/it] 80%|████████  | 8/10 [01:34<00:23, 11.84s/it] 90%|█████████ | 9/10 [01:45<00:11, 11.80s/it]100%|██████████| 10/10 [01:57<00:00, 11.77s/it]100%|██████████| 10/10 [01:57<00:00, 11.76s/it]
iteration:  132
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.60it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.6696234071796798
The final epsilon delta values after the training is over:  (1.6696234071796798, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1724137931034484, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.74s/it] 20%|██        | 2/10 [00:23<01:33, 11.73s/it] 30%|███       | 3/10 [00:35<01:22, 11.73s/it] 40%|████      | 4/10 [00:46<01:10, 11.72s/it] 50%|█████     | 5/10 [00:58<00:58, 11.72s/it] 60%|██████    | 6/10 [01:10<00:46, 11.72s/it] 70%|███████   | 7/10 [01:22<00:35, 11.72s/it] 80%|████████  | 8/10 [01:33<00:23, 11.77s/it] 90%|█████████ | 9/10 [01:45<00:11, 11.78s/it]100%|██████████| 10/10 [01:57<00:00, 11.82s/it]100%|██████████| 10/10 [01:57<00:00, 11.76s/it]
iteration:  133
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.87it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.6696234071796798
The final epsilon delta values after the training is over:  (1.6696234071796798, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1724137931034484, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:46, 11.82s/it] 20%|██        | 2/10 [00:23<01:34, 11.83s/it] 30%|███       | 3/10 [00:35<01:22, 11.76s/it] 40%|████      | 4/10 [00:47<01:10, 11.74s/it] 50%|█████     | 5/10 [00:58<00:58, 11.75s/it] 60%|██████    | 6/10 [01:10<00:46, 11.73s/it] 70%|███████   | 7/10 [01:22<00:35, 11.74s/it] 80%|████████  | 8/10 [01:34<00:23, 11.74s/it] 90%|█████████ | 9/10 [01:45<00:11, 11.74s/it]100%|██████████| 10/10 [01:57<00:00, 11.75s/it]100%|██████████| 10/10 [01:57<00:00, 11.75s/it]
iteration:  134
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.48it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.6696234071796798
The final epsilon delta values after the training is over:  (1.6696234071796798, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1724137931034484, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:46, 11.78s/it] 20%|██        | 2/10 [00:23<01:34, 11.75s/it] 30%|███       | 3/10 [00:35<01:22, 11.76s/it] 40%|████      | 4/10 [00:47<01:10, 11.78s/it] 50%|█████     | 5/10 [00:58<00:58, 11.78s/it] 60%|██████    | 6/10 [01:10<00:47, 11.77s/it] 70%|███████   | 7/10 [01:22<00:35, 11.76s/it] 80%|████████  | 8/10 [01:34<00:23, 11.77s/it] 90%|█████████ | 9/10 [01:45<00:11, 11.79s/it]100%|██████████| 10/10 [01:57<00:00, 11.78s/it]100%|██████████| 10/10 [01:57<00:00, 11.78s/it]
iteration:  135
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.46it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.6696234071796798
The final epsilon delta values after the training is over:  (1.6696234071796798, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1724137931034484, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:47, 11.94s/it] 20%|██        | 2/10 [00:23<01:35, 11.99s/it] 30%|███       | 3/10 [00:35<01:23, 11.93s/it] 40%|████      | 4/10 [00:47<01:11, 11.86s/it] 50%|█████     | 5/10 [00:59<00:59, 11.81s/it] 60%|██████    | 6/10 [01:11<00:47, 11.79s/it] 70%|███████   | 7/10 [01:22<00:35, 11.78s/it] 80%|████████  | 8/10 [01:34<00:23, 11.78s/it] 90%|█████████ | 9/10 [01:46<00:11, 11.78s/it]100%|██████████| 10/10 [01:58<00:00, 11.78s/it]100%|██████████| 10/10 [01:58<00:00, 11.81s/it]
iteration:  136
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.58it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.6696234071796798
The final epsilon delta values after the training is over:  (1.6696234071796798, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1724137931034484, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:46, 11.79s/it] 20%|██        | 2/10 [00:23<01:34, 11.77s/it] 30%|███       | 3/10 [00:35<01:22, 11.77s/it] 40%|████      | 4/10 [00:47<01:10, 11.78s/it] 50%|█████     | 5/10 [00:58<00:58, 11.79s/it] 60%|██████    | 6/10 [01:10<00:47, 11.79s/it] 70%|███████   | 7/10 [01:22<00:35, 11.79s/it] 80%|████████  | 8/10 [01:34<00:23, 11.79s/it] 90%|█████████ | 9/10 [01:46<00:11, 11.78s/it]100%|██████████| 10/10 [01:57<00:00, 11.79s/it]100%|██████████| 10/10 [01:57<00:00, 11.79s/it]
iteration:  137
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.14it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.6696234071796798
The final epsilon delta values after the training is over:  (1.6696234071796798, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1724137931034484, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.76s/it] 20%|██        | 2/10 [00:23<01:34, 11.77s/it] 30%|███       | 3/10 [00:35<01:22, 11.76s/it] 40%|████      | 4/10 [00:47<01:10, 11.76s/it] 50%|█████     | 5/10 [00:58<00:58, 11.78s/it] 60%|██████    | 6/10 [01:10<00:47, 11.79s/it] 70%|███████   | 7/10 [01:22<00:35, 11.82s/it] 80%|████████  | 8/10 [01:34<00:23, 11.81s/it] 90%|█████████ | 9/10 [01:46<00:11, 11.80s/it]100%|██████████| 10/10 [01:57<00:00, 11.80s/it]100%|██████████| 10/10 [01:57<00:00, 11.79s/it]
iteration:  138
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.76it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.6696234071796798
The final epsilon delta values after the training is over:  (1.6696234071796798, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1724137931034484, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:46, 11.82s/it] 20%|██        | 2/10 [00:23<01:34, 11.81s/it] 30%|███       | 3/10 [00:35<01:24, 12.01s/it] 40%|████      | 4/10 [00:47<01:12, 12.03s/it] 50%|█████     | 5/10 [00:59<00:59, 11.99s/it] 60%|██████    | 6/10 [01:11<00:47, 11.96s/it] 70%|███████   | 7/10 [01:23<00:35, 11.92s/it] 80%|████████  | 8/10 [01:35<00:23, 11.88s/it] 90%|█████████ | 9/10 [01:47<00:11, 11.85s/it]100%|██████████| 10/10 [01:58<00:00, 11.84s/it]100%|██████████| 10/10 [01:58<00:00, 11.90s/it]
iteration:  139
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.36it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.6696234071796798
The final epsilon delta values after the training is over:  (1.6696234071796798, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1724137931034484, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:46, 11.82s/it] 20%|██        | 2/10 [00:23<01:34, 11.81s/it] 30%|███       | 3/10 [00:35<01:22, 11.80s/it] 40%|████      | 4/10 [00:47<01:10, 11.79s/it] 50%|█████     | 5/10 [00:58<00:58, 11.80s/it] 60%|██████    | 6/10 [01:10<00:47, 11.80s/it] 70%|███████   | 7/10 [01:22<00:35, 11.81s/it] 80%|████████  | 8/10 [01:34<00:23, 11.81s/it] 90%|█████████ | 9/10 [01:46<00:11, 11.83s/it]100%|██████████| 10/10 [01:58<00:00, 11.83s/it]100%|██████████| 10/10 [01:58<00:00, 11.81s/it]
iteration:  140
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.73it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.6696234071796798
The final epsilon delta values after the training is over:  (1.6696234071796798, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1724137931034484, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:47, 11.90s/it] 20%|██        | 2/10 [00:23<01:34, 11.87s/it] 30%|███       | 3/10 [00:35<01:23, 11.86s/it] 40%|████      | 4/10 [00:47<01:11, 11.88s/it] 50%|█████     | 5/10 [00:59<00:59, 11.88s/it] 60%|██████    | 6/10 [01:11<00:47, 11.88s/it] 70%|███████   | 7/10 [01:23<00:35, 11.88s/it] 80%|████████  | 8/10 [01:35<00:23, 11.90s/it] 90%|█████████ | 9/10 [01:47<00:12, 12.01s/it]100%|██████████| 10/10 [01:59<00:00, 12.00s/it]100%|██████████| 10/10 [01:59<00:00, 11.93s/it]
iteration:  141
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.24it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.54766719601816
The final epsilon delta values after the training is over:  (1.54766719601816, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2241379310344827, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:47, 11.96s/it] 20%|██        | 2/10 [00:23<01:35, 11.93s/it] 30%|███       | 3/10 [00:35<01:23, 11.92s/it] 40%|████      | 4/10 [00:47<01:11, 11.92s/it] 50%|█████     | 5/10 [00:59<00:59, 11.91s/it] 60%|██████    | 6/10 [01:11<00:47, 11.91s/it] 70%|███████   | 7/10 [01:23<00:35, 11.95s/it] 80%|████████  | 8/10 [01:35<00:23, 11.93s/it] 90%|█████████ | 9/10 [01:47<00:11, 11.93s/it]100%|██████████| 10/10 [01:59<00:00, 11.94s/it]100%|██████████| 10/10 [01:59<00:00, 11.93s/it]
iteration:  142
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.59it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.54766719601816
The final epsilon delta values after the training is over:  (1.54766719601816, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2241379310344827, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:47, 11.95s/it] 20%|██        | 2/10 [00:23<01:35, 11.95s/it] 30%|███       | 3/10 [00:35<01:23, 11.94s/it] 40%|████      | 4/10 [00:47<01:11, 11.92s/it] 50%|█████     | 5/10 [00:59<00:59, 11.92s/it] 60%|██████    | 6/10 [01:11<00:47, 11.96s/it] 70%|███████   | 7/10 [01:23<00:35, 11.97s/it] 80%|████████  | 8/10 [01:35<00:23, 11.97s/it] 90%|█████████ | 9/10 [01:47<00:11, 11.97s/it]100%|██████████| 10/10 [01:59<00:00, 11.97s/it]100%|██████████| 10/10 [01:59<00:00, 11.96s/it]
iteration:  143
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.70it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.54766719601816
The final epsilon delta values after the training is over:  (1.54766719601816, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2241379310344827, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:47, 11.94s/it] 20%|██        | 2/10 [00:23<01:35, 11.94s/it] 30%|███       | 3/10 [00:35<01:23, 11.94s/it] 40%|████      | 4/10 [00:47<01:11, 11.95s/it] 50%|█████     | 5/10 [00:59<00:59, 11.96s/it] 60%|██████    | 6/10 [01:11<00:47, 11.95s/it] 70%|███████   | 7/10 [01:23<00:35, 11.95s/it] 80%|████████  | 8/10 [01:35<00:23, 11.96s/it] 90%|█████████ | 9/10 [01:47<00:12, 12.00s/it]100%|██████████| 10/10 [01:59<00:00, 12.03s/it]100%|██████████| 10/10 [01:59<00:00, 11.98s/it]
iteration:  144
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.16it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.54766719601816
The final epsilon delta values after the training is over:  (1.54766719601816, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2241379310344827, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:48, 12.07s/it] 20%|██        | 2/10 [00:24<01:36, 12.06s/it] 30%|███       | 3/10 [00:36<01:24, 12.01s/it] 40%|████      | 4/10 [00:48<01:11, 11.98s/it] 50%|█████     | 5/10 [01:00<01:00, 12.02s/it] 60%|██████    | 6/10 [01:12<00:48, 12.06s/it] 70%|███████   | 7/10 [01:24<00:36, 12.05s/it] 80%|████████  | 8/10 [01:36<00:24, 12.03s/it] 90%|█████████ | 9/10 [01:48<00:12, 12.03s/it]100%|██████████| 10/10 [02:00<00:00, 12.07s/it]100%|██████████| 10/10 [02:00<00:00, 12.04s/it]
iteration:  145
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.32it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.54766719601816
The final epsilon delta values after the training is over:  (1.54766719601816, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2241379310344827, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:50, 12.23s/it] 20%|██        | 2/10 [00:24<01:36, 12.05s/it] 30%|███       | 3/10 [00:36<01:24, 12.01s/it] 40%|████      | 4/10 [00:48<01:11, 11.98s/it] 50%|█████     | 5/10 [00:59<00:59, 11.96s/it] 60%|██████    | 6/10 [01:11<00:47, 11.96s/it] 70%|███████   | 7/10 [01:23<00:35, 11.97s/it] 80%|████████  | 8/10 [01:35<00:23, 11.98s/it] 90%|█████████ | 9/10 [01:47<00:11, 11.99s/it]100%|██████████| 10/10 [01:59<00:00, 12.00s/it]100%|██████████| 10/10 [01:59<00:00, 11.99s/it]
iteration:  146
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.38it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.54766719601816
The final epsilon delta values after the training is over:  (1.54766719601816, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2241379310344827, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:48, 12.03s/it] 20%|██        | 2/10 [00:24<01:36, 12.01s/it] 30%|███       | 3/10 [00:36<01:24, 12.02s/it] 40%|████      | 4/10 [00:48<01:12, 12.01s/it] 50%|█████     | 5/10 [01:00<01:00, 12.01s/it] 60%|██████    | 6/10 [01:12<00:48, 12.02s/it] 70%|███████   | 7/10 [01:24<00:36, 12.05s/it] 80%|████████  | 8/10 [01:36<00:24, 12.07s/it] 90%|█████████ | 9/10 [01:48<00:12, 12.09s/it]100%|██████████| 10/10 [02:00<00:00, 12.11s/it]100%|██████████| 10/10 [02:00<00:00, 12.06s/it]
iteration:  147
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.47it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.54766719601816
The final epsilon delta values after the training is over:  (1.54766719601816, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2241379310344827, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:48, 12.07s/it] 20%|██        | 2/10 [00:24<01:36, 12.11s/it] 30%|███       | 3/10 [00:36<01:24, 12.08s/it] 40%|████      | 4/10 [00:48<01:12, 12.04s/it] 50%|█████     | 5/10 [01:00<01:00, 12.03s/it] 60%|██████    | 6/10 [01:12<00:48, 12.02s/it] 70%|███████   | 7/10 [01:24<00:36, 12.02s/it] 80%|████████  | 8/10 [01:36<00:24, 12.06s/it] 90%|█████████ | 9/10 [01:48<00:12, 12.09s/it]100%|██████████| 10/10 [02:00<00:00, 12.11s/it]100%|██████████| 10/10 [02:00<00:00, 12.07s/it]
iteration:  148
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.83it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.54766719601816
The final epsilon delta values after the training is over:  (1.54766719601816, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2241379310344827, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:49, 12.16s/it] 20%|██        | 2/10 [00:24<01:37, 12.13s/it] 30%|███       | 3/10 [00:36<01:24, 12.10s/it] 40%|████      | 4/10 [00:48<01:12, 12.15s/it] 50%|█████     | 5/10 [01:00<01:00, 12.15s/it] 60%|██████    | 6/10 [01:12<00:48, 12.11s/it] 70%|███████   | 7/10 [01:24<00:36, 12.07s/it] 80%|████████  | 8/10 [01:36<00:24, 12.05s/it] 90%|█████████ | 9/10 [01:48<00:12, 12.10s/it]100%|██████████| 10/10 [02:01<00:00, 12.16s/it]100%|██████████| 10/10 [02:01<00:00, 12.12s/it]
iteration:  149
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.15it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.54766719601816
The final epsilon delta values after the training is over:  (1.54766719601816, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2241379310344827, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:47, 12.00s/it] 20%|██        | 2/10 [00:23<01:35, 11.99s/it] 30%|███       | 3/10 [00:35<01:23, 11.99s/it] 40%|████      | 4/10 [00:48<01:12, 12.01s/it] 50%|█████     | 5/10 [01:00<01:00, 12.07s/it] 60%|██████    | 6/10 [01:12<00:48, 12.08s/it] 70%|███████   | 7/10 [01:24<00:36, 12.14s/it] 80%|████████  | 8/10 [01:36<00:24, 12.14s/it] 90%|█████████ | 9/10 [01:48<00:12, 12.13s/it]100%|██████████| 10/10 [02:00<00:00, 12.11s/it]100%|██████████| 10/10 [02:00<00:00, 12.08s/it]
iteration:  150
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.13it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.54766719601816
The final epsilon delta values after the training is over:  (1.54766719601816, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2241379310344827, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:48, 12.08s/it] 20%|██        | 2/10 [00:24<01:36, 12.07s/it] 30%|███       | 3/10 [00:36<01:24, 12.05s/it] 40%|████      | 4/10 [00:48<01:12, 12.06s/it] 50%|█████     | 5/10 [01:00<01:00, 12.12s/it] 60%|██████    | 6/10 [01:12<00:48, 12.12s/it] 70%|███████   | 7/10 [01:24<00:36, 12.18s/it] 80%|████████  | 8/10 [01:37<00:24, 12.17s/it] 90%|█████████ | 9/10 [01:49<00:12, 12.18s/it]100%|██████████| 10/10 [02:01<00:00, 12.15s/it]100%|██████████| 10/10 [02:01<00:00, 12.13s/it]
iteration:  151
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.91it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.4304109951869581
The final epsilon delta values after the training is over:  (1.4304109951869581, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2758620689655173, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:48, 12.05s/it] 20%|██        | 2/10 [00:24<01:37, 12.15s/it] 30%|███       | 3/10 [00:36<01:24, 12.14s/it] 40%|████      | 4/10 [00:48<01:12, 12.11s/it] 50%|█████     | 5/10 [01:00<01:00, 12.09s/it] 60%|██████    | 6/10 [01:12<00:48, 12.07s/it] 70%|███████   | 7/10 [01:24<00:36, 12.07s/it] 80%|████████  | 8/10 [01:36<00:24, 12.07s/it] 90%|█████████ | 9/10 [01:48<00:12, 12.07s/it]100%|██████████| 10/10 [02:00<00:00, 12.09s/it]100%|██████████| 10/10 [02:00<00:00, 12.09s/it]
iteration:  152
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.43it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.4304109951869581
The final epsilon delta values after the training is over:  (1.4304109951869581, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2758620689655173, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:49, 12.14s/it] 20%|██        | 2/10 [00:24<01:36, 12.12s/it] 30%|███       | 3/10 [00:36<01:24, 12.12s/it] 40%|████      | 4/10 [00:48<01:12, 12.16s/it] 50%|█████     | 5/10 [01:00<01:00, 12.17s/it] 60%|██████    | 6/10 [01:12<00:48, 12.16s/it] 70%|███████   | 7/10 [01:25<00:36, 12.19s/it] 80%|████████  | 8/10 [01:37<00:24, 12.16s/it] 90%|█████████ | 9/10 [01:49<00:12, 12.14s/it]100%|██████████| 10/10 [02:01<00:00, 12.13s/it]100%|██████████| 10/10 [02:01<00:00, 12.15s/it]
iteration:  153
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.85it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.4304109951869581
The final epsilon delta values after the training is over:  (1.4304109951869581, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2758620689655173, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:49, 12.11s/it] 20%|██        | 2/10 [00:24<01:36, 12.10s/it] 30%|███       | 3/10 [00:36<01:24, 12.09s/it] 40%|████      | 4/10 [00:48<01:12, 12.10s/it] 50%|█████     | 5/10 [01:00<01:00, 12.16s/it] 60%|██████    | 6/10 [01:12<00:48, 12.16s/it] 70%|███████   | 7/10 [01:24<00:36, 12.16s/it] 80%|████████  | 8/10 [01:37<00:24, 12.18s/it] 90%|█████████ | 9/10 [01:49<00:12, 12.20s/it]100%|██████████| 10/10 [02:01<00:00, 12.18s/it]100%|██████████| 10/10 [02:01<00:00, 12.16s/it]
iteration:  154
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.99it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.4304109951869581
The final epsilon delta values after the training is over:  (1.4304109951869581, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2758620689655173, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:49, 12.15s/it] 20%|██        | 2/10 [00:24<01:37, 12.15s/it] 30%|███       | 3/10 [00:36<01:25, 12.18s/it] 40%|████      | 4/10 [00:48<01:12, 12.16s/it] 50%|█████     | 5/10 [01:00<01:00, 12.15s/it] 60%|██████    | 6/10 [01:12<00:48, 12.14s/it] 70%|███████   | 7/10 [01:25<00:36, 12.14s/it] 80%|████████  | 8/10 [01:37<00:24, 12.14s/it] 90%|█████████ | 9/10 [01:49<00:12, 12.14s/it]100%|██████████| 10/10 [02:01<00:00, 12.14s/it]100%|██████████| 10/10 [02:01<00:00, 12.15s/it]
iteration:  155
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.95it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.4304109951869581
The final epsilon delta values after the training is over:  (1.4304109951869581, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2758620689655173, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:49, 12.13s/it] 20%|██        | 2/10 [00:24<01:37, 12.21s/it] 30%|███       | 3/10 [00:36<01:25, 12.19s/it] 40%|████      | 4/10 [00:48<01:13, 12.25s/it] 50%|█████     | 5/10 [01:01<01:01, 12.20s/it] 60%|██████    | 6/10 [01:13<00:48, 12.22s/it] 70%|███████   | 7/10 [01:25<00:36, 12.20s/it] 80%|████████  | 8/10 [01:37<00:24, 12.20s/it] 90%|█████████ | 9/10 [01:49<00:12, 12.20s/it]100%|██████████| 10/10 [02:02<00:00, 12.25s/it]100%|██████████| 10/10 [02:02<00:00, 12.22s/it]
iteration:  156
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.74it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.4304109951869581
The final epsilon delta values after the training is over:  (1.4304109951869581, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2758620689655173, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:51, 12.40s/it] 20%|██        | 2/10 [00:25<01:40, 12.53s/it] 30%|███       | 3/10 [00:37<01:26, 12.37s/it] 40%|████      | 4/10 [00:49<01:13, 12.31s/it] 50%|█████     | 5/10 [01:01<01:01, 12.34s/it] 60%|██████    | 6/10 [01:13<00:49, 12.27s/it] 70%|███████   | 7/10 [01:26<00:36, 12.23s/it] 80%|████████  | 8/10 [01:38<00:24, 12.20s/it] 90%|█████████ | 9/10 [01:50<00:12, 12.19s/it]100%|██████████| 10/10 [02:02<00:00, 12.23s/it]100%|██████████| 10/10 [02:02<00:00, 12.27s/it]
iteration:  157
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.54it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.4304109951869581
The final epsilon delta values after the training is over:  (1.4304109951869581, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2758620689655173, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:51, 12.36s/it] 20%|██        | 2/10 [00:24<01:38, 12.25s/it] 30%|███       | 3/10 [00:36<01:25, 12.22s/it] 40%|████      | 4/10 [00:48<01:13, 12.20s/it] 50%|█████     | 5/10 [01:01<01:00, 12.19s/it] 60%|██████    | 6/10 [01:13<00:48, 12.18s/it] 70%|███████   | 7/10 [01:25<00:36, 12.17s/it] 80%|████████  | 8/10 [01:37<00:24, 12.17s/it] 90%|█████████ | 9/10 [01:49<00:12, 12.18s/it]100%|██████████| 10/10 [02:02<00:00, 12.23s/it]100%|██████████| 10/10 [02:02<00:00, 12.21s/it]
iteration:  158
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.66it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.4304109951869581
The final epsilon delta values after the training is over:  (1.4304109951869581, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2758620689655173, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:49, 12.21s/it] 20%|██        | 2/10 [00:24<01:37, 12.20s/it] 30%|███       | 3/10 [00:36<01:25, 12.24s/it] 40%|████      | 4/10 [00:48<01:13, 12.23s/it] 50%|█████     | 5/10 [01:01<01:01, 12.23s/it] 60%|██████    | 6/10 [01:13<00:48, 12.23s/it] 70%|███████   | 7/10 [01:25<00:36, 12.28s/it] 80%|████████  | 8/10 [01:37<00:24, 12.26s/it] 90%|█████████ | 9/10 [01:50<00:12, 12.29s/it]100%|██████████| 10/10 [02:02<00:00, 12.27s/it]100%|██████████| 10/10 [02:02<00:00, 12.25s/it]
iteration:  159
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 55.09it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.4304109951869581
The final epsilon delta values after the training is over:  (1.4304109951869581, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2758620689655173, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:50, 12.29s/it] 20%|██        | 2/10 [00:24<01:38, 12.36s/it] 30%|███       | 3/10 [00:37<01:27, 12.43s/it] 40%|████      | 4/10 [00:49<01:13, 12.33s/it] 50%|█████     | 5/10 [01:01<01:01, 12.28s/it] 60%|██████    | 6/10 [01:13<00:48, 12.25s/it] 70%|███████   | 7/10 [01:25<00:36, 12.24s/it] 80%|████████  | 8/10 [01:38<00:24, 12.28s/it] 90%|█████████ | 9/10 [01:53<00:13, 13.22s/it]100%|██████████| 10/10 [02:09<00:00, 14.12s/it]100%|██████████| 10/10 [02:09<00:00, 12.98s/it]
iteration:  160
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 51.81it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.4304109951869581
The final epsilon delta values after the training is over:  (1.4304109951869581, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2758620689655173, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:05, 13.96s/it] 20%|██        | 2/10 [00:27<01:47, 13.48s/it] 30%|███       | 3/10 [00:40<01:33, 13.37s/it] 40%|████      | 4/10 [00:53<01:18, 13.09s/it] 50%|█████     | 5/10 [01:05<01:04, 12.90s/it] 60%|██████    | 6/10 [01:17<00:50, 12.73s/it] 70%|███████   | 7/10 [01:30<00:37, 12.59s/it] 80%|████████  | 8/10 [01:42<00:25, 12.62s/it] 90%|█████████ | 9/10 [01:55<00:12, 12.63s/it]100%|██████████| 10/10 [02:08<00:00, 12.62s/it]100%|██████████| 10/10 [02:08<00:00, 12.82s/it]
iteration:  161
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 51.52it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.3293639454188084
The final epsilon delta values after the training is over:  (1.3293639454188084, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3275862068965516, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:56, 12.94s/it] 20%|██        | 2/10 [00:25<01:41, 12.67s/it] 30%|███       | 3/10 [00:38<01:30, 12.90s/it] 40%|████      | 4/10 [00:50<01:16, 12.68s/it] 50%|█████     | 5/10 [01:03<01:02, 12.51s/it] 60%|██████    | 6/10 [01:15<00:49, 12.42s/it] 70%|███████   | 7/10 [01:27<00:37, 12.37s/it] 80%|████████  | 8/10 [01:39<00:24, 12.33s/it] 90%|█████████ | 9/10 [01:52<00:12, 12.32s/it]100%|██████████| 10/10 [02:04<00:00, 12.30s/it]100%|██████████| 10/10 [02:04<00:00, 12.45s/it]
iteration:  162
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.20it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.3293639454188084
The final epsilon delta values after the training is over:  (1.3293639454188084, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3275862068965516, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:50, 12.28s/it] 20%|██        | 2/10 [00:24<01:38, 12.27s/it] 30%|███       | 3/10 [00:36<01:25, 12.26s/it] 40%|████      | 4/10 [00:49<01:13, 12.26s/it] 50%|█████     | 5/10 [01:01<01:01, 12.26s/it] 60%|██████    | 6/10 [01:13<00:49, 12.27s/it] 70%|███████   | 7/10 [01:25<00:36, 12.26s/it] 80%|████████  | 8/10 [01:38<00:24, 12.33s/it] 90%|█████████ | 9/10 [01:50<00:12, 12.35s/it]100%|██████████| 10/10 [02:03<00:00, 12.33s/it]100%|██████████| 10/10 [02:03<00:00, 12.30s/it]
iteration:  163
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.92it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.3293639454188084
The final epsilon delta values after the training is over:  (1.3293639454188084, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3275862068965516, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:50, 12.28s/it] 20%|██        | 2/10 [00:24<01:38, 12.26s/it] 30%|███       | 3/10 [00:36<01:26, 12.32s/it] 40%|████      | 4/10 [00:49<01:13, 12.31s/it] 50%|█████     | 5/10 [01:01<01:01, 12.36s/it] 60%|██████    | 6/10 [01:13<00:49, 12.33s/it] 70%|███████   | 7/10 [01:26<00:37, 12.41s/it] 80%|████████  | 8/10 [01:38<00:24, 12.38s/it] 90%|█████████ | 9/10 [01:51<00:12, 12.40s/it]100%|██████████| 10/10 [02:03<00:00, 12.38s/it]100%|██████████| 10/10 [02:03<00:00, 12.36s/it]
iteration:  164
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.75it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.3293639454188084
The final epsilon delta values after the training is over:  (1.3293639454188084, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3275862068965516, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:50, 12.31s/it] 20%|██        | 2/10 [00:24<01:38, 12.32s/it] 30%|███       | 3/10 [00:37<01:26, 12.34s/it] 40%|████      | 4/10 [00:49<01:14, 12.37s/it] 50%|█████     | 5/10 [01:01<01:01, 12.34s/it] 60%|██████    | 6/10 [01:14<00:49, 12.42s/it] 70%|███████   | 7/10 [01:26<00:37, 12.38s/it] 80%|████████  | 8/10 [01:38<00:24, 12.36s/it] 90%|█████████ | 9/10 [01:51<00:12, 12.35s/it]100%|██████████| 10/10 [02:03<00:00, 12.34s/it]100%|██████████| 10/10 [02:03<00:00, 12.35s/it]
iteration:  165
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.81it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.3293639454188084
The final epsilon delta values after the training is over:  (1.3293639454188084, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3275862068965516, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:50, 12.30s/it] 20%|██        | 2/10 [00:24<01:38, 12.30s/it] 30%|███       | 3/10 [00:36<01:26, 12.31s/it] 40%|████      | 4/10 [00:49<01:13, 12.32s/it] 50%|█████     | 5/10 [01:01<01:01, 12.35s/it] 60%|██████    | 6/10 [01:14<00:49, 12.37s/it] 70%|███████   | 7/10 [01:26<00:37, 12.36s/it] 80%|████████  | 8/10 [01:38<00:24, 12.35s/it] 90%|█████████ | 9/10 [01:51<00:12, 12.40s/it]100%|██████████| 10/10 [02:03<00:00, 12.45s/it]100%|██████████| 10/10 [02:03<00:00, 12.38s/it]
iteration:  166
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.05it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.3293639454188084
The final epsilon delta values after the training is over:  (1.3293639454188084, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3275862068965516, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:51, 12.41s/it] 20%|██        | 2/10 [00:24<01:39, 12.41s/it] 30%|███       | 3/10 [00:37<01:26, 12.37s/it] 40%|████      | 4/10 [00:49<01:14, 12.36s/it] 50%|█████     | 5/10 [01:01<01:01, 12.35s/it] 60%|██████    | 6/10 [01:14<00:49, 12.34s/it] 70%|███████   | 7/10 [01:26<00:37, 12.39s/it] 80%|████████  | 8/10 [01:39<00:24, 12.39s/it] 90%|█████████ | 9/10 [01:51<00:12, 12.40s/it]100%|██████████| 10/10 [02:03<00:00, 12.43s/it]100%|██████████| 10/10 [02:03<00:00, 12.40s/it]
iteration:  167
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.98it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.3293639454188084
The final epsilon delta values after the training is over:  (1.3293639454188084, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3275862068965516, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:51, 12.37s/it] 20%|██        | 2/10 [00:24<01:38, 12.36s/it] 30%|███       | 3/10 [00:37<01:26, 12.35s/it] 40%|████      | 4/10 [00:49<01:14, 12.34s/it] 50%|█████     | 5/10 [01:01<01:01, 12.34s/it] 60%|██████    | 6/10 [01:14<00:49, 12.34s/it] 70%|███████   | 7/10 [01:26<00:37, 12.35s/it] 80%|████████  | 8/10 [01:38<00:24, 12.36s/it] 90%|█████████ | 9/10 [01:51<00:12, 12.44s/it]100%|██████████| 10/10 [02:03<00:00, 12.44s/it]100%|██████████| 10/10 [02:03<00:00, 12.39s/it]
iteration:  168
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.35it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.3293639454188084
The final epsilon delta values after the training is over:  (1.3293639454188084, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3275862068965516, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:51, 12.41s/it] 20%|██        | 2/10 [00:24<01:39, 12.48s/it] 30%|███       | 3/10 [00:37<01:27, 12.50s/it] 40%|████      | 4/10 [00:49<01:14, 12.45s/it] 50%|█████     | 5/10 [01:02<01:02, 12.46s/it] 60%|██████    | 6/10 [01:14<00:49, 12.44s/it] 70%|███████   | 7/10 [01:27<00:37, 12.48s/it] 80%|████████  | 8/10 [01:39<00:24, 12.47s/it] 90%|█████████ | 9/10 [01:52<00:12, 12.57s/it]100%|██████████| 10/10 [02:04<00:00, 12.53s/it]100%|██████████| 10/10 [02:04<00:00, 12.50s/it]
iteration:  169
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 53.43it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.3293639454188084
The final epsilon delta values after the training is over:  (1.3293639454188084, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3275862068965516, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:51, 12.44s/it] 20%|██        | 2/10 [00:24<01:39, 12.42s/it] 30%|███       | 3/10 [00:37<01:26, 12.40s/it] 40%|████      | 4/10 [00:49<01:14, 12.43s/it] 50%|█████     | 5/10 [01:02<01:02, 12.47s/it] 60%|██████    | 6/10 [01:14<00:49, 12.49s/it] 70%|███████   | 7/10 [01:27<00:37, 12.45s/it] 80%|████████  | 8/10 [01:39<00:24, 12.44s/it] 90%|█████████ | 9/10 [01:51<00:12, 12.43s/it]100%|██████████| 10/10 [02:04<00:00, 12.43s/it]100%|██████████| 10/10 [02:04<00:00, 12.44s/it]
iteration:  170
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.63it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.3293639454188084
The final epsilon delta values after the training is over:  (1.3293639454188084, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3275862068965516, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:52, 12.50s/it] 20%|██        | 2/10 [00:24<01:39, 12.50s/it] 30%|███       | 3/10 [00:37<01:27, 12.43s/it] 40%|████      | 4/10 [00:49<01:14, 12.41s/it] 50%|█████     | 5/10 [01:02<01:01, 12.39s/it] 60%|██████    | 6/10 [01:14<00:49, 12.38s/it] 70%|███████   | 7/10 [01:26<00:37, 12.39s/it] 80%|████████  | 8/10 [01:39<00:24, 12.40s/it] 90%|█████████ | 9/10 [01:51<00:12, 12.41s/it]100%|██████████| 10/10 [02:04<00:00, 12.40s/it]100%|██████████| 10/10 [02:04<00:00, 12.41s/it]
iteration:  171
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.42it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.2442729068833662
The final epsilon delta values after the training is over:  (1.2442729068833662, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3793103448275863, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:52, 12.45s/it] 20%|██        | 2/10 [00:25<01:40, 12.52s/it] 30%|███       | 3/10 [00:37<01:27, 12.49s/it] 40%|████      | 4/10 [00:49<01:14, 12.50s/it] 50%|█████     | 5/10 [01:02<01:02, 12.58s/it] 60%|██████    | 6/10 [01:15<00:50, 12.56s/it] 70%|███████   | 7/10 [01:27<00:37, 12.54s/it] 80%|████████  | 8/10 [01:40<00:25, 12.55s/it] 90%|█████████ | 9/10 [01:53<00:12, 12.60s/it]100%|██████████| 10/10 [02:05<00:00, 12.59s/it]100%|██████████| 10/10 [02:05<00:00, 12.56s/it]
iteration:  172
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.24it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.2442729068833662
The final epsilon delta values after the training is over:  (1.2442729068833662, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3793103448275863, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:51, 12.40s/it] 20%|██        | 2/10 [00:24<01:40, 12.50s/it] 30%|███       | 3/10 [00:37<01:27, 12.50s/it] 40%|████      | 4/10 [00:49<01:14, 12.49s/it] 50%|█████     | 5/10 [01:02<01:02, 12.50s/it] 60%|██████    | 6/10 [01:14<00:50, 12.51s/it] 70%|███████   | 7/10 [01:27<00:37, 12.48s/it] 80%|████████  | 8/10 [01:40<00:25, 12.54s/it] 90%|█████████ | 9/10 [01:52<00:12, 12.56s/it]100%|██████████| 10/10 [02:05<00:00, 12.53s/it]100%|██████████| 10/10 [02:05<00:00, 12.51s/it]
iteration:  173
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.50it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.2442729068833662
The final epsilon delta values after the training is over:  (1.2442729068833662, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3793103448275863, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:52, 12.52s/it] 20%|██        | 2/10 [00:25<01:40, 12.51s/it] 30%|███       | 3/10 [00:37<01:27, 12.51s/it] 40%|████      | 4/10 [00:50<01:15, 12.56s/it] 50%|█████     | 5/10 [01:02<01:02, 12.52s/it] 60%|██████    | 6/10 [01:15<00:50, 12.51s/it] 70%|███████   | 7/10 [01:27<00:37, 12.49s/it] 80%|████████  | 8/10 [01:40<00:25, 12.51s/it] 90%|█████████ | 9/10 [01:52<00:12, 12.52s/it]100%|██████████| 10/10 [02:05<00:00, 12.53s/it]100%|██████████| 10/10 [02:05<00:00, 12.52s/it]
iteration:  174
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.85it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.2442729068833662
The final epsilon delta values after the training is over:  (1.2442729068833662, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3793103448275863, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:53, 12.63s/it] 20%|██        | 2/10 [00:25<01:40, 12.52s/it] 30%|███       | 3/10 [00:37<01:27, 12.50s/it] 40%|████      | 4/10 [00:49<01:14, 12.48s/it] 50%|█████     | 5/10 [01:02<01:02, 12.51s/it] 60%|██████    | 6/10 [01:15<00:49, 12.50s/it] 70%|███████   | 7/10 [01:27<00:37, 12.54s/it] 80%|████████  | 8/10 [01:40<00:25, 12.62s/it] 90%|█████████ | 9/10 [01:52<00:12, 12.59s/it]100%|██████████| 10/10 [02:05<00:00, 12.58s/it]100%|██████████| 10/10 [02:05<00:00, 12.56s/it]
iteration:  175
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.93it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.2442729068833662
The final epsilon delta values after the training is over:  (1.2442729068833662, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3793103448275863, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:52, 12.52s/it] 20%|██        | 2/10 [00:25<01:40, 12.53s/it] 30%|███       | 3/10 [00:37<01:27, 12.54s/it] 40%|████      | 4/10 [00:50<01:15, 12.53s/it] 50%|█████     | 5/10 [01:02<01:02, 12.52s/it] 60%|██████    | 6/10 [01:15<00:50, 12.54s/it] 70%|███████   | 7/10 [01:27<00:37, 12.57s/it] 80%|████████  | 8/10 [01:40<00:25, 12.66s/it] 90%|█████████ | 9/10 [01:53<00:12, 12.61s/it]100%|██████████| 10/10 [02:05<00:00, 12.58s/it]100%|██████████| 10/10 [02:05<00:00, 12.57s/it]
iteration:  176
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 53.22it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.2442729068833662
The final epsilon delta values after the training is over:  (1.2442729068833662, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3793103448275863, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:54, 12.70s/it] 20%|██        | 2/10 [00:25<01:41, 12.64s/it] 30%|███       | 3/10 [00:37<01:28, 12.57s/it] 40%|████      | 4/10 [00:50<01:15, 12.57s/it] 50%|█████     | 5/10 [01:02<01:02, 12.53s/it] 60%|██████    | 6/10 [01:15<00:50, 12.51s/it] 70%|███████   | 7/10 [01:27<00:37, 12.51s/it] 80%|████████  | 8/10 [01:40<00:25, 12.51s/it] 90%|█████████ | 9/10 [01:52<00:12, 12.52s/it]100%|██████████| 10/10 [02:05<00:00, 12.52s/it]100%|██████████| 10/10 [02:05<00:00, 12.54s/it]
iteration:  177
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.82it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.2442729068833662
The final epsilon delta values after the training is over:  (1.2442729068833662, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3793103448275863, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:54, 12.68s/it] 20%|██        | 2/10 [00:25<01:41, 12.66s/it] 30%|███       | 3/10 [00:37<01:28, 12.61s/it] 40%|████      | 4/10 [00:50<01:15, 12.57s/it] 50%|█████     | 5/10 [01:02<01:02, 12.55s/it] 60%|██████    | 6/10 [01:15<00:50, 12.57s/it] 70%|███████   | 7/10 [01:28<00:37, 12.59s/it] 80%|████████  | 8/10 [01:40<00:25, 12.59s/it] 90%|█████████ | 9/10 [01:53<00:12, 12.59s/it]100%|██████████| 10/10 [02:05<00:00, 12.59s/it]100%|██████████| 10/10 [02:05<00:00, 12.59s/it]
iteration:  178
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.67it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.2442729068833662
The final epsilon delta values after the training is over:  (1.2442729068833662, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3793103448275863, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:53, 12.60s/it] 20%|██        | 2/10 [00:25<01:40, 12.59s/it] 30%|███       | 3/10 [00:37<01:28, 12.61s/it] 40%|████      | 4/10 [00:50<01:15, 12.59s/it] 50%|█████     | 5/10 [01:02<01:02, 12.59s/it] 60%|██████    | 6/10 [01:15<00:50, 12.61s/it] 70%|███████   | 7/10 [01:28<00:37, 12.62s/it] 80%|████████  | 8/10 [01:40<00:25, 12.62s/it] 90%|█████████ | 9/10 [01:53<00:12, 12.64s/it]100%|██████████| 10/10 [02:06<00:00, 12.61s/it]100%|██████████| 10/10 [02:06<00:00, 12.61s/it]
iteration:  179
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.35it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.2442729068833662
The final epsilon delta values after the training is over:  (1.2442729068833662, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3793103448275863, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:53, 12.61s/it] 20%|██        | 2/10 [00:25<01:40, 12.61s/it] 30%|███       | 3/10 [00:37<01:28, 12.64s/it] 40%|████      | 4/10 [00:50<01:15, 12.62s/it] 50%|█████     | 5/10 [01:03<01:03, 12.67s/it] 60%|██████    | 6/10 [01:15<00:50, 12.62s/it] 70%|███████   | 7/10 [01:28<00:37, 12.64s/it] 80%|████████  | 8/10 [01:41<00:25, 12.62s/it] 90%|█████████ | 9/10 [01:53<00:12, 12.66s/it]100%|██████████| 10/10 [02:06<00:00, 12.67s/it]100%|██████████| 10/10 [02:06<00:00, 12.65s/it]
iteration:  180
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.14it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.2442729068833662
The final epsilon delta values after the training is over:  (1.2442729068833662, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3793103448275863, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:53, 12.59s/it] 20%|██        | 2/10 [00:25<01:40, 12.61s/it] 30%|███       | 3/10 [00:37<01:28, 12.59s/it] 40%|████      | 4/10 [00:50<01:15, 12.61s/it] 50%|█████     | 5/10 [01:02<01:02, 12.60s/it] 60%|██████    | 6/10 [01:15<00:50, 12.60s/it] 70%|███████   | 7/10 [01:28<00:37, 12.60s/it] 80%|████████  | 8/10 [01:40<00:25, 12.64s/it] 90%|█████████ | 9/10 [01:53<00:12, 12.68s/it]100%|██████████| 10/10 [02:06<00:00, 12.67s/it]100%|██████████| 10/10 [02:06<00:00, 12.63s/it]
iteration:  181
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.76it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1733379813769553
The final epsilon delta values after the training is over:  (1.1733379813769553, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4310344827586206, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:53, 12.59s/it] 20%|██        | 2/10 [00:25<01:40, 12.60s/it] 30%|███       | 3/10 [00:38<01:29, 12.77s/it] 40%|████      | 4/10 [00:50<01:16, 12.76s/it] 50%|█████     | 5/10 [01:03<01:03, 12.70s/it] 60%|██████    | 6/10 [01:16<00:50, 12.66s/it] 70%|███████   | 7/10 [01:28<00:37, 12.65s/it] 80%|████████  | 8/10 [01:41<00:25, 12.64s/it] 90%|█████████ | 9/10 [01:53<00:12, 12.64s/it]100%|██████████| 10/10 [02:06<00:00, 12.69s/it]100%|██████████| 10/10 [02:06<00:00, 12.68s/it]
iteration:  182
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.72it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1733379813769553
The final epsilon delta values after the training is over:  (1.1733379813769553, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4310344827586206, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:54, 12.75s/it] 20%|██        | 2/10 [00:25<01:42, 12.78s/it] 30%|███       | 3/10 [00:38<01:29, 12.75s/it] 40%|████      | 4/10 [00:51<01:16, 12.75s/it] 50%|█████     | 5/10 [01:03<01:03, 12.72s/it] 60%|██████    | 6/10 [01:16<00:50, 12.68s/it] 70%|███████   | 7/10 [01:28<00:37, 12.66s/it] 80%|████████  | 8/10 [01:41<00:25, 12.66s/it] 90%|█████████ | 9/10 [01:54<00:12, 12.66s/it]100%|██████████| 10/10 [02:07<00:00, 12.72s/it]100%|██████████| 10/10 [02:07<00:00, 12.71s/it]
iteration:  183
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.34it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1733379813769553
The final epsilon delta values after the training is over:  (1.1733379813769553, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4310344827586206, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:54, 12.68s/it] 20%|██        | 2/10 [00:25<01:41, 12.65s/it] 30%|███       | 3/10 [00:37<01:28, 12.64s/it] 40%|████      | 4/10 [00:50<01:16, 12.69s/it] 50%|█████     | 5/10 [01:03<01:03, 12.72s/it] 60%|██████    | 6/10 [01:16<00:50, 12.72s/it] 70%|███████   | 7/10 [01:28<00:38, 12.73s/it] 80%|████████  | 8/10 [01:41<00:25, 12.72s/it] 90%|█████████ | 9/10 [01:54<00:12, 12.76s/it]100%|██████████| 10/10 [02:07<00:00, 12.78s/it]100%|██████████| 10/10 [02:07<00:00, 12.73s/it]
iteration:  184
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.20it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1733379813769553
The final epsilon delta values after the training is over:  (1.1733379813769553, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4310344827586206, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:53, 12.66s/it] 20%|██        | 2/10 [00:25<01:41, 12.73s/it] 30%|███       | 3/10 [00:38<01:29, 12.76s/it] 40%|████      | 4/10 [00:50<01:16, 12.75s/it] 50%|█████     | 5/10 [01:03<01:03, 12.76s/it] 60%|██████    | 6/10 [01:16<00:50, 12.72s/it] 70%|███████   | 7/10 [01:29<00:38, 12.73s/it] 80%|████████  | 8/10 [01:42<00:25, 12.79s/it] 90%|█████████ | 9/10 [01:54<00:12, 12.76s/it]100%|██████████| 10/10 [02:07<00:00, 12.81s/it]100%|██████████| 10/10 [02:07<00:00, 12.77s/it]
iteration:  185
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.62it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1733379813769553
The final epsilon delta values after the training is over:  (1.1733379813769553, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4310344827586206, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:54, 12.68s/it] 20%|██        | 2/10 [00:25<01:41, 12.72s/it] 30%|███       | 3/10 [00:38<01:28, 12.67s/it] 40%|████      | 4/10 [00:50<01:15, 12.66s/it] 50%|█████     | 5/10 [01:03<01:03, 12.69s/it] 60%|██████    | 6/10 [01:16<00:50, 12.70s/it] 70%|███████   | 7/10 [01:28<00:38, 12.73s/it] 80%|████████  | 8/10 [01:41<00:25, 12.70s/it] 90%|█████████ | 9/10 [01:54<00:12, 12.69s/it]100%|██████████| 10/10 [02:06<00:00, 12.69s/it]100%|██████████| 10/10 [02:06<00:00, 12.69s/it]
iteration:  186
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.07it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1733379813769553
The final epsilon delta values after the training is over:  (1.1733379813769553, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4310344827586206, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:54, 12.71s/it] 20%|██        | 2/10 [00:25<01:41, 12.68s/it] 30%|███       | 3/10 [00:38<01:29, 12.80s/it] 40%|████      | 4/10 [00:51<01:16, 12.81s/it] 50%|█████     | 5/10 [01:03<01:03, 12.79s/it] 60%|██████    | 6/10 [01:16<00:51, 12.76s/it] 70%|███████   | 7/10 [01:29<00:38, 12.79s/it] 80%|████████  | 8/10 [01:42<00:25, 12.78s/it] 90%|█████████ | 9/10 [01:54<00:12, 12.76s/it]100%|██████████| 10/10 [02:07<00:00, 12.80s/it]100%|██████████| 10/10 [02:07<00:00, 12.78s/it]
iteration:  187
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.05it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1733379813769553
The final epsilon delta values after the training is over:  (1.1733379813769553, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4310344827586206, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:54, 12.73s/it] 20%|██        | 2/10 [00:25<01:42, 12.75s/it] 30%|███       | 3/10 [00:38<01:29, 12.75s/it] 40%|████      | 4/10 [00:51<01:16, 12.75s/it] 50%|█████     | 5/10 [01:03<01:03, 12.74s/it] 60%|██████    | 6/10 [01:16<00:50, 12.72s/it] 70%|███████   | 7/10 [01:29<00:38, 12.72s/it] 80%|████████  | 8/10 [01:42<00:25, 12.77s/it] 90%|█████████ | 9/10 [01:54<00:12, 12.77s/it]100%|██████████| 10/10 [02:07<00:00, 12.78s/it]100%|██████████| 10/10 [02:07<00:00, 12.76s/it]
iteration:  188
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.06it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1733379813769553
The final epsilon delta values after the training is over:  (1.1733379813769553, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4310344827586206, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:54, 12.71s/it] 20%|██        | 2/10 [00:25<01:41, 12.67s/it] 30%|███       | 3/10 [00:37<01:28, 12.66s/it] 40%|████      | 4/10 [00:50<01:15, 12.66s/it] 50%|█████     | 5/10 [01:03<01:03, 12.65s/it] 60%|██████    | 6/10 [01:15<00:50, 12.67s/it] 70%|███████   | 7/10 [01:28<00:38, 12.70s/it] 80%|████████  | 8/10 [01:41<00:25, 12.74s/it] 90%|█████████ | 9/10 [01:54<00:12, 12.74s/it]100%|██████████| 10/10 [02:07<00:00, 12.76s/it]100%|██████████| 10/10 [02:07<00:00, 12.71s/it]
iteration:  189
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.78it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1733379813769553
The final epsilon delta values after the training is over:  (1.1733379813769553, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4310344827586206, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:54, 12.71s/it] 20%|██        | 2/10 [00:25<01:41, 12.70s/it] 30%|███       | 3/10 [00:38<01:28, 12.68s/it] 40%|████      | 4/10 [00:50<01:16, 12.68s/it] 50%|█████     | 5/10 [01:03<01:03, 12.69s/it] 60%|██████    | 6/10 [01:16<00:50, 12.71s/it] 70%|███████   | 7/10 [01:29<00:38, 12.76s/it] 80%|████████  | 8/10 [01:41<00:25, 12.82s/it] 90%|█████████ | 9/10 [01:54<00:12, 12.82s/it]100%|██████████| 10/10 [02:07<00:00, 12.88s/it]100%|██████████| 10/10 [02:07<00:00, 12.78s/it]
iteration:  190
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.54it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1733379813769553
The final epsilon delta values after the training is over:  (1.1733379813769553, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4310344827586206, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:53, 12.66s/it] 20%|██        | 2/10 [00:25<01:41, 12.72s/it] 30%|███       | 3/10 [00:38<01:28, 12.69s/it] 40%|████      | 4/10 [00:50<01:16, 12.74s/it] 50%|█████     | 5/10 [01:03<01:03, 12.71s/it] 60%|██████    | 6/10 [01:16<00:50, 12.69s/it] 70%|███████   | 7/10 [01:28<00:38, 12.69s/it] 80%|████████  | 8/10 [01:41<00:25, 12.68s/it] 90%|█████████ | 9/10 [01:54<00:12, 12.68s/it]100%|██████████| 10/10 [02:06<00:00, 12.68s/it]100%|██████████| 10/10 [02:06<00:00, 12.69s/it]
iteration:  191
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.97it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1138372721283347
The final epsilon delta values after the training is over:  (1.1138372721283347, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4827586206896552, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:54, 12.68s/it] 20%|██        | 2/10 [00:25<01:42, 12.80s/it] 30%|███       | 3/10 [00:38<01:29, 12.74s/it] 40%|████      | 4/10 [00:51<01:16, 12.77s/it] 50%|█████     | 5/10 [01:04<01:04, 12.84s/it] 60%|██████    | 6/10 [01:16<00:51, 12.80s/it] 70%|███████   | 7/10 [01:29<00:38, 12.78s/it] 80%|████████  | 8/10 [01:42<00:25, 12.78s/it] 90%|█████████ | 9/10 [01:54<00:12, 12.76s/it]100%|██████████| 10/10 [02:07<00:00, 12.75s/it]100%|██████████| 10/10 [02:07<00:00, 12.77s/it]
iteration:  192
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.86it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1138372721283347
The final epsilon delta values after the training is over:  (1.1138372721283347, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4827586206896552, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:55, 12.79s/it] 20%|██        | 2/10 [00:25<01:42, 12.76s/it] 30%|███       | 3/10 [00:38<01:29, 12.79s/it] 40%|████      | 4/10 [00:51<01:16, 12.75s/it] 50%|█████     | 5/10 [01:03<01:03, 12.76s/it] 60%|██████    | 6/10 [01:16<00:51, 12.77s/it] 70%|███████   | 7/10 [01:29<00:38, 12.77s/it] 80%|████████  | 8/10 [01:42<00:25, 12.76s/it] 90%|█████████ | 9/10 [01:54<00:12, 12.75s/it]100%|██████████| 10/10 [02:07<00:00, 12.74s/it]100%|██████████| 10/10 [02:07<00:00, 12.76s/it]
iteration:  193
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.18it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1138372721283347
The final epsilon delta values after the training is over:  (1.1138372721283347, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4827586206896552, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:54, 12.76s/it] 20%|██        | 2/10 [00:25<01:41, 12.73s/it] 30%|███       | 3/10 [00:38<01:29, 12.72s/it] 40%|████      | 4/10 [00:50<01:16, 12.73s/it] 50%|█████     | 5/10 [01:03<01:04, 12.82s/it] 60%|██████    | 6/10 [01:20<00:57, 14.27s/it] 70%|███████   | 7/10 [01:37<00:45, 15.12s/it] 80%|████████  | 8/10 [01:52<00:30, 15.02s/it] 90%|█████████ | 9/10 [02:06<00:14, 14.58s/it]100%|██████████| 10/10 [02:19<00:00, 14.13s/it]100%|██████████| 10/10 [02:19<00:00, 13.94s/it]
iteration:  194
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.30it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1138372721283347
The final epsilon delta values after the training is over:  (1.1138372721283347, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4827586206896552, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:06, 14.00s/it] 20%|██        | 2/10 [00:27<01:48, 13.52s/it] 30%|███       | 3/10 [00:39<01:32, 13.15s/it] 40%|████      | 4/10 [00:52<01:17, 12.97s/it] 50%|█████     | 5/10 [01:05<01:04, 12.88s/it] 60%|██████    | 6/10 [01:17<00:51, 12.81s/it] 70%|███████   | 7/10 [01:30<00:38, 12.84s/it] 80%|████████  | 8/10 [01:43<00:25, 12.85s/it] 90%|█████████ | 9/10 [01:56<00:12, 12.89s/it]100%|██████████| 10/10 [02:09<00:00, 12.88s/it]100%|██████████| 10/10 [02:09<00:00, 12.96s/it]
iteration:  195
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.78it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1138372721283347
The final epsilon delta values after the training is over:  (1.1138372721283347, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4827586206896552, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:54, 12.74s/it] 20%|██        | 2/10 [00:25<01:41, 12.73s/it] 30%|███       | 3/10 [00:38<01:29, 12.74s/it] 40%|████      | 4/10 [00:51<01:16, 12.78s/it] 50%|█████     | 5/10 [01:03<01:03, 12.77s/it] 60%|██████    | 6/10 [01:16<00:51, 12.76s/it] 70%|███████   | 7/10 [01:29<00:38, 12.76s/it] 80%|████████  | 8/10 [01:42<00:25, 12.78s/it] 90%|█████████ | 9/10 [01:54<00:12, 12.78s/it]100%|██████████| 10/10 [02:07<00:00, 12.79s/it]100%|██████████| 10/10 [02:07<00:00, 12.77s/it]
iteration:  196
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.41it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1138372721283347
The final epsilon delta values after the training is over:  (1.1138372721283347, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4827586206896552, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:54, 12.74s/it] 20%|██        | 2/10 [00:25<01:42, 12.79s/it] 30%|███       | 3/10 [00:38<01:29, 12.77s/it] 40%|████      | 4/10 [00:51<01:16, 12.77s/it] 50%|█████     | 5/10 [01:04<01:04, 12.83s/it] 60%|██████    | 6/10 [01:16<00:51, 12.85s/it] 70%|███████   | 7/10 [01:29<00:38, 12.85s/it] 80%|████████  | 8/10 [01:42<00:25, 12.85s/it] 90%|█████████ | 9/10 [01:55<00:12, 12.88s/it]100%|██████████| 10/10 [02:08<00:00, 12.88s/it]100%|██████████| 10/10 [02:08<00:00, 12.84s/it]
iteration:  197
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.84it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1138372721283347
The final epsilon delta values after the training is over:  (1.1138372721283347, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4827586206896552, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:56, 12.92s/it] 20%|██        | 2/10 [00:25<01:43, 12.88s/it] 30%|███       | 3/10 [00:38<01:30, 12.86s/it] 40%|████      | 4/10 [00:51<01:17, 12.85s/it] 50%|█████     | 5/10 [01:04<01:04, 12.88s/it] 60%|██████    | 6/10 [01:17<00:51, 12.89s/it] 70%|███████   | 7/10 [01:30<00:38, 12.93s/it] 80%|████████  | 8/10 [01:43<00:25, 12.89s/it] 90%|█████████ | 9/10 [01:55<00:12, 12.86s/it]100%|██████████| 10/10 [02:08<00:00, 12.86s/it]100%|██████████| 10/10 [02:08<00:00, 12.88s/it]
iteration:  198
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.09it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1138372721283347
The final epsilon delta values after the training is over:  (1.1138372721283347, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4827586206896552, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:55, 12.82s/it] 20%|██        | 2/10 [00:25<01:42, 12.81s/it] 30%|███       | 3/10 [00:38<01:30, 12.86s/it] 40%|████      | 4/10 [00:51<01:17, 12.91s/it] 50%|█████     | 5/10 [01:04<01:04, 12.94s/it] 60%|██████    | 6/10 [01:17<00:52, 13.01s/it] 70%|███████   | 7/10 [01:30<00:38, 12.95s/it] 80%|████████  | 8/10 [01:43<00:25, 12.92s/it] 90%|█████████ | 9/10 [01:56<00:12, 12.89s/it]100%|██████████| 10/10 [02:08<00:00, 12.87s/it]100%|██████████| 10/10 [02:08<00:00, 12.90s/it]
iteration:  199
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.75it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1138372721283347
The final epsilon delta values after the training is over:  (1.1138372721283347, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4827586206896552, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:55, 12.85s/it] 20%|██        | 2/10 [00:25<01:43, 12.91s/it] 30%|███       | 3/10 [00:38<01:30, 12.93s/it] 40%|████      | 4/10 [00:51<01:17, 12.90s/it] 50%|█████     | 5/10 [01:04<01:04, 12.89s/it] 60%|██████    | 6/10 [01:17<00:51, 12.90s/it] 70%|███████   | 7/10 [01:30<00:38, 12.93s/it] 80%|████████  | 8/10 [01:43<00:25, 12.90s/it] 90%|█████████ | 9/10 [01:56<00:12, 12.92s/it]100%|██████████| 10/10 [02:09<00:00, 12.93s/it]100%|██████████| 10/10 [02:09<00:00, 12.91s/it]
iteration:  200
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.93it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1138372721283347
The final epsilon delta values after the training is over:  (1.1138372721283347, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4827586206896552, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:57, 13.08s/it] 20%|██        | 2/10 [00:25<01:43, 12.95s/it] 30%|███       | 3/10 [00:38<01:30, 12.97s/it] 40%|████      | 4/10 [00:51<01:17, 12.99s/it] 50%|█████     | 5/10 [01:04<01:04, 12.95s/it] 60%|██████    | 6/10 [01:17<00:51, 12.93s/it] 70%|███████   | 7/10 [01:30<00:38, 12.92s/it] 80%|████████  | 8/10 [01:43<00:25, 12.97s/it] 90%|█████████ | 9/10 [01:56<00:12, 12.94s/it]100%|██████████| 10/10 [02:09<00:00, 12.93s/it]100%|██████████| 10/10 [02:09<00:00, 12.95s/it]
iteration:  201
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.34it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0630957485927064
The final epsilon delta values after the training is over:  (1.0630957485927064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5344827586206897, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:55, 12.87s/it] 20%|██        | 2/10 [00:25<01:42, 12.87s/it] 30%|███       | 3/10 [00:38<01:30, 12.94s/it] 40%|████      | 4/10 [00:51<01:17, 12.92s/it] 50%|█████     | 5/10 [01:04<01:04, 12.93s/it] 60%|██████    | 6/10 [01:17<00:51, 12.92s/it] 70%|███████   | 7/10 [01:30<00:38, 12.93s/it] 80%|████████  | 8/10 [01:43<00:25, 12.92s/it] 90%|█████████ | 9/10 [01:56<00:12, 12.96s/it]100%|██████████| 10/10 [02:09<00:00, 12.99s/it]100%|██████████| 10/10 [02:09<00:00, 12.94s/it]
iteration:  202
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.75it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0630957485927064
The final epsilon delta values after the training is over:  (1.0630957485927064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5344827586206897, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:57, 13.02s/it] 20%|██        | 2/10 [00:25<01:43, 12.95s/it] 30%|███       | 3/10 [00:38<01:30, 12.94s/it] 40%|████      | 4/10 [00:51<01:17, 12.91s/it] 50%|█████     | 5/10 [01:04<01:04, 12.91s/it] 60%|██████    | 6/10 [01:17<00:51, 12.93s/it] 70%|███████   | 7/10 [01:30<00:38, 13.00s/it] 80%|████████  | 8/10 [01:43<00:26, 13.00s/it] 90%|█████████ | 9/10 [01:56<00:13, 13.02s/it]100%|██████████| 10/10 [02:09<00:00, 13.04s/it]100%|██████████| 10/10 [02:09<00:00, 12.99s/it]
iteration:  203
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 55.66it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0630957485927064
The final epsilon delta values after the training is over:  (1.0630957485927064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5344827586206897, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:56, 12.98s/it] 20%|██        | 2/10 [00:25<01:43, 12.95s/it] 30%|███       | 3/10 [00:38<01:30, 12.95s/it] 40%|████      | 4/10 [00:51<01:17, 12.94s/it] 50%|█████     | 5/10 [01:04<01:04, 12.93s/it] 60%|██████    | 6/10 [01:17<00:51, 12.93s/it] 70%|███████   | 7/10 [01:30<00:38, 12.94s/it] 80%|████████  | 8/10 [01:43<00:25, 12.94s/it] 90%|█████████ | 9/10 [01:56<00:12, 12.94s/it]100%|██████████| 10/10 [02:09<00:00, 12.94s/it]100%|██████████| 10/10 [02:09<00:00, 12.94s/it]
iteration:  204
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.00it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0630957485927064
The final epsilon delta values after the training is over:  (1.0630957485927064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5344827586206897, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:56, 12.95s/it] 20%|██        | 2/10 [00:25<01:43, 12.95s/it] 30%|███       | 3/10 [00:38<01:30, 12.98s/it] 40%|████      | 4/10 [00:52<01:18, 13.02s/it] 50%|█████     | 5/10 [01:05<01:05, 13.06s/it] 60%|██████    | 6/10 [01:18<00:52, 13.04s/it] 70%|███████   | 7/10 [01:31<00:39, 13.04s/it] 80%|████████  | 8/10 [01:44<00:26, 13.08s/it] 90%|█████████ | 9/10 [01:57<00:13, 13.05s/it]100%|██████████| 10/10 [02:10<00:00, 13.06s/it]100%|██████████| 10/10 [02:10<00:00, 13.04s/it]
iteration:  205
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.19it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0630957485927064
The final epsilon delta values after the training is over:  (1.0630957485927064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5344827586206897, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:57, 13.03s/it] 20%|██        | 2/10 [00:26<01:45, 13.13s/it] 30%|███       | 3/10 [00:39<01:31, 13.09s/it] 40%|████      | 4/10 [00:52<01:18, 13.06s/it] 50%|█████     | 5/10 [01:05<01:05, 13.08s/it] 60%|██████    | 6/10 [01:18<00:52, 13.06s/it] 70%|███████   | 7/10 [01:31<00:39, 13.04s/it] 80%|████████  | 8/10 [01:44<00:26, 13.03s/it] 90%|█████████ | 9/10 [01:57<00:13, 13.03s/it]100%|██████████| 10/10 [02:10<00:00, 13.05s/it]100%|██████████| 10/10 [02:10<00:00, 13.06s/it]
iteration:  206
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.55it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0630957485927064
The final epsilon delta values after the training is over:  (1.0630957485927064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5344827586206897, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:57, 13.02s/it] 20%|██        | 2/10 [00:25<01:43, 12.99s/it] 30%|███       | 3/10 [00:38<01:30, 12.99s/it] 40%|████      | 4/10 [00:52<01:18, 13.05s/it] 50%|█████     | 5/10 [01:05<01:05, 13.06s/it] 60%|██████    | 6/10 [01:18<00:52, 13.05s/it] 70%|███████   | 7/10 [01:31<00:39, 13.05s/it] 80%|████████  | 8/10 [01:44<00:26, 13.06s/it] 90%|█████████ | 9/10 [01:57<00:13, 13.07s/it]100%|██████████| 10/10 [02:10<00:00, 13.11s/it]100%|██████████| 10/10 [02:10<00:00, 13.06s/it]
iteration:  207
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.44it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0630957485927064
The final epsilon delta values after the training is over:  (1.0630957485927064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5344827586206897, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:57, 13.07s/it] 20%|██        | 2/10 [00:26<01:44, 13.06s/it] 30%|███       | 3/10 [00:39<01:31, 13.06s/it] 40%|████      | 4/10 [00:52<01:18, 13.05s/it] 50%|█████     | 5/10 [01:05<01:05, 13.04s/it] 60%|██████    | 6/10 [01:18<00:52, 13.08s/it] 70%|███████   | 7/10 [01:31<00:39, 13.09s/it] 80%|████████  | 8/10 [01:44<00:26, 13.12s/it] 90%|█████████ | 9/10 [01:58<00:13, 13.25s/it]100%|██████████| 10/10 [02:11<00:00, 13.20s/it]100%|██████████| 10/10 [02:11<00:00, 13.13s/it]
iteration:  208
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 55.50it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0630957485927064
The final epsilon delta values after the training is over:  (1.0630957485927064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5344827586206897, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:57, 13.06s/it] 20%|██        | 2/10 [00:26<01:44, 13.05s/it] 30%|███       | 3/10 [00:39<01:31, 13.04s/it] 40%|████      | 4/10 [00:52<01:18, 13.05s/it] 50%|█████     | 5/10 [01:05<01:05, 13.05s/it] 60%|██████    | 6/10 [01:18<00:52, 13.09s/it] 70%|███████   | 7/10 [01:31<00:39, 13.07s/it] 80%|████████  | 8/10 [01:44<00:26, 13.10s/it] 90%|█████████ | 9/10 [01:57<00:13, 13.13s/it]100%|██████████| 10/10 [02:10<00:00, 13.11s/it]100%|██████████| 10/10 [02:10<00:00, 13.09s/it]
iteration:  209
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.71it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0630957485927064
The final epsilon delta values after the training is over:  (1.0630957485927064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5344827586206897, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:57, 13.05s/it] 20%|██        | 2/10 [00:26<01:44, 13.04s/it] 30%|███       | 3/10 [00:39<01:31, 13.05s/it] 40%|████      | 4/10 [00:52<01:18, 13.06s/it] 50%|█████     | 5/10 [01:05<01:05, 13.05s/it] 60%|██████    | 6/10 [01:18<00:52, 13.04s/it] 70%|███████   | 7/10 [01:31<00:39, 13.06s/it] 80%|████████  | 8/10 [01:44<00:26, 13.06s/it] 90%|█████████ | 9/10 [01:57<00:13, 13.07s/it]100%|██████████| 10/10 [02:10<00:00, 13.09s/it]100%|██████████| 10/10 [02:10<00:00, 13.07s/it]
iteration:  210
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.41it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0630957485927064
The final epsilon delta values after the training is over:  (1.0630957485927064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5344827586206897, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:57, 13.06s/it] 20%|██        | 2/10 [00:26<01:44, 13.06s/it] 30%|███       | 3/10 [00:39<01:31, 13.05s/it] 40%|████      | 4/10 [00:52<01:18, 13.04s/it] 50%|█████     | 5/10 [01:05<01:05, 13.04s/it] 60%|██████    | 6/10 [01:18<00:52, 13.04s/it] 70%|███████   | 7/10 [01:31<00:39, 13.05s/it] 80%|████████  | 8/10 [01:44<00:26, 13.06s/it] 90%|█████████ | 9/10 [01:57<00:13, 13.06s/it]100%|██████████| 10/10 [02:10<00:00, 13.07s/it]100%|██████████| 10/10 [02:10<00:00, 13.06s/it]
iteration:  211
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 55.95it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0172588764126955
The final epsilon delta values after the training is over:  (1.0172588764126955, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5862068965517242, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:57, 13.10s/it] 20%|██        | 2/10 [00:26<01:44, 13.09s/it] 30%|███       | 3/10 [00:39<01:31, 13.08s/it] 40%|████      | 4/10 [00:52<01:18, 13.08s/it] 50%|█████     | 5/10 [01:05<01:05, 13.09s/it] 60%|██████    | 6/10 [01:18<00:52, 13.08s/it] 70%|███████   | 7/10 [01:31<00:39, 13.10s/it] 80%|████████  | 8/10 [01:44<00:26, 13.11s/it] 90%|█████████ | 9/10 [01:57<00:13, 13.14s/it]100%|██████████| 10/10 [02:11<00:00, 13.13s/it]100%|██████████| 10/10 [02:11<00:00, 13.11s/it]
iteration:  212
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.20it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0172588764126955
The final epsilon delta values after the training is over:  (1.0172588764126955, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5862068965517242, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:57, 13.08s/it] 20%|██        | 2/10 [00:26<01:44, 13.09s/it] 30%|███       | 3/10 [00:39<01:31, 13.09s/it] 40%|████      | 4/10 [00:52<01:18, 13.13s/it] 50%|█████     | 5/10 [01:05<01:05, 13.12s/it] 60%|██████    | 6/10 [01:18<00:52, 13.14s/it] 70%|███████   | 7/10 [01:31<00:39, 13.17s/it] 80%|████████  | 8/10 [01:45<00:26, 13.17s/it] 90%|█████████ | 9/10 [01:58<00:13, 13.19s/it]100%|██████████| 10/10 [02:11<00:00, 13.17s/it]100%|██████████| 10/10 [02:11<00:00, 13.15s/it]
iteration:  213
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.76it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0172588764126955
The final epsilon delta values after the training is over:  (1.0172588764126955, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5862068965517242, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:58, 13.16s/it] 20%|██        | 2/10 [00:26<01:45, 13.15s/it] 30%|███       | 3/10 [00:39<01:32, 13.24s/it] 40%|████      | 4/10 [00:52<01:19, 13.23s/it] 50%|█████     | 5/10 [01:06<01:06, 13.22s/it] 60%|██████    | 6/10 [01:19<00:53, 13.26s/it] 70%|███████   | 7/10 [01:32<00:39, 13.24s/it] 80%|████████  | 8/10 [01:45<00:26, 13.23s/it] 90%|█████████ | 9/10 [01:59<00:13, 13.26s/it]100%|██████████| 10/10 [02:12<00:00, 13.24s/it]100%|██████████| 10/10 [02:12<00:00, 13.23s/it]
iteration:  214
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.33it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0172588764126955
The final epsilon delta values after the training is over:  (1.0172588764126955, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5862068965517242, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:58, 13.12s/it] 20%|██        | 2/10 [00:26<01:46, 13.33s/it] 30%|███       | 3/10 [00:39<01:32, 13.22s/it] 40%|████      | 4/10 [00:52<01:19, 13.17s/it] 50%|█████     | 5/10 [01:05<01:05, 13.15s/it] 60%|██████    | 6/10 [01:19<00:52, 13.14s/it] 70%|███████   | 7/10 [01:32<00:39, 13.17s/it] 80%|████████  | 8/10 [01:45<00:26, 13.22s/it] 90%|█████████ | 9/10 [01:58<00:13, 13.19s/it]100%|██████████| 10/10 [02:11<00:00, 13.21s/it]100%|██████████| 10/10 [02:11<00:00, 13.19s/it]
iteration:  215
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 54.68it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0172588764126955
The final epsilon delta values after the training is over:  (1.0172588764126955, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5862068965517242, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:00, 13.34s/it] 20%|██        | 2/10 [00:26<01:46, 13.26s/it] 30%|███       | 3/10 [00:39<01:33, 13.33s/it] 40%|████      | 4/10 [00:53<01:19, 13.30s/it] 50%|█████     | 5/10 [01:06<01:06, 13.30s/it] 60%|██████    | 6/10 [01:19<00:53, 13.28s/it] 70%|███████   | 7/10 [01:32<00:39, 13.24s/it] 80%|████████  | 8/10 [01:46<00:26, 13.22s/it] 90%|█████████ | 9/10 [01:59<00:13, 13.20s/it]100%|██████████| 10/10 [02:12<00:00, 13.18s/it]100%|██████████| 10/10 [02:12<00:00, 13.24s/it]
iteration:  216
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 55.30it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0172588764126955
The final epsilon delta values after the training is over:  (1.0172588764126955, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5862068965517242, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:58, 13.14s/it] 20%|██        | 2/10 [00:26<01:45, 13.16s/it] 30%|███       | 3/10 [00:39<01:31, 13.14s/it] 40%|████      | 4/10 [00:52<01:18, 13.13s/it] 50%|█████     | 5/10 [01:05<01:05, 13.13s/it] 60%|██████    | 6/10 [01:18<00:52, 13.19s/it] 70%|███████   | 7/10 [01:32<00:39, 13.25s/it] 80%|████████  | 8/10 [01:45<00:26, 13.25s/it] 90%|█████████ | 9/10 [01:58<00:13, 13.24s/it]100%|██████████| 10/10 [02:12<00:00, 13.24s/it]100%|██████████| 10/10 [02:12<00:00, 13.21s/it]
iteration:  217
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.08it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0172588764126955
The final epsilon delta values after the training is over:  (1.0172588764126955, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5862068965517242, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:59, 13.28s/it] 20%|██        | 2/10 [00:26<01:45, 13.24s/it] 30%|███       | 3/10 [00:39<01:32, 13.22s/it] 40%|████      | 4/10 [00:52<01:19, 13.24s/it] 50%|█████     | 5/10 [01:06<01:06, 13.30s/it] 60%|██████    | 6/10 [01:19<00:53, 13.31s/it] 70%|███████   | 7/10 [01:32<00:39, 13.27s/it] 80%|████████  | 8/10 [01:46<00:26, 13.25s/it] 90%|█████████ | 9/10 [01:59<00:13, 13.24s/it]100%|██████████| 10/10 [02:12<00:00, 13.24s/it]100%|██████████| 10/10 [02:12<00:00, 13.26s/it]
iteration:  218
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.29it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0172588764126955
The final epsilon delta values after the training is over:  (1.0172588764126955, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5862068965517242, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:58, 13.17s/it] 20%|██        | 2/10 [00:26<01:45, 13.16s/it] 30%|███       | 3/10 [00:39<01:32, 13.16s/it] 40%|████      | 4/10 [00:52<01:18, 13.17s/it] 50%|█████     | 5/10 [01:05<01:05, 13.16s/it] 60%|██████    | 6/10 [01:18<00:52, 13.17s/it] 70%|███████   | 7/10 [01:32<00:39, 13.18s/it] 80%|████████  | 8/10 [01:45<00:26, 13.19s/it] 90%|█████████ | 9/10 [01:58<00:13, 13.19s/it]100%|██████████| 10/10 [02:11<00:00, 13.20s/it]100%|██████████| 10/10 [02:11<00:00, 13.18s/it]
iteration:  219
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.67it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0172588764126955
The final epsilon delta values after the training is over:  (1.0172588764126955, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5862068965517242, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:59, 13.26s/it] 20%|██        | 2/10 [00:26<01:46, 13.30s/it] 30%|███       | 3/10 [00:39<01:33, 13.30s/it] 40%|████      | 4/10 [00:53<01:19, 13.29s/it] 50%|█████     | 5/10 [01:06<01:07, 13.41s/it] 60%|██████    | 6/10 [01:19<00:53, 13.35s/it] 70%|███████   | 7/10 [01:33<00:40, 13.40s/it] 80%|████████  | 8/10 [01:46<00:26, 13.37s/it] 90%|█████████ | 9/10 [02:00<00:13, 13.32s/it]100%|██████████| 10/10 [02:13<00:00, 13.29s/it]100%|██████████| 10/10 [02:13<00:00, 13.32s/it]
iteration:  220
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.68it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0172588764126955
The final epsilon delta values after the training is over:  (1.0172588764126955, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5862068965517242, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:58, 13.18s/it] 20%|██        | 2/10 [00:26<01:45, 13.18s/it] 30%|███       | 3/10 [00:39<01:32, 13.17s/it] 40%|████      | 4/10 [00:52<01:19, 13.17s/it] 50%|█████     | 5/10 [01:05<01:05, 13.17s/it] 60%|██████    | 6/10 [01:19<00:52, 13.21s/it] 70%|███████   | 7/10 [01:32<00:39, 13.21s/it] 80%|████████  | 8/10 [01:45<00:26, 13.24s/it] 90%|█████████ | 9/10 [01:59<00:13, 13.28s/it]100%|██████████| 10/10 [02:12<00:00, 13.26s/it]100%|██████████| 10/10 [02:12<00:00, 13.22s/it]
iteration:  221
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 55.40it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9758025205260582
The final epsilon delta values after the training is over:  (0.9758025205260582, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6379310344827587, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:59, 13.23s/it] 20%|██        | 2/10 [00:26<01:45, 13.23s/it] 30%|███       | 3/10 [00:39<01:32, 13.26s/it] 40%|████      | 4/10 [00:53<01:19, 13.27s/it] 50%|█████     | 5/10 [01:06<01:06, 13.28s/it] 60%|██████    | 6/10 [01:19<00:53, 13.31s/it] 70%|███████   | 7/10 [01:33<00:39, 13.31s/it] 80%|████████  | 8/10 [01:46<00:26, 13.35s/it] 90%|█████████ | 9/10 [01:59<00:13, 13.33s/it]100%|██████████| 10/10 [02:13<00:00, 13.33s/it]100%|██████████| 10/10 [02:13<00:00, 13.31s/it]
iteration:  222
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.66it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9758025205260582
The final epsilon delta values after the training is over:  (0.9758025205260582, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6379310344827587, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:00, 13.34s/it] 20%|██        | 2/10 [00:26<01:46, 13.30s/it] 30%|███       | 3/10 [00:39<01:32, 13.24s/it] 40%|████      | 4/10 [00:52<01:19, 13.23s/it] 50%|█████     | 5/10 [01:06<01:06, 13.21s/it] 60%|██████    | 6/10 [01:19<00:52, 13.20s/it] 70%|███████   | 7/10 [01:32<00:39, 13.21s/it] 80%|████████  | 8/10 [01:45<00:26, 13.20s/it] 90%|█████████ | 9/10 [01:59<00:13, 13.25s/it]100%|██████████| 10/10 [02:12<00:00, 13.27s/it]100%|██████████| 10/10 [02:12<00:00, 13.24s/it]
iteration:  223
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 55.81it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9758025205260582
The final epsilon delta values after the training is over:  (0.9758025205260582, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6379310344827587, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:59, 13.33s/it] 20%|██        | 2/10 [00:26<01:46, 13.34s/it] 30%|███       | 3/10 [00:39<01:33, 13.29s/it] 40%|████      | 4/10 [00:53<01:19, 13.26s/it] 50%|█████     | 5/10 [01:06<01:06, 13.26s/it] 60%|██████    | 6/10 [01:19<00:53, 13.26s/it] 70%|███████   | 7/10 [01:32<00:39, 13.26s/it] 80%|████████  | 8/10 [01:46<00:26, 13.26s/it] 90%|█████████ | 9/10 [01:59<00:13, 13.27s/it]100%|██████████| 10/10 [02:12<00:00, 13.27s/it]100%|██████████| 10/10 [02:12<00:00, 13.27s/it]
iteration:  224
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.70it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9758025205260582
The final epsilon delta values after the training is over:  (0.9758025205260582, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6379310344827587, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:59, 13.25s/it] 20%|██        | 2/10 [00:26<01:45, 13.23s/it] 30%|███       | 3/10 [00:39<01:32, 13.22s/it] 40%|████      | 4/10 [00:53<01:19, 13.27s/it] 50%|█████     | 5/10 [01:06<01:06, 13.27s/it] 60%|██████    | 6/10 [01:19<00:53, 13.28s/it] 70%|███████   | 7/10 [01:32<00:39, 13.27s/it] 80%|████████  | 8/10 [01:46<00:26, 13.29s/it] 90%|█████████ | 9/10 [01:59<00:13, 13.29s/it]100%|██████████| 10/10 [02:12<00:00, 13.29s/it]100%|██████████| 10/10 [02:12<00:00, 13.27s/it]
iteration:  225
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.19it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9758025205260582
The final epsilon delta values after the training is over:  (0.9758025205260582, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6379310344827587, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:00, 13.37s/it] 20%|██        | 2/10 [00:26<01:46, 13.30s/it] 30%|███       | 3/10 [00:40<01:33, 13.34s/it] 40%|████      | 4/10 [00:53<01:20, 13.34s/it] 50%|█████     | 5/10 [01:06<01:06, 13.32s/it] 60%|██████    | 6/10 [01:19<00:53, 13.32s/it] 70%|███████   | 7/10 [01:33<00:39, 13.32s/it] 80%|████████  | 8/10 [01:46<00:26, 13.31s/it] 90%|█████████ | 9/10 [01:59<00:13, 13.31s/it]100%|██████████| 10/10 [02:13<00:00, 13.32s/it]100%|██████████| 10/10 [02:13<00:00, 13.32s/it]
iteration:  226
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.73it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9758025205260582
The final epsilon delta values after the training is over:  (0.9758025205260582, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6379310344827587, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:59, 13.30s/it] 20%|██        | 2/10 [00:26<01:46, 13.34s/it] 30%|███       | 3/10 [00:39<01:33, 13.31s/it] 40%|████      | 4/10 [00:53<01:19, 13.28s/it] 50%|█████     | 5/10 [01:06<01:06, 13.26s/it] 60%|██████    | 6/10 [01:19<00:53, 13.29s/it] 70%|███████   | 7/10 [01:33<00:39, 13.30s/it] 80%|████████  | 8/10 [01:46<00:26, 13.28s/it] 90%|█████████ | 9/10 [01:59<00:13, 13.28s/it]100%|██████████| 10/10 [02:12<00:00, 13.28s/it]100%|██████████| 10/10 [02:12<00:00, 13.29s/it]
iteration:  227
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.84it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9758025205260582
The final epsilon delta values after the training is over:  (0.9758025205260582, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6379310344827587, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:01, 13.46s/it] 20%|██        | 2/10 [00:26<01:47, 13.41s/it] 30%|███       | 3/10 [00:40<01:33, 13.36s/it] 40%|████      | 4/10 [00:53<01:20, 13.35s/it] 50%|█████     | 5/10 [01:07<01:07, 13.46s/it] 60%|██████    | 6/10 [01:20<00:53, 13.44s/it] 70%|███████   | 7/10 [01:33<00:40, 13.38s/it] 80%|████████  | 8/10 [01:47<00:26, 13.36s/it] 90%|█████████ | 9/10 [02:00<00:13, 13.34s/it]100%|██████████| 10/10 [02:13<00:00, 13.34s/it]100%|██████████| 10/10 [02:13<00:00, 13.37s/it]
iteration:  228
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 55.53it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9758025205260582
The final epsilon delta values after the training is over:  (0.9758025205260582, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6379310344827587, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:59, 13.29s/it] 20%|██        | 2/10 [00:26<01:46, 13.28s/it] 30%|███       | 3/10 [00:39<01:32, 13.26s/it] 40%|████      | 4/10 [00:53<01:20, 13.41s/it] 50%|█████     | 5/10 [01:06<01:06, 13.37s/it] 60%|██████    | 6/10 [01:20<00:53, 13.35s/it] 70%|███████   | 7/10 [01:33<00:40, 13.37s/it] 80%|████████  | 8/10 [01:46<00:26, 13.35s/it] 90%|█████████ | 9/10 [02:00<00:13, 13.35s/it]100%|██████████| 10/10 [02:13<00:00, 13.33s/it]100%|██████████| 10/10 [02:13<00:00, 13.34s/it]
iteration:  229
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.18it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9758025205260582
The final epsilon delta values after the training is over:  (0.9758025205260582, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6379310344827587, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:02, 13.57s/it] 20%|██        | 2/10 [00:26<01:47, 13.43s/it] 30%|███       | 3/10 [00:40<01:33, 13.43s/it] 40%|████      | 4/10 [00:53<01:20, 13.44s/it] 50%|█████     | 5/10 [01:07<01:06, 13.39s/it] 60%|██████    | 6/10 [01:20<00:53, 13.37s/it] 70%|███████   | 7/10 [01:33<00:40, 13.43s/it] 80%|████████  | 8/10 [01:47<00:26, 13.45s/it] 90%|█████████ | 9/10 [02:00<00:13, 13.41s/it]100%|██████████| 10/10 [02:14<00:00, 13.40s/it]100%|██████████| 10/10 [02:14<00:00, 13.42s/it]
iteration:  230
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 54.86it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9758025205260582
The final epsilon delta values after the training is over:  (0.9758025205260582, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6379310344827587, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:00, 13.41s/it] 20%|██        | 2/10 [00:26<01:46, 13.34s/it] 30%|███       | 3/10 [00:39<01:33, 13.31s/it] 40%|████      | 4/10 [00:53<01:19, 13.30s/it] 50%|█████     | 5/10 [01:06<01:06, 13.30s/it] 60%|██████    | 6/10 [01:19<00:53, 13.30s/it] 70%|███████   | 7/10 [01:33<00:39, 13.30s/it] 80%|████████  | 8/10 [01:46<00:26, 13.30s/it] 90%|█████████ | 9/10 [01:59<00:13, 13.33s/it]100%|██████████| 10/10 [02:13<00:00, 13.35s/it]100%|██████████| 10/10 [02:13<00:00, 13.32s/it]
iteration:  231
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.70it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.941564515213259
The final epsilon delta values after the training is over:  (0.941564515213259, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:00, 13.34s/it] 20%|██        | 2/10 [00:26<01:46, 13.32s/it] 30%|███       | 3/10 [00:39<01:33, 13.31s/it] 40%|████      | 4/10 [00:53<01:19, 13.32s/it] 50%|█████     | 5/10 [01:06<01:06, 13.32s/it] 60%|██████    | 6/10 [01:19<00:53, 13.32s/it] 70%|███████   | 7/10 [01:33<00:39, 13.32s/it] 80%|████████  | 8/10 [01:46<00:26, 13.33s/it] 90%|█████████ | 9/10 [02:00<00:13, 13.35s/it]100%|██████████| 10/10 [02:13<00:00, 13.36s/it]100%|██████████| 10/10 [02:13<00:00, 13.34s/it]
iteration:  232
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.77it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.941564515213259
The final epsilon delta values after the training is over:  (0.941564515213259, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<01:59, 13.32s/it] 20%|██        | 2/10 [00:26<01:46, 13.32s/it] 30%|███       | 3/10 [00:39<01:33, 13.33s/it] 40%|████      | 4/10 [00:53<01:19, 13.33s/it] 50%|█████     | 5/10 [01:06<01:06, 13.34s/it] 60%|██████    | 6/10 [01:20<00:53, 13.34s/it] 70%|███████   | 7/10 [01:33<00:40, 13.36s/it] 80%|████████  | 8/10 [01:46<00:26, 13.36s/it] 90%|█████████ | 9/10 [02:00<00:13, 13.37s/it]100%|██████████| 10/10 [02:13<00:00, 13.37s/it]100%|██████████| 10/10 [02:13<00:00, 13.35s/it]
iteration:  233
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 55.89it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.941564515213259
The final epsilon delta values after the training is over:  (0.941564515213259, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:00, 13.39s/it] 20%|██        | 2/10 [00:26<01:47, 13.38s/it] 30%|███       | 3/10 [00:40<01:33, 13.38s/it] 40%|████      | 4/10 [00:53<01:20, 13.37s/it] 50%|█████     | 5/10 [01:06<01:06, 13.37s/it] 60%|██████    | 6/10 [01:20<00:53, 13.37s/it] 70%|███████   | 7/10 [01:33<00:40, 13.41s/it] 80%|████████  | 8/10 [01:47<00:26, 13.42s/it] 90%|█████████ | 9/10 [02:00<00:13, 13.42s/it]100%|██████████| 10/10 [02:14<00:00, 13.45s/it]100%|██████████| 10/10 [02:14<00:00, 13.41s/it]
iteration:  234
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.10it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.941564515213259
The final epsilon delta values after the training is over:  (0.941564515213259, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:02, 13.65s/it] 20%|██        | 2/10 [00:27<01:47, 13.47s/it] 30%|███       | 3/10 [00:40<01:33, 13.43s/it] 40%|████      | 4/10 [00:53<01:20, 13.39s/it] 50%|█████     | 5/10 [01:07<01:06, 13.38s/it] 60%|██████    | 6/10 [01:20<00:53, 13.44s/it] 70%|███████   | 7/10 [01:34<00:40, 13.42s/it] 80%|████████  | 8/10 [01:47<00:26, 13.41s/it] 90%|█████████ | 9/10 [02:00<00:13, 13.42s/it]100%|██████████| 10/10 [02:14<00:00, 13.51s/it]100%|██████████| 10/10 [02:14<00:00, 13.45s/it]
iteration:  235
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 54.72it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.941564515213259
The final epsilon delta values after the training is over:  (0.941564515213259, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:01, 13.46s/it] 20%|██        | 2/10 [00:27<01:48, 13.51s/it] 30%|███       | 3/10 [00:40<01:34, 13.52s/it] 40%|████      | 4/10 [00:53<01:20, 13.46s/it] 50%|█████     | 5/10 [01:07<01:07, 13.46s/it] 60%|██████    | 6/10 [01:20<00:53, 13.43s/it] 70%|███████   | 7/10 [01:34<00:40, 13.42s/it] 80%|████████  | 8/10 [01:47<00:26, 13.41s/it] 90%|█████████ | 9/10 [02:00<00:13, 13.41s/it]100%|██████████| 10/10 [02:14<00:00, 13.40s/it]100%|██████████| 10/10 [02:14<00:00, 13.43s/it]
iteration:  236
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.37it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.941564515213259
The final epsilon delta values after the training is over:  (0.941564515213259, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:00, 13.40s/it] 20%|██        | 2/10 [00:26<01:47, 13.40s/it] 30%|███       | 3/10 [00:40<01:33, 13.38s/it] 40%|████      | 4/10 [00:53<01:20, 13.38s/it] 50%|█████     | 5/10 [01:06<01:06, 13.37s/it] 60%|██████    | 6/10 [01:20<00:53, 13.38s/it] 70%|███████   | 7/10 [01:33<00:40, 13.41s/it] 80%|████████  | 8/10 [01:47<00:26, 13.43s/it] 90%|█████████ | 9/10 [02:00<00:13, 13.43s/it]100%|██████████| 10/10 [02:14<00:00, 13.46s/it]100%|██████████| 10/10 [02:14<00:00, 13.42s/it]
iteration:  237
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 56.30it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.941564515213259
The final epsilon delta values after the training is over:  (0.941564515213259, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:03, 13.70s/it] 20%|██        | 2/10 [00:27<01:48, 13.54s/it] 30%|███       | 3/10 [00:40<01:35, 13.65s/it] 40%|████      | 4/10 [00:54<01:21, 13.55s/it] 50%|█████     | 5/10 [01:07<01:07, 13.50s/it] 60%|██████    | 6/10 [01:21<00:53, 13.48s/it] 70%|███████   | 7/10 [01:34<00:40, 13.46s/it] 80%|████████  | 8/10 [01:48<00:26, 13.46s/it] 90%|█████████ | 9/10 [02:01<00:13, 13.51s/it]100%|██████████| 10/10 [02:15<00:00, 13.50s/it]100%|██████████| 10/10 [02:15<00:00, 13.51s/it]
iteration:  238
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 55.52it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.941564515213259
The final epsilon delta values after the training is over:  (0.941564515213259, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:01, 13.49s/it] 20%|██        | 2/10 [00:26<01:47, 13.42s/it] 30%|███       | 3/10 [00:40<01:34, 13.47s/it] 40%|████      | 4/10 [00:53<01:21, 13.51s/it] 50%|█████     | 5/10 [01:07<01:07, 13.49s/it] 60%|██████    | 6/10 [01:20<00:54, 13.50s/it] 70%|███████   | 7/10 [01:34<00:40, 13.53s/it] 80%|████████  | 8/10 [01:48<00:27, 13.66s/it] 90%|█████████ | 9/10 [02:02<00:13, 13.63s/it]100%|██████████| 10/10 [02:15<00:00, 13.61s/it]100%|██████████| 10/10 [02:15<00:00, 13.56s/it]
iteration:  239
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 54.85it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.941564515213259
The final epsilon delta values after the training is over:  (0.941564515213259, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:02, 13.64s/it] 20%|██        | 2/10 [00:27<01:48, 13.57s/it] 30%|███       | 3/10 [00:40<01:34, 13.53s/it] 40%|████      | 4/10 [00:54<01:21, 13.55s/it] 50%|█████     | 5/10 [01:07<01:07, 13.52s/it] 60%|██████    | 6/10 [01:21<00:54, 13.51s/it] 70%|███████   | 7/10 [01:34<00:40, 13.50s/it] 80%|████████  | 8/10 [01:48<00:26, 13.49s/it] 90%|█████████ | 9/10 [02:01<00:13, 13.48s/it]100%|██████████| 10/10 [02:15<00:00, 13.49s/it]100%|██████████| 10/10 [02:15<00:00, 13.51s/it]
iteration:  240
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 55.58it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.941564515213259
The final epsilon delta values after the training is over:  (0.941564515213259, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:00, 13.43s/it] 20%|██        | 2/10 [00:26<01:47, 13.43s/it] 30%|███       | 3/10 [00:40<01:33, 13.42s/it] 40%|████      | 4/10 [00:53<01:20, 13.44s/it] 50%|█████     | 5/10 [01:07<01:07, 13.43s/it] 60%|██████    | 6/10 [01:20<00:53, 13.42s/it] 70%|███████   | 7/10 [01:34<00:40, 13.52s/it] 80%|████████  | 8/10 [01:47<00:27, 13.58s/it] 90%|█████████ | 9/10 [02:05<00:14, 14.90s/it]100%|██████████| 10/10 [02:23<00:00, 15.64s/it]100%|██████████| 10/10 [02:23<00:00, 14.31s/it]
iteration:  241
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 47.93it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9116570771598174
The final epsilon delta values after the training is over:  (0.9116570771598174, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.7413793103448276, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:06, 14.06s/it] 20%|██        | 2/10 [00:28<01:52, 14.00s/it] 30%|███       | 3/10 [00:41<01:37, 13.86s/it] 40%|████      | 4/10 [00:55<01:23, 13.96s/it] 50%|█████     | 5/10 [01:09<01:09, 13.96s/it] 60%|██████    | 6/10 [01:23<00:55, 13.95s/it] 70%|███████   | 7/10 [01:37<00:41, 13.94s/it] 80%|████████  | 8/10 [01:51<00:27, 13.89s/it] 90%|█████████ | 9/10 [02:05<00:13, 13.85s/it]100%|██████████| 10/10 [02:18<00:00, 13.83s/it]100%|██████████| 10/10 [02:18<00:00, 13.90s/it]
iteration:  242
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 37.03it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9116570771598174
The final epsilon delta values after the training is over:  (0.9116570771598174, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.7413793103448276, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:10, 14.48s/it] 20%|██        | 2/10 [00:28<01:52, 14.10s/it] 30%|███       | 3/10 [00:41<01:36, 13.84s/it] 40%|████      | 4/10 [00:55<01:23, 13.85s/it] 50%|█████     | 5/10 [01:09<01:08, 13.77s/it] 60%|██████    | 6/10 [01:22<00:54, 13.72s/it] 70%|███████   | 7/10 [01:36<00:41, 13.67s/it] 80%|████████  | 8/10 [01:50<00:27, 13.64s/it] 90%|█████████ | 9/10 [02:03<00:13, 13.70s/it]100%|██████████| 10/10 [02:17<00:00, 13.75s/it]100%|██████████| 10/10 [02:17<00:00, 13.78s/it]
iteration:  243
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 37.71it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9116570771598174
The final epsilon delta values after the training is over:  (0.9116570771598174, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.7413793103448276, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:02, 13.56s/it] 20%|██        | 2/10 [00:27<01:49, 13.64s/it] 30%|███       | 3/10 [00:40<01:35, 13.68s/it] 40%|████      | 4/10 [00:54<01:22, 13.70s/it] 50%|█████     | 5/10 [01:08<01:09, 13.89s/it] 60%|██████    | 6/10 [01:23<00:56, 14.17s/it] 70%|███████   | 7/10 [01:37<00:42, 14.06s/it] 80%|████████  | 8/10 [01:51<00:27, 13.94s/it] 90%|█████████ | 9/10 [02:04<00:13, 13.85s/it]100%|██████████| 10/10 [02:18<00:00, 13.81s/it]100%|██████████| 10/10 [02:18<00:00, 13.85s/it]
iteration:  244
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 52.93it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9116570771598174
The final epsilon delta values after the training is over:  (0.9116570771598174, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.7413793103448276, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:07, 14.21s/it] 20%|██        | 2/10 [00:28<01:52, 14.11s/it] 30%|███       | 3/10 [00:41<01:37, 13.90s/it] 40%|████      | 4/10 [00:55<01:23, 13.91s/it] 50%|█████     | 5/10 [01:09<01:09, 13.83s/it] 60%|██████    | 6/10 [01:23<00:55, 13.90s/it] 70%|███████   | 7/10 [01:37<00:41, 13.82s/it] 80%|████████  | 8/10 [01:51<00:27, 13.93s/it] 90%|█████████ | 9/10 [02:05<00:13, 13.84s/it]100%|██████████| 10/10 [02:18<00:00, 13.78s/it]100%|██████████| 10/10 [02:18<00:00, 13.87s/it]
iteration:  245
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 53.65it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9116570771598174
The final epsilon delta values after the training is over:  (0.9116570771598174, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.7413793103448276, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:02, 13.63s/it] 20%|██        | 2/10 [00:27<01:50, 13.85s/it] 30%|███       | 3/10 [00:41<01:36, 13.80s/it] 40%|████      | 4/10 [00:55<01:22, 13.76s/it] 50%|█████     | 5/10 [01:08<01:08, 13.73s/it] 60%|██████    | 6/10 [01:22<00:54, 13.70s/it] 70%|███████   | 7/10 [01:35<00:40, 13.66s/it] 80%|████████  | 8/10 [01:49<00:27, 13.68s/it] 90%|█████████ | 9/10 [02:03<00:13, 13.65s/it]100%|██████████| 10/10 [02:16<00:00, 13.64s/it]100%|██████████| 10/10 [02:16<00:00, 13.69s/it]
iteration:  246
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 51.95it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9116570771598174
The final epsilon delta values after the training is over:  (0.9116570771598174, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.7413793103448276, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:06, 14.00s/it] 20%|██        | 2/10 [00:27<01:50, 13.82s/it] 30%|███       | 3/10 [00:41<01:36, 13.74s/it] 40%|████      | 4/10 [00:55<01:22, 13.72s/it] 50%|█████     | 5/10 [01:09<01:09, 13.90s/it] 60%|██████    | 6/10 [01:22<00:55, 13.83s/it] 70%|███████   | 7/10 [01:37<00:41, 13.91s/it] 80%|████████  | 8/10 [01:50<00:27, 13.83s/it] 90%|█████████ | 9/10 [02:04<00:13, 13.78s/it]100%|██████████| 10/10 [02:18<00:00, 13.77s/it]100%|██████████| 10/10 [02:18<00:00, 13.81s/it]
iteration:  247
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 53.82it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9116570771598174
The final epsilon delta values after the training is over:  (0.9116570771598174, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.7413793103448276, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:03, 13.71s/it] 20%|██        | 2/10 [00:27<01:50, 13.76s/it] 30%|███       | 3/10 [00:41<01:35, 13.70s/it] 40%|████      | 4/10 [00:55<01:22, 13.79s/it] 50%|█████     | 5/10 [01:08<01:09, 13.81s/it] 60%|██████    | 6/10 [01:22<00:55, 13.78s/it] 70%|███████   | 7/10 [01:36<00:41, 13.78s/it] 80%|████████  | 8/10 [01:50<00:27, 13.82s/it] 90%|█████████ | 9/10 [02:04<00:13, 13.94s/it]100%|██████████| 10/10 [02:18<00:00, 13.86s/it]100%|██████████| 10/10 [02:18<00:00, 13.82s/it]
iteration:  248
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 52.89it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9116570771598174
The final epsilon delta values after the training is over:  (0.9116570771598174, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.7413793103448276, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:06, 14.04s/it] 20%|██        | 2/10 [00:27<01:50, 13.83s/it] 30%|███       | 3/10 [00:42<01:40, 14.32s/it] 40%|████      | 4/10 [00:56<01:25, 14.23s/it] 50%|█████     | 5/10 [01:10<01:10, 14.02s/it] 60%|██████    | 6/10 [01:24<00:55, 13.92s/it] 70%|███████   | 7/10 [01:37<00:41, 13.86s/it] 80%|████████  | 8/10 [01:52<00:28, 14.03s/it] 90%|█████████ | 9/10 [02:06<00:13, 13.98s/it]100%|██████████| 10/10 [02:19<00:00, 13.93s/it]100%|██████████| 10/10 [02:19<00:00, 13.99s/it]
iteration:  249
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 36.88it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9116570771598174
The final epsilon delta values after the training is over:  (0.9116570771598174, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.7413793103448276, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:04, 13.87s/it] 20%|██        | 2/10 [00:28<01:52, 14.10s/it] 30%|███       | 3/10 [00:41<01:37, 13.98s/it] 40%|████      | 4/10 [00:55<01:23, 13.84s/it] 50%|█████     | 5/10 [01:09<01:09, 13.81s/it] 60%|██████    | 6/10 [01:23<00:55, 13.81s/it] 70%|███████   | 7/10 [01:37<00:41, 13.84s/it] 80%|████████  | 8/10 [01:50<00:27, 13.84s/it] 90%|█████████ | 9/10 [02:04<00:13, 13.82s/it]100%|██████████| 10/10 [02:19<00:00, 14.02s/it]100%|██████████| 10/10 [02:19<00:00, 13.91s/it]
iteration:  250
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 52.55it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9116570771598174
The final epsilon delta values after the training is over:  (0.9116570771598174, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.7413793103448276, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:06, 14.05s/it] 20%|██        | 2/10 [00:27<01:50, 13.84s/it] 30%|███       | 3/10 [00:41<01:36, 13.75s/it] 40%|████      | 4/10 [00:55<01:22, 13.83s/it] 50%|█████     | 5/10 [01:09<01:09, 13.81s/it] 60%|██████    | 6/10 [01:22<00:55, 13.77s/it] 70%|███████   | 7/10 [01:36<00:41, 13.75s/it] 80%|████████  | 8/10 [01:50<00:27, 13.73s/it] 90%|█████████ | 9/10 [02:04<00:13, 13.76s/it]100%|██████████| 10/10 [02:17<00:00, 13.77s/it]100%|██████████| 10/10 [02:17<00:00, 13.78s/it]
iteration:  251
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 53.93it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8849435341031682
The final epsilon delta values after the training is over:  (0.8849435341031682, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.793103448275862, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:06, 14.01s/it] 20%|██        | 2/10 [00:27<01:50, 13.84s/it] 30%|███       | 3/10 [00:41<01:37, 13.88s/it] 40%|████      | 4/10 [00:55<01:22, 13.81s/it] 50%|█████     | 5/10 [01:09<01:09, 13.87s/it] 60%|██████    | 6/10 [01:23<00:55, 13.90s/it] 70%|███████   | 7/10 [01:37<00:41, 13.93s/it] 80%|████████  | 8/10 [01:51<00:27, 13.88s/it] 90%|█████████ | 9/10 [02:05<00:14, 14.09s/it]100%|██████████| 10/10 [02:19<00:00, 14.02s/it]100%|██████████| 10/10 [02:19<00:00, 13.95s/it]
iteration:  252
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 53.89it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8849435341031682
The final epsilon delta values after the training is over:  (0.8849435341031682, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.793103448275862, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:04, 13.87s/it] 20%|██        | 2/10 [00:27<01:50, 13.87s/it] 30%|███       | 3/10 [00:41<01:36, 13.83s/it] 40%|████      | 4/10 [00:55<01:23, 13.86s/it] 50%|█████     | 5/10 [01:09<01:09, 13.94s/it] 60%|██████    | 6/10 [01:23<00:55, 13.85s/it] 70%|███████   | 7/10 [01:36<00:41, 13.79s/it] 80%|████████  | 8/10 [01:50<00:27, 13.85s/it] 90%|█████████ | 9/10 [02:04<00:13, 13.93s/it]100%|██████████| 10/10 [02:18<00:00, 13.91s/it]100%|██████████| 10/10 [02:18<00:00, 13.88s/it]
iteration:  253
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 37.49it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8849435341031682
The final epsilon delta values after the training is over:  (0.8849435341031682, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.793103448275862, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:03, 13.75s/it] 20%|██        | 2/10 [00:27<01:49, 13.74s/it] 30%|███       | 3/10 [00:41<01:36, 13.75s/it] 40%|████      | 4/10 [00:54<01:22, 13.73s/it] 50%|█████     | 5/10 [01:08<01:08, 13.72s/it] 60%|██████    | 6/10 [01:22<00:55, 13.77s/it] 70%|███████   | 7/10 [01:36<00:41, 13.78s/it] 80%|████████  | 8/10 [01:50<00:27, 13.83s/it] 90%|█████████ | 9/10 [02:04<00:13, 13.86s/it]100%|██████████| 10/10 [02:17<00:00, 13.85s/it]100%|██████████| 10/10 [02:17<00:00, 13.80s/it]
iteration:  254
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 47.66it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8849435341031682
The final epsilon delta values after the training is over:  (0.8849435341031682, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.793103448275862, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:05, 13.95s/it] 20%|██        | 2/10 [00:27<01:50, 13.84s/it] 30%|███       | 3/10 [00:41<01:37, 13.95s/it] 40%|████      | 4/10 [00:55<01:23, 13.89s/it] 50%|█████     | 5/10 [01:09<01:09, 13.94s/it] 60%|██████    | 6/10 [01:23<00:55, 13.88s/it] 70%|███████   | 7/10 [01:37<00:41, 13.86s/it] 80%|████████  | 8/10 [01:51<00:27, 13.87s/it] 90%|█████████ | 9/10 [02:04<00:13, 13.86s/it]100%|██████████| 10/10 [02:18<00:00, 13.89s/it]100%|██████████| 10/10 [02:18<00:00, 13.89s/it]
iteration:  255
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 53.45it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8849435341031682
The final epsilon delta values after the training is over:  (0.8849435341031682, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.793103448275862, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:04, 13.86s/it] 20%|██        | 2/10 [00:27<01:50, 13.85s/it] 30%|███       | 3/10 [00:43<01:43, 14.75s/it] 40%|████      | 4/10 [00:58<01:27, 14.65s/it] 50%|█████     | 5/10 [01:12<01:12, 14.44s/it] 60%|██████    | 6/10 [01:26<00:57, 14.28s/it] 70%|███████   | 7/10 [01:39<00:42, 14.11s/it] 80%|████████  | 8/10 [01:53<00:27, 13.99s/it] 90%|█████████ | 9/10 [02:07<00:13, 13.94s/it]100%|██████████| 10/10 [02:21<00:00, 13.96s/it]100%|██████████| 10/10 [02:21<00:00, 14.14s/it]
iteration:  256
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 43.51it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8849435341031682
The final epsilon delta values after the training is over:  (0.8849435341031682, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.793103448275862, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:04, 13.86s/it] 20%|██        | 2/10 [00:27<01:51, 13.91s/it] 30%|███       | 3/10 [00:41<01:36, 13.86s/it] 40%|████      | 4/10 [00:55<01:22, 13.82s/it] 50%|█████     | 5/10 [01:09<01:09, 13.85s/it] 60%|██████    | 6/10 [01:23<00:55, 13.98s/it] 70%|███████   | 7/10 [01:37<00:41, 13.92s/it] 80%|████████  | 8/10 [01:51<00:27, 13.86s/it] 90%|█████████ | 9/10 [02:04<00:13, 13.88s/it]100%|██████████| 10/10 [02:18<00:00, 13.89s/it]100%|██████████| 10/10 [02:18<00:00, 13.89s/it]
iteration:  257
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 44.90it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8849435341031682
The final epsilon delta values after the training is over:  (0.8849435341031682, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.793103448275862, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:07, 14.12s/it] 20%|██        | 2/10 [00:28<01:52, 14.02s/it] 30%|███       | 3/10 [00:41<01:37, 13.94s/it] 40%|████      | 4/10 [00:55<01:23, 13.89s/it] 50%|█████     | 5/10 [01:09<01:09, 13.91s/it] 60%|██████    | 6/10 [01:23<00:55, 13.84s/it] 70%|███████   | 7/10 [01:37<00:41, 13.91s/it] 80%|████████  | 8/10 [01:51<00:27, 13.92s/it] 90%|█████████ | 9/10 [02:05<00:14, 14.00s/it]100%|██████████| 10/10 [02:19<00:00, 13.94s/it]100%|██████████| 10/10 [02:19<00:00, 13.94s/it]
iteration:  258
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 53.20it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8849435341031682
The final epsilon delta values after the training is over:  (0.8849435341031682, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.793103448275862, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:04, 13.83s/it] 20%|██        | 2/10 [00:27<01:50, 13.81s/it] 30%|███       | 3/10 [00:41<01:36, 13.80s/it] 40%|████      | 4/10 [00:55<01:22, 13.79s/it] 50%|█████     | 5/10 [01:08<01:08, 13.78s/it] 60%|██████    | 6/10 [01:22<00:55, 13.80s/it] 70%|███████   | 7/10 [01:36<00:41, 13.80s/it] 80%|████████  | 8/10 [01:50<00:27, 13.83s/it] 90%|█████████ | 9/10 [02:04<00:13, 13.93s/it]100%|██████████| 10/10 [02:18<00:00, 14.05s/it]100%|██████████| 10/10 [02:18<00:00, 13.90s/it]
iteration:  259
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 36.23it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8849435341031682
The final epsilon delta values after the training is over:  (0.8849435341031682, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.793103448275862, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:09, 14.36s/it] 20%|██        | 2/10 [00:28<01:52, 14.04s/it] 30%|███       | 3/10 [00:41<01:37, 13.93s/it] 40%|████      | 4/10 [00:55<01:23, 13.87s/it] 50%|█████     | 5/10 [01:09<01:09, 13.84s/it] 60%|██████    | 6/10 [01:23<00:55, 13.89s/it] 70%|███████   | 7/10 [01:37<00:41, 13.93s/it] 80%|████████  | 8/10 [01:51<00:27, 13.95s/it] 90%|█████████ | 9/10 [02:05<00:13, 13.92s/it]100%|██████████| 10/10 [02:19<00:00, 14.02s/it]100%|██████████| 10/10 [02:19<00:00, 13.96s/it]
iteration:  260
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 36.66it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8849435341031682
The final epsilon delta values after the training is over:  (0.8849435341031682, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.793103448275862, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:06, 14.03s/it] 20%|██        | 2/10 [00:28<01:52, 14.02s/it] 30%|███       | 3/10 [00:41<01:37, 13.93s/it] 40%|████      | 4/10 [00:55<01:23, 13.87s/it] 50%|█████     | 5/10 [01:09<01:09, 13.83s/it] 60%|██████    | 6/10 [01:23<00:55, 13.82s/it] 70%|███████   | 7/10 [01:37<00:41, 13.86s/it] 80%|████████  | 8/10 [01:51<00:27, 13.94s/it] 90%|█████████ | 9/10 [02:05<00:13, 13.89s/it]100%|██████████| 10/10 [02:19<00:00, 13.92s/it]100%|██████████| 10/10 [02:19<00:00, 13.90s/it]
iteration:  261
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 53.01it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8608852958452982
The final epsilon delta values after the training is over:  (0.8608852958452982, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.8448275862068966, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:05, 13.96s/it] 20%|██        | 2/10 [00:27<01:51, 13.94s/it] 30%|███       | 3/10 [00:41<01:37, 13.88s/it] 40%|████      | 4/10 [00:55<01:23, 13.86s/it] 50%|█████     | 5/10 [01:09<01:09, 13.84s/it] 60%|██████    | 6/10 [01:23<00:55, 13.84s/it] 70%|███████   | 7/10 [01:37<00:41, 13.85s/it] 80%|████████  | 8/10 [01:51<00:27, 13.89s/it] 90%|█████████ | 9/10 [02:05<00:13, 13.95s/it]100%|██████████| 10/10 [02:18<00:00, 13.93s/it]100%|██████████| 10/10 [02:18<00:00, 13.90s/it]
iteration:  262
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 52.54it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8608852958452982
The final epsilon delta values after the training is over:  (0.8608852958452982, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.8448275862068966, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:06, 14.08s/it] 20%|██        | 2/10 [00:27<01:51, 13.97s/it] 30%|███       | 3/10 [00:41<01:37, 13.94s/it] 40%|████      | 4/10 [00:55<01:23, 13.92s/it] 50%|█████     | 5/10 [01:09<01:09, 13.90s/it] 60%|██████    | 6/10 [01:23<00:55, 13.90s/it] 70%|███████   | 7/10 [01:37<00:41, 13.89s/it] 80%|████████  | 8/10 [01:51<00:27, 13.98s/it] 90%|█████████ | 9/10 [02:05<00:13, 13.98s/it]100%|██████████| 10/10 [02:19<00:00, 13.96s/it]100%|██████████| 10/10 [02:19<00:00, 13.95s/it]
iteration:  263
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 53.18it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8608852958452982
The final epsilon delta values after the training is over:  (0.8608852958452982, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.8448275862068966, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:05, 13.99s/it] 20%|██        | 2/10 [00:28<01:52, 14.03s/it] 30%|███       | 3/10 [00:41<01:37, 13.99s/it] 40%|████      | 4/10 [00:55<01:23, 13.94s/it] 50%|█████     | 5/10 [01:09<01:09, 13.91s/it] 60%|██████    | 6/10 [01:23<00:55, 13.90s/it] 70%|███████   | 7/10 [01:37<00:41, 13.88s/it] 80%|████████  | 8/10 [01:51<00:27, 13.87s/it] 90%|█████████ | 9/10 [02:05<00:13, 13.86s/it]100%|██████████| 10/10 [02:19<00:00, 13.90s/it]100%|██████████| 10/10 [02:19<00:00, 13.91s/it]
iteration:  264
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 52.83it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8608852958452982
The final epsilon delta values after the training is over:  (0.8608852958452982, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.8448275862068966, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:07, 14.16s/it] 20%|██        | 2/10 [00:28<01:52, 14.01s/it] 30%|███       | 3/10 [00:41<01:37, 13.97s/it] 40%|████      | 4/10 [00:55<01:23, 13.93s/it] 50%|█████     | 5/10 [01:09<01:09, 13.97s/it] 60%|██████    | 6/10 [01:23<00:55, 13.98s/it] 70%|███████   | 7/10 [01:37<00:41, 13.98s/it] 80%|████████  | 8/10 [01:52<00:28, 14.04s/it] 90%|█████████ | 9/10 [02:06<00:14, 14.04s/it]100%|██████████| 10/10 [02:19<00:00, 13.99s/it]100%|██████████| 10/10 [02:19<00:00, 14.00s/it]
iteration:  265
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 36.33it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8608852958452982
The final epsilon delta values after the training is over:  (0.8608852958452982, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.8448275862068966, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:09, 14.41s/it] 20%|██        | 2/10 [00:28<01:52, 14.10s/it] 30%|███       | 3/10 [00:42<01:38, 14.06s/it] 40%|████      | 4/10 [00:56<01:24, 14.03s/it] 50%|█████     | 5/10 [01:10<01:10, 14.07s/it] 60%|██████    | 6/10 [01:24<00:56, 14.11s/it] 70%|███████   | 7/10 [01:38<00:42, 14.14s/it] 80%|████████  | 8/10 [01:52<00:28, 14.09s/it] 90%|█████████ | 9/10 [02:06<00:14, 14.12s/it]100%|██████████| 10/10 [02:21<00:00, 14.17s/it]100%|██████████| 10/10 [02:21<00:00, 14.13s/it]
iteration:  266
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 52.18it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8608852958452982
The final epsilon delta values after the training is over:  (0.8608852958452982, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.8448275862068966, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:09, 14.35s/it] 20%|██        | 2/10 [00:28<01:53, 14.14s/it] 30%|███       | 3/10 [00:42<01:38, 14.11s/it] 40%|████      | 4/10 [00:56<01:24, 14.12s/it] 50%|█████     | 5/10 [01:10<01:10, 14.04s/it] 60%|██████    | 6/10 [01:24<00:55, 13.97s/it] 70%|███████   | 7/10 [01:38<00:41, 13.99s/it] 80%|████████  | 8/10 [01:52<00:27, 13.96s/it] 90%|█████████ | 9/10 [02:06<00:13, 13.97s/it]100%|██████████| 10/10 [02:20<00:00, 13.96s/it]100%|██████████| 10/10 [02:20<00:00, 14.01s/it]
iteration:  267
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 52.73it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8608852958452982
The final epsilon delta values after the training is over:  (0.8608852958452982, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.8448275862068966, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:06, 14.04s/it] 20%|██        | 2/10 [00:27<01:51, 13.96s/it] 30%|███       | 3/10 [00:41<01:37, 13.93s/it] 40%|████      | 4/10 [00:55<01:24, 14.01s/it] 50%|█████     | 5/10 [01:09<01:09, 13.98s/it] 60%|██████    | 6/10 [01:23<00:55, 13.96s/it] 70%|███████   | 7/10 [01:37<00:41, 13.96s/it] 80%|████████  | 8/10 [01:51<00:27, 13.97s/it] 90%|█████████ | 9/10 [02:05<00:13, 13.98s/it]100%|██████████| 10/10 [02:19<00:00, 13.97s/it]100%|██████████| 10/10 [02:19<00:00, 13.97s/it]
iteration:  268
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 36.31it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8608852958452982
The final epsilon delta values after the training is over:  (0.8608852958452982, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.8448275862068966, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:13<02:05, 13.99s/it] 20%|██        | 2/10 [00:27<01:51, 13.95s/it] 30%|███       | 3/10 [00:41<01:37, 13.96s/it] 40%|████      | 4/10 [00:55<01:23, 13.94s/it] 50%|█████     | 5/10 [01:09<01:09, 13.94s/it] 60%|██████    | 6/10 [01:23<00:55, 13.94s/it] 70%|███████   | 7/10 [01:37<00:41, 14.00s/it] 80%|████████  | 8/10 [01:52<00:28, 14.13s/it] 90%|█████████ | 9/10 [02:06<00:14, 14.07s/it]100%|██████████| 10/10 [02:20<00:00, 14.04s/it]100%|██████████| 10/10 [02:20<00:00, 14.01s/it]
iteration:  269
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 36.53it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8608852958452982
The final epsilon delta values after the training is over:  (0.8608852958452982, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.8448275862068966, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:09, 14.37s/it] 20%|██        | 2/10 [00:28<01:54, 14.26s/it] 30%|███       | 3/10 [00:42<01:39, 14.17s/it] 40%|████      | 4/10 [00:56<01:24, 14.09s/it] 50%|█████     | 5/10 [01:10<01:10, 14.02s/it] 60%|██████    | 6/10 [01:24<00:55, 13.99s/it] 70%|███████   | 7/10 [01:38<00:42, 14.01s/it] 80%|████████  | 8/10 [01:52<00:28, 14.01s/it] 90%|█████████ | 9/10 [02:06<00:14, 14.10s/it]100%|██████████| 10/10 [02:20<00:00, 14.12s/it]100%|██████████| 10/10 [02:20<00:00, 14.09s/it]
iteration:  270
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 52.25it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8608852958452982
The final epsilon delta values after the training is over:  (0.8608852958452982, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.8448275862068966, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:06, 14.04s/it] 20%|██        | 2/10 [00:28<01:52, 14.06s/it] 30%|███       | 3/10 [00:42<01:38, 14.02s/it] 40%|████      | 4/10 [00:56<01:24, 14.05s/it] 50%|█████     | 5/10 [01:10<01:10, 14.03s/it] 60%|██████    | 6/10 [01:24<00:56, 14.17s/it] 70%|███████   | 7/10 [01:38<00:42, 14.12s/it] 80%|████████  | 8/10 [01:52<00:28, 14.09s/it] 90%|█████████ | 9/10 [02:06<00:14, 14.07s/it]100%|██████████| 10/10 [02:20<00:00, 14.06s/it]100%|██████████| 10/10 [02:20<00:00, 14.07s/it]
iteration:  271
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 52.22it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8391466687807205
The final epsilon delta values after the training is over:  (0.8391466687807205, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:07, 14.16s/it] 20%|██        | 2/10 [00:28<01:52, 14.10s/it] 30%|███       | 3/10 [00:42<01:38, 14.13s/it] 40%|████      | 4/10 [00:56<01:24, 14.17s/it] 50%|█████     | 5/10 [01:10<01:10, 14.19s/it] 60%|██████    | 6/10 [01:24<00:56, 14.13s/it] 70%|███████   | 7/10 [01:38<00:42, 14.10s/it] 80%|████████  | 8/10 [01:52<00:28, 14.06s/it] 90%|█████████ | 9/10 [02:06<00:14, 14.04s/it]100%|██████████| 10/10 [02:20<00:00, 14.06s/it]100%|██████████| 10/10 [02:20<00:00, 14.10s/it]
iteration:  272
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 52.09it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8391466687807205
The final epsilon delta values after the training is over:  (0.8391466687807205, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:07, 14.21s/it] 20%|██        | 2/10 [00:28<01:52, 14.09s/it] 30%|███       | 3/10 [00:42<01:38, 14.05s/it] 40%|████      | 4/10 [00:56<01:24, 14.03s/it] 50%|█████     | 5/10 [01:10<01:10, 14.02s/it] 60%|██████    | 6/10 [01:24<00:56, 14.06s/it] 70%|███████   | 7/10 [01:38<00:42, 14.09s/it] 80%|████████  | 8/10 [01:53<00:28, 14.28s/it] 90%|█████████ | 9/10 [02:07<00:14, 14.32s/it]100%|██████████| 10/10 [02:21<00:00, 14.32s/it]100%|██████████| 10/10 [02:21<00:00, 14.19s/it]
iteration:  273
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 36.37it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8391466687807205
The final epsilon delta values after the training is over:  (0.8391466687807205, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:07, 14.16s/it] 20%|██        | 2/10 [00:28<01:53, 14.16s/it] 30%|███       | 3/10 [00:42<01:39, 14.15s/it] 40%|████      | 4/10 [00:56<01:24, 14.14s/it] 50%|█████     | 5/10 [01:10<01:10, 14.13s/it] 60%|██████    | 6/10 [01:24<00:56, 14.13s/it] 70%|███████   | 7/10 [01:38<00:42, 14.10s/it] 80%|████████  | 8/10 [01:53<00:28, 14.12s/it] 90%|█████████ | 9/10 [02:07<00:14, 14.11s/it]100%|██████████| 10/10 [02:21<00:00, 14.11s/it]100%|██████████| 10/10 [02:21<00:00, 14.12s/it]
iteration:  274
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 52.42it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8391466687807205
The final epsilon delta values after the training is over:  (0.8391466687807205, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:06, 14.00s/it] 20%|██        | 2/10 [00:28<01:52, 14.12s/it] 30%|███       | 3/10 [00:42<01:39, 14.16s/it] 40%|████      | 4/10 [00:56<01:24, 14.09s/it] 50%|█████     | 5/10 [01:10<01:10, 14.05s/it] 60%|██████    | 6/10 [01:24<00:56, 14.05s/it] 70%|███████   | 7/10 [01:38<00:42, 14.05s/it] 80%|████████  | 8/10 [01:52<00:28, 14.05s/it] 90%|█████████ | 9/10 [02:06<00:14, 14.11s/it]100%|██████████| 10/10 [02:21<00:00, 14.20s/it]100%|██████████| 10/10 [02:21<00:00, 14.12s/it]
iteration:  275
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 53.25it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8391466687807205
The final epsilon delta values after the training is over:  (0.8391466687807205, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:08, 14.25s/it] 20%|██        | 2/10 [00:28<01:53, 14.17s/it] 30%|███       | 3/10 [00:42<01:39, 14.27s/it] 40%|████      | 4/10 [00:56<01:25, 14.19s/it] 50%|█████     | 5/10 [01:10<01:10, 14.16s/it] 60%|██████    | 6/10 [01:25<00:56, 14.16s/it] 70%|███████   | 7/10 [01:39<00:42, 14.17s/it] 80%|████████  | 8/10 [01:53<00:28, 14.25s/it] 90%|█████████ | 9/10 [02:07<00:14, 14.25s/it]100%|██████████| 10/10 [02:22<00:00, 14.23s/it]100%|██████████| 10/10 [02:22<00:00, 14.21s/it]
iteration:  276
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 52.15it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8391466687807205
The final epsilon delta values after the training is over:  (0.8391466687807205, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:07, 14.16s/it] 20%|██        | 2/10 [00:28<01:54, 14.37s/it] 30%|███       | 3/10 [00:42<01:40, 14.32s/it] 40%|████      | 4/10 [00:57<01:25, 14.26s/it] 50%|█████     | 5/10 [01:11<01:10, 14.17s/it] 60%|██████    | 6/10 [01:25<00:56, 14.12s/it] 70%|███████   | 7/10 [01:39<00:42, 14.13s/it] 80%|████████  | 8/10 [01:53<00:28, 14.14s/it] 90%|█████████ | 9/10 [02:07<00:14, 14.16s/it]100%|██████████| 10/10 [02:21<00:00, 14.17s/it]100%|██████████| 10/10 [02:21<00:00, 14.18s/it]
iteration:  277
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 53.62it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8391466687807205
The final epsilon delta values after the training is over:  (0.8391466687807205, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:12, 14.69s/it] 20%|██        | 2/10 [00:29<01:56, 14.52s/it] 30%|███       | 3/10 [00:43<01:40, 14.35s/it] 40%|████      | 4/10 [00:58<01:28, 14.67s/it] 50%|█████     | 5/10 [01:12<01:12, 14.55s/it] 60%|██████    | 6/10 [01:26<00:57, 14.43s/it] 70%|███████   | 7/10 [01:43<00:44, 14.99s/it] 80%|████████  | 8/10 [01:57<00:29, 14.73s/it] 90%|█████████ | 9/10 [02:11<00:14, 14.56s/it]100%|██████████| 10/10 [02:26<00:00, 14.57s/it]100%|██████████| 10/10 [02:26<00:00, 14.60s/it]
iteration:  278
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 35.87it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8391466687807205
The final epsilon delta values after the training is over:  (0.8391466687807205, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:14, 14.98s/it] 20%|██        | 2/10 [00:29<01:57, 14.73s/it] 30%|███       | 3/10 [00:43<01:42, 14.58s/it] 40%|████      | 4/10 [00:58<01:27, 14.65s/it] 50%|█████     | 5/10 [01:13<01:13, 14.65s/it] 60%|██████    | 6/10 [01:27<00:57, 14.49s/it] 70%|███████   | 7/10 [01:41<00:43, 14.38s/it] 80%|████████  | 8/10 [01:55<00:28, 14.31s/it] 90%|█████████ | 9/10 [02:10<00:14, 14.47s/it]100%|██████████| 10/10 [02:26<00:00, 14.81s/it]100%|██████████| 10/10 [02:26<00:00, 14.62s/it]
iteration:  279
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 45.20it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8391466687807205
The final epsilon delta values after the training is over:  (0.8391466687807205, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:13, 14.85s/it] 20%|██        | 2/10 [00:29<01:56, 14.61s/it] 30%|███       | 3/10 [00:43<01:41, 14.50s/it] 40%|████      | 4/10 [00:57<01:26, 14.39s/it] 50%|█████     | 5/10 [01:12<01:11, 14.32s/it] 60%|██████    | 6/10 [01:26<00:57, 14.28s/it] 70%|███████   | 7/10 [01:40<00:42, 14.30s/it] 80%|████████  | 8/10 [01:54<00:28, 14.28s/it] 90%|█████████ | 9/10 [02:09<00:14, 14.30s/it]100%|██████████| 10/10 [02:23<00:00, 14.38s/it]100%|██████████| 10/10 [02:23<00:00, 14.38s/it]
iteration:  280
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 35.97it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8391466687807205
The final epsilon delta values after the training is over:  (0.8391466687807205, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:07, 14.21s/it] 20%|██        | 2/10 [00:28<01:53, 14.18s/it] 30%|███       | 3/10 [00:42<01:39, 14.18s/it] 40%|████      | 4/10 [00:56<01:25, 14.23s/it] 50%|█████     | 5/10 [01:11<01:11, 14.22s/it] 60%|██████    | 6/10 [01:25<00:57, 14.27s/it] 70%|███████   | 7/10 [01:39<00:43, 14.35s/it] 80%|████████  | 8/10 [01:54<00:28, 14.32s/it] 90%|█████████ | 9/10 [02:08<00:14, 14.28s/it]100%|██████████| 10/10 [02:22<00:00, 14.29s/it]100%|██████████| 10/10 [02:22<00:00, 14.27s/it]
iteration:  281
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 35.66it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8187543443065453
The final epsilon delta values after the training is over:  (0.8187543443065453, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.9482758620689655, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:11, 14.58s/it] 20%|██        | 2/10 [00:28<01:54, 14.33s/it] 30%|███       | 3/10 [00:42<01:39, 14.26s/it] 40%|████      | 4/10 [00:57<01:25, 14.23s/it] 50%|█████     | 5/10 [01:11<01:11, 14.30s/it] 60%|██████    | 6/10 [01:26<00:57, 14.39s/it] 70%|███████   | 7/10 [01:40<00:43, 14.45s/it] 80%|████████  | 8/10 [01:55<00:28, 14.47s/it] 90%|█████████ | 9/10 [02:09<00:14, 14.48s/it]100%|██████████| 10/10 [02:25<00:00, 14.78s/it]100%|██████████| 10/10 [02:25<00:00, 14.51s/it]
iteration:  282
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 50.26it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8187543443065453
The final epsilon delta values after the training is over:  (0.8187543443065453, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.9482758620689655, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:12, 14.69s/it] 20%|██        | 2/10 [00:30<02:01, 15.13s/it] 30%|███       | 3/10 [00:44<01:44, 14.93s/it] 40%|████      | 4/10 [00:59<01:28, 14.78s/it] 50%|█████     | 5/10 [01:13<01:13, 14.62s/it] 60%|██████    | 6/10 [01:28<00:59, 14.84s/it] 70%|███████   | 7/10 [01:43<00:44, 14.68s/it] 80%|████████  | 8/10 [01:57<00:29, 14.59s/it] 90%|█████████ | 9/10 [02:12<00:14, 14.60s/it]100%|██████████| 10/10 [02:26<00:00, 14.54s/it]100%|██████████| 10/10 [02:26<00:00, 14.67s/it]
iteration:  283
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 45.39it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8187543443065453
The final epsilon delta values after the training is over:  (0.8187543443065453, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.9482758620689655, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:12, 14.69s/it] 20%|██        | 2/10 [00:29<01:56, 14.51s/it] 30%|███       | 3/10 [00:43<01:42, 14.58s/it] 40%|████      | 4/10 [00:58<01:27, 14.51s/it] 50%|█████     | 5/10 [01:12<01:12, 14.55s/it] 60%|██████    | 6/10 [01:27<00:57, 14.48s/it] 70%|███████   | 7/10 [01:41<00:43, 14.40s/it] 80%|████████  | 8/10 [01:55<00:28, 14.36s/it] 90%|█████████ | 9/10 [02:09<00:14, 14.33s/it]100%|██████████| 10/10 [02:24<00:00, 14.37s/it]100%|██████████| 10/10 [02:24<00:00, 14.44s/it]
iteration:  284
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 34.82it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8187543443065453
The final epsilon delta values after the training is over:  (0.8187543443065453, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.9482758620689655, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:08, 14.31s/it] 20%|██        | 2/10 [00:28<01:55, 14.47s/it] 30%|███       | 3/10 [00:43<01:40, 14.35s/it] 40%|████      | 4/10 [00:57<01:25, 14.28s/it] 50%|█████     | 5/10 [01:11<01:11, 14.25s/it] 60%|██████    | 6/10 [01:25<00:56, 14.24s/it] 70%|███████   | 7/10 [01:39<00:42, 14.25s/it] 80%|████████  | 8/10 [01:55<00:29, 14.65s/it] 90%|█████████ | 9/10 [02:10<00:14, 14.70s/it]100%|██████████| 10/10 [02:24<00:00, 14.54s/it]100%|██████████| 10/10 [02:24<00:00, 14.45s/it]
iteration:  285
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 35.94it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8187543443065453
The final epsilon delta values after the training is over:  (0.8187543443065453, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.9482758620689655, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:14, 14.93s/it] 20%|██        | 2/10 [00:29<01:59, 14.88s/it] 30%|███       | 3/10 [00:45<01:46, 15.19s/it] 40%|████      | 4/10 [00:59<01:28, 14.82s/it] 50%|█████     | 5/10 [01:13<01:13, 14.62s/it] 60%|██████    | 6/10 [01:28<00:58, 14.52s/it] 70%|███████   | 7/10 [01:42<00:43, 14.57s/it] 80%|████████  | 8/10 [01:57<00:28, 14.47s/it] 90%|█████████ | 9/10 [02:11<00:14, 14.44s/it]100%|██████████| 10/10 [02:25<00:00, 14.44s/it]100%|██████████| 10/10 [02:25<00:00, 14.59s/it]
iteration:  286
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 35.75it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8187543443065453
The final epsilon delta values after the training is over:  (0.8187543443065453, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.9482758620689655, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:09, 14.37s/it] 20%|██        | 2/10 [00:28<01:55, 14.44s/it] 30%|███       | 3/10 [00:43<01:40, 14.36s/it] 40%|████      | 4/10 [00:57<01:26, 14.34s/it] 50%|█████     | 5/10 [01:11<01:11, 14.31s/it] 60%|██████    | 6/10 [01:26<00:57, 14.42s/it] 70%|███████   | 7/10 [01:40<00:43, 14.37s/it] 80%|████████  | 8/10 [01:54<00:28, 14.35s/it] 90%|█████████ | 9/10 [02:09<00:14, 14.31s/it]100%|██████████| 10/10 [02:23<00:00, 14.28s/it]100%|██████████| 10/10 [02:23<00:00, 14.33s/it]
iteration:  287
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 31.30it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8187543443065453
The final epsilon delta values after the training is over:  (0.8187543443065453, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.9482758620689655, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:09, 14.40s/it] 20%|██        | 2/10 [00:28<01:54, 14.36s/it] 30%|███       | 3/10 [00:43<01:40, 14.36s/it] 40%|████      | 4/10 [00:57<01:26, 14.41s/it] 50%|█████     | 5/10 [01:12<01:12, 14.45s/it] 60%|██████    | 6/10 [01:26<00:57, 14.47s/it] 70%|███████   | 7/10 [01:40<00:43, 14.42s/it] 80%|████████  | 8/10 [01:55<00:28, 14.40s/it] 90%|█████████ | 9/10 [02:09<00:14, 14.43s/it]100%|██████████| 10/10 [02:24<00:00, 14.39s/it]100%|██████████| 10/10 [02:24<00:00, 14.41s/it]
iteration:  288
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 35.12it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8187543443065453
The final epsilon delta values after the training is over:  (0.8187543443065453, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.9482758620689655, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:11, 14.63s/it] 20%|██        | 2/10 [00:29<01:58, 14.87s/it] 30%|███       | 3/10 [00:44<01:42, 14.68s/it] 40%|████      | 4/10 [00:58<01:27, 14.55s/it] 50%|█████     | 5/10 [01:13<01:12, 14.59s/it] 60%|██████    | 6/10 [01:27<00:58, 14.51s/it] 70%|███████   | 7/10 [01:42<00:43, 14.61s/it] 80%|████████  | 8/10 [01:56<00:29, 14.52s/it] 90%|█████████ | 9/10 [02:11<00:14, 14.49s/it]100%|██████████| 10/10 [02:25<00:00, 14.45s/it]100%|██████████| 10/10 [02:25<00:00, 14.54s/it]
iteration:  289
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 51.32it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8187543443065453
The final epsilon delta values after the training is over:  (0.8187543443065453, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.9482758620689655, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:15<02:16, 15.22s/it] 20%|██        | 2/10 [00:29<01:58, 14.79s/it] 30%|███       | 3/10 [00:44<01:43, 14.73s/it] 40%|████      | 4/10 [00:59<01:28, 14.71s/it] 50%|█████     | 5/10 [01:13<01:12, 14.57s/it] 60%|██████    | 6/10 [01:27<00:58, 14.50s/it] 70%|███████   | 7/10 [01:42<00:43, 14.62s/it] 80%|████████  | 8/10 [01:56<00:29, 14.53s/it] 90%|█████████ | 9/10 [02:11<00:14, 14.67s/it]100%|██████████| 10/10 [02:26<00:00, 14.67s/it]100%|██████████| 10/10 [02:26<00:00, 14.66s/it]
iteration:  290
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 51.78it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8187543443065453
The final epsilon delta values after the training is over:  (0.8187543443065453, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.9482758620689655, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:13, 14.81s/it] 20%|██        | 2/10 [00:29<01:58, 14.76s/it] 30%|███       | 3/10 [00:44<01:42, 14.64s/it] 40%|████      | 4/10 [00:58<01:27, 14.53s/it] 50%|█████     | 5/10 [01:13<01:12, 14.60s/it] 60%|██████    | 6/10 [01:27<00:58, 14.63s/it] 70%|███████   | 7/10 [01:42<00:43, 14.60s/it] 80%|████████  | 8/10 [01:57<00:29, 14.72s/it] 90%|█████████ | 9/10 [02:11<00:14, 14.62s/it]100%|██████████| 10/10 [02:26<00:00, 14.70s/it]100%|██████████| 10/10 [02:26<00:00, 14.66s/it]
iteration:  291
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 43.90it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:13, 14.86s/it] 20%|██        | 2/10 [00:29<01:56, 14.62s/it] 30%|███       | 3/10 [00:44<01:44, 14.95s/it] 40%|████      | 4/10 [00:58<01:28, 14.70s/it] 50%|█████     | 5/10 [01:13<01:12, 14.58s/it] 60%|██████    | 6/10 [01:28<00:58, 14.62s/it] 70%|███████   | 7/10 [01:42<00:43, 14.54s/it] 80%|████████  | 8/10 [01:56<00:29, 14.54s/it] 90%|█████████ | 9/10 [02:11<00:14, 14.62s/it]100%|██████████| 10/10 [02:26<00:00, 14.56s/it]100%|██████████| 10/10 [02:26<00:00, 14.61s/it]
iteration:  292
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 35.70it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:11, 14.60s/it] 20%|██        | 2/10 [00:29<01:58, 14.78s/it] 30%|███       | 3/10 [00:44<01:42, 14.65s/it] 40%|████      | 4/10 [00:58<01:27, 14.60s/it] 50%|█████     | 5/10 [01:12<01:12, 14.54s/it] 60%|██████    | 6/10 [01:28<00:58, 14.71s/it] 70%|███████   | 7/10 [01:42<00:44, 14.77s/it] 80%|████████  | 8/10 [01:58<00:29, 14.89s/it] 90%|█████████ | 9/10 [02:13<00:15, 15.01s/it]100%|██████████| 10/10 [02:27<00:00, 14.83s/it]100%|██████████| 10/10 [02:27<00:00, 14.78s/it]
iteration:  293
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 36.06it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:09, 14.41s/it] 20%|██        | 2/10 [00:28<01:55, 14.45s/it] 30%|███       | 3/10 [00:43<01:41, 14.51s/it] 40%|████      | 4/10 [00:57<01:26, 14.48s/it] 50%|█████     | 5/10 [01:12<01:12, 14.53s/it] 60%|██████    | 6/10 [01:27<00:58, 14.63s/it] 70%|███████   | 7/10 [01:42<00:43, 14.65s/it] 80%|████████  | 8/10 [01:56<00:29, 14.62s/it] 90%|█████████ | 9/10 [02:11<00:14, 14.67s/it]100%|██████████| 10/10 [02:26<00:00, 14.69s/it]100%|██████████| 10/10 [02:26<00:00, 14.61s/it]
iteration:  294
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 51.01it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:13, 14.78s/it] 20%|██        | 2/10 [00:29<01:57, 14.74s/it] 30%|███       | 3/10 [00:43<01:42, 14.61s/it] 40%|████      | 4/10 [00:59<01:30, 15.06s/it] 50%|█████     | 5/10 [01:14<01:14, 14.83s/it] 60%|██████    | 6/10 [01:28<00:58, 14.70s/it] 70%|███████   | 7/10 [01:43<00:43, 14.66s/it] 80%|████████  | 8/10 [01:57<00:29, 14.67s/it] 90%|█████████ | 9/10 [02:12<00:14, 14.62s/it]100%|██████████| 10/10 [02:26<00:00, 14.62s/it]100%|██████████| 10/10 [02:26<00:00, 14.70s/it]
iteration:  295
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 45.90it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:14, 14.99s/it] 20%|██        | 2/10 [00:29<01:58, 14.80s/it] 30%|███       | 3/10 [00:44<01:42, 14.65s/it] 40%|████      | 4/10 [00:59<01:28, 14.81s/it] 50%|█████     | 5/10 [01:14<01:14, 14.90s/it] 60%|██████    | 6/10 [01:28<00:59, 14.77s/it] 70%|███████   | 7/10 [01:43<00:44, 14.71s/it] 80%|████████  | 8/10 [01:58<00:29, 14.71s/it] 90%|█████████ | 9/10 [02:12<00:14, 14.70s/it]100%|██████████| 10/10 [02:27<00:00, 14.73s/it]100%|██████████| 10/10 [02:27<00:00, 14.75s/it]
iteration:  296
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 46.54it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:13, 14.78s/it] 20%|██        | 2/10 [00:29<01:58, 14.75s/it] 30%|███       | 3/10 [00:43<01:42, 14.61s/it] 40%|████      | 4/10 [00:58<01:28, 14.75s/it] 50%|█████     | 5/10 [01:13<01:13, 14.73s/it] 60%|██████    | 6/10 [01:28<00:59, 14.77s/it] 70%|███████   | 7/10 [01:42<00:43, 14.65s/it] 80%|████████  | 8/10 [01:57<00:29, 14.60s/it] 90%|█████████ | 9/10 [02:12<00:14, 14.65s/it]100%|██████████| 10/10 [02:26<00:00, 14.62s/it]100%|██████████| 10/10 [02:26<00:00, 14.67s/it]
iteration:  297
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 49.68it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:10, 14.49s/it] 20%|██        | 2/10 [00:29<01:56, 14.55s/it] 30%|███       | 3/10 [00:43<01:42, 14.68s/it] 40%|████      | 4/10 [00:58<01:28, 14.75s/it] 50%|█████     | 5/10 [01:13<01:13, 14.70s/it] 60%|██████    | 6/10 [01:27<00:58, 14.61s/it] 70%|███████   | 7/10 [01:42<00:43, 14.62s/it] 80%|████████  | 8/10 [01:57<00:29, 14.62s/it] 90%|█████████ | 9/10 [02:11<00:14, 14.59s/it]100%|██████████| 10/10 [02:26<00:00, 14.68s/it]100%|██████████| 10/10 [02:26<00:00, 14.65s/it]
iteration:  298
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 50.27it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:12, 14.67s/it] 20%|██        | 2/10 [00:29<01:57, 14.65s/it] 30%|███       | 3/10 [00:43<01:41, 14.55s/it] 40%|████      | 4/10 [00:58<01:27, 14.55s/it] 50%|█████     | 5/10 [01:13<01:13, 14.65s/it] 60%|██████    | 6/10 [01:27<00:58, 14.69s/it] 70%|███████   | 7/10 [01:42<00:44, 14.72s/it] 80%|████████  | 8/10 [01:57<00:29, 14.63s/it] 90%|█████████ | 9/10 [02:11<00:14, 14.58s/it]100%|██████████| 10/10 [02:26<00:00, 14.57s/it]100%|██████████| 10/10 [02:26<00:00, 14.61s/it]
iteration:  299
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 35.50it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:10, 14.50s/it] 20%|██        | 2/10 [00:29<01:56, 14.57s/it] 30%|███       | 3/10 [00:43<01:42, 14.60s/it] 40%|████      | 4/10 [00:58<01:27, 14.56s/it] 50%|█████     | 5/10 [01:12<01:12, 14.54s/it] 60%|██████    | 6/10 [01:27<00:58, 14.58s/it] 70%|███████   | 7/10 [01:41<00:43, 14.52s/it] 80%|████████  | 8/10 [01:56<00:28, 14.49s/it] 90%|█████████ | 9/10 [02:10<00:14, 14.53s/it]100%|██████████| 10/10 [02:25<00:00, 14.62s/it]100%|██████████| 10/10 [02:25<00:00, 14.57s/it]
iteration:  300
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 50.49it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:14<02:13, 14.79s/it] 20%|██        | 2/10 [00:29<01:57, 14.69s/it] 30%|███       | 3/10 [00:44<01:42, 14.70s/it] 40%|████      | 4/10 [00:58<01:27, 14.62s/it] 50%|█████     | 5/10 [01:13<01:13, 14.61s/it] 60%|██████    | 6/10 [01:27<00:58, 14.56s/it] 70%|███████   | 7/10 [01:43<00:44, 14.94s/it] 80%|████████  | 8/10 [01:58<00:29, 14.95s/it] 90%|█████████ | 9/10 [02:13<00:14, 14.97s/it]100%|██████████| 10/10 [02:27<00:00, 14.83s/it]100%|██████████| 10/10 [02:27<00:00, 14.79s/it]
2023-02-07 17:44:43.185080: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-07 17:44:43.311609: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-07 17:44:43.829192: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-02-07 17:44:43.829258: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-02-07 17:44:43.829269: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
WARNING: this experiment is not being saved.
Loading mnist dataset.
Creating default-fc model.
iteration:  1
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.35it/s]100%|██████████| 1/1 [00:00<00:00,  7.34it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:08<01:17,  8.57s/it] 20%|██        | 2/10 [00:17<01:08,  8.62s/it] 30%|███       | 3/10 [00:25<01:00,  8.61s/it] 40%|████      | 4/10 [00:34<00:51,  8.60s/it] 50%|█████     | 5/10 [00:42<00:42,  8.58s/it] 60%|██████    | 6/10 [00:51<00:34,  8.72s/it] 70%|███████   | 7/10 [01:00<00:26,  8.80s/it] 80%|████████  | 8/10 [01:09<00:17,  8.74s/it] 90%|█████████ | 9/10 [01:18<00:08,  8.68s/it]100%|██████████| 10/10 [01:26<00:00,  8.67s/it]100%|██████████| 10/10 [01:26<00:00,  8.67s/it]
iteration:  2
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 69.91it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:21,  9.04s/it] 20%|██        | 2/10 [00:18<01:13,  9.16s/it] 30%|███       | 3/10 [00:27<01:04,  9.19s/it] 40%|████      | 4/10 [00:36<00:54,  9.11s/it] 50%|█████     | 5/10 [00:45<00:45,  9.18s/it] 60%|██████    | 6/10 [00:55<00:36,  9.20s/it] 70%|███████   | 7/10 [01:04<00:27,  9.15s/it] 80%|████████  | 8/10 [01:13<00:18,  9.10s/it] 90%|█████████ | 9/10 [01:21<00:09,  9.04s/it]100%|██████████| 10/10 [01:31<00:00,  9.06s/it]100%|██████████| 10/10 [01:31<00:00,  9.11s/it]
iteration:  3
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.83it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:22,  9.20s/it] 20%|██        | 2/10 [00:18<01:13,  9.25s/it] 30%|███       | 3/10 [00:27<01:05,  9.33s/it] 40%|████      | 4/10 [00:37<00:55,  9.27s/it] 50%|█████     | 5/10 [00:46<00:46,  9.32s/it] 60%|██████    | 6/10 [00:55<00:36,  9.22s/it] 70%|███████   | 7/10 [01:04<00:27,  9.21s/it] 80%|████████  | 8/10 [01:13<00:18,  9.16s/it] 90%|█████████ | 9/10 [01:23<00:09,  9.19s/it]100%|██████████| 10/10 [01:32<00:00,  9.20s/it]100%|██████████| 10/10 [01:32<00:00,  9.22s/it]
iteration:  4
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.21it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:23,  9.22s/it] 20%|██        | 2/10 [00:18<01:13,  9.14s/it] 30%|███       | 3/10 [00:27<01:03,  9.11s/it] 40%|████      | 4/10 [00:36<00:55,  9.17s/it] 50%|█████     | 5/10 [00:45<00:45,  9.10s/it] 60%|██████    | 6/10 [00:54<00:36,  9.07s/it] 70%|███████   | 7/10 [01:04<00:27,  9.31s/it] 80%|████████  | 8/10 [01:14<00:18,  9.45s/it] 90%|█████████ | 9/10 [01:23<00:09,  9.43s/it]100%|██████████| 10/10 [01:33<00:00,  9.44s/it]100%|██████████| 10/10 [01:33<00:00,  9.30s/it]
iteration:  5
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.60it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:08<01:20,  9.00s/it] 20%|██        | 2/10 [00:18<01:12,  9.10s/it] 30%|███       | 3/10 [00:27<01:04,  9.15s/it] 40%|████      | 4/10 [00:36<00:54,  9.10s/it] 50%|█████     | 5/10 [00:45<00:45,  9.11s/it] 60%|██████    | 6/10 [00:54<00:36,  9.10s/it] 70%|███████   | 7/10 [01:03<00:27,  9.10s/it] 80%|████████  | 8/10 [01:12<00:18,  9.06s/it] 90%|█████████ | 9/10 [01:21<00:09,  9.12s/it]100%|██████████| 10/10 [01:30<00:00,  9.10s/it]100%|██████████| 10/10 [01:30<00:00,  9.10s/it]
iteration:  6
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.41it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:21,  9.06s/it] 20%|██        | 2/10 [00:18<01:12,  9.08s/it] 30%|███       | 3/10 [00:27<01:03,  9.05s/it] 40%|████      | 4/10 [00:36<00:54,  9.03s/it] 50%|█████     | 5/10 [00:45<00:45,  9.02s/it] 60%|██████    | 6/10 [00:54<00:36,  9.12s/it] 70%|███████   | 7/10 [01:04<00:27,  9.26s/it] 80%|████████  | 8/10 [01:12<00:18,  9.16s/it] 90%|█████████ | 9/10 [01:21<00:09,  9.10s/it]100%|██████████| 10/10 [01:30<00:00,  9.06s/it]100%|██████████| 10/10 [01:30<00:00,  9.09s/it]
iteration:  7
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.41it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:21,  9.00s/it] 20%|██        | 2/10 [00:17<01:11,  8.98s/it] 30%|███       | 3/10 [00:27<01:04,  9.22s/it] 40%|████      | 4/10 [00:36<00:55,  9.23s/it] 50%|█████     | 5/10 [00:45<00:46,  9.22s/it] 60%|██████    | 6/10 [00:55<00:36,  9.20s/it] 70%|███████   | 7/10 [01:04<00:27,  9.14s/it] 80%|████████  | 8/10 [01:13<00:18,  9.21s/it] 90%|█████████ | 9/10 [01:22<00:09,  9.15s/it]100%|██████████| 10/10 [01:31<00:00,  9.10s/it]100%|██████████| 10/10 [01:31<00:00,  9.15s/it]
iteration:  8
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 46.25it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:23,  9.30s/it] 20%|██        | 2/10 [00:18<01:13,  9.20s/it] 30%|███       | 3/10 [00:27<01:04,  9.16s/it] 40%|████      | 4/10 [00:36<00:54,  9.15s/it] 50%|█████     | 5/10 [00:45<00:45,  9.10s/it] 60%|██████    | 6/10 [00:54<00:36,  9.07s/it] 70%|███████   | 7/10 [01:03<00:27,  9.06s/it] 80%|████████  | 8/10 [01:12<00:18,  9.06s/it] 90%|█████████ | 9/10 [01:21<00:09,  9.05s/it]100%|██████████| 10/10 [01:30<00:00,  9.05s/it]100%|██████████| 10/10 [01:30<00:00,  9.09s/it]
iteration:  9
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.63it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:21,  9.10s/it] 20%|██        | 2/10 [00:18<01:13,  9.19s/it] 30%|███       | 3/10 [00:27<01:04,  9.23s/it] 40%|████      | 4/10 [00:37<00:55,  9.30s/it] 50%|█████     | 5/10 [00:46<00:46,  9.24s/it] 60%|██████    | 6/10 [00:55<00:37,  9.30s/it] 70%|███████   | 7/10 [01:05<00:28,  9.35s/it] 80%|████████  | 8/10 [01:14<00:18,  9.29s/it] 90%|█████████ | 9/10 [01:23<00:09,  9.35s/it]100%|██████████| 10/10 [01:32<00:00,  9.33s/it]100%|██████████| 10/10 [01:32<00:00,  9.30s/it]
iteration:  10
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 45.61it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:23,  9.28s/it] 20%|██        | 2/10 [00:18<01:14,  9.31s/it] 30%|███       | 3/10 [00:27<01:05,  9.30s/it] 40%|████      | 4/10 [00:37<00:55,  9.28s/it] 50%|█████     | 5/10 [00:46<00:46,  9.25s/it] 60%|██████    | 6/10 [00:55<00:36,  9.24s/it] 70%|███████   | 7/10 [01:04<00:27,  9.26s/it] 80%|████████  | 8/10 [01:14<00:18,  9.33s/it] 90%|█████████ | 9/10 [01:23<00:09,  9.31s/it]100%|██████████| 10/10 [01:32<00:00,  9.32s/it]100%|██████████| 10/10 [01:32<00:00,  9.29s/it]
2023-02-07 18:03:06.038385: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-07 18:03:06.160852: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-07 18:03:06.675382: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-02-07 18:03:06.675445: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-02-07 18:03:06.675453: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
WARNING: this experiment is not being saved.
Loading mnist dataset.
Creating default-fc model.
iteration:  1
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  7.57it/s]100%|██████████| 1/1 [00:00<00:00,  7.56it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:08<01:18,  8.75s/it] 20%|██        | 2/10 [00:17<01:09,  8.69s/it] 30%|███       | 3/10 [00:25<01:00,  8.62s/it] 40%|████      | 4/10 [00:34<00:52,  8.67s/it] 50%|█████     | 5/10 [00:43<00:43,  8.69s/it] 60%|██████    | 6/10 [00:51<00:34,  8.62s/it] 70%|███████   | 7/10 [01:00<00:25,  8.58s/it] 80%|████████  | 8/10 [01:09<00:17,  8.70s/it] 90%|█████████ | 9/10 [01:18<00:08,  8.70s/it]100%|██████████| 10/10 [01:26<00:00,  8.68s/it]100%|██████████| 10/10 [01:26<00:00,  8.67s/it]
iteration:  2
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.76it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:08<01:20,  8.95s/it] 20%|██        | 2/10 [00:17<01:11,  8.96s/it] 30%|███       | 3/10 [00:26<01:02,  8.91s/it] 40%|████      | 4/10 [00:35<00:54,  9.01s/it] 50%|█████     | 5/10 [00:44<00:44,  8.97s/it] 60%|██████    | 6/10 [00:54<00:36,  9.07s/it] 70%|███████   | 7/10 [01:03<00:27,  9.03s/it] 80%|████████  | 8/10 [01:12<00:18,  9.05s/it] 90%|█████████ | 9/10 [01:21<00:09,  9.02s/it]100%|██████████| 10/10 [01:29<00:00,  8.98s/it]100%|██████████| 10/10 [01:29<00:00,  9.00s/it]
iteration:  3
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 69.08it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:08<01:20,  8.98s/it] 20%|██        | 2/10 [00:18<01:13,  9.15s/it] 30%|███       | 3/10 [00:27<01:03,  9.12s/it] 40%|████      | 4/10 [00:36<00:54,  9.09s/it] 50%|█████     | 5/10 [00:45<00:45,  9.06s/it] 60%|██████    | 6/10 [00:54<00:36,  9.03s/it] 70%|███████   | 7/10 [01:03<00:27,  9.06s/it] 80%|████████  | 8/10 [01:12<00:18,  9.08s/it] 90%|█████████ | 9/10 [01:21<00:09,  9.04s/it]100%|██████████| 10/10 [01:31<00:00,  9.29s/it]100%|██████████| 10/10 [01:31<00:00,  9.14s/it]
iteration:  4
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.97it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:08<01:20,  8.99s/it] 20%|██        | 2/10 [00:18<01:13,  9.13s/it] 30%|███       | 3/10 [00:27<01:03,  9.10s/it] 40%|████      | 4/10 [00:36<00:54,  9.05s/it] 50%|█████     | 5/10 [00:45<00:44,  9.00s/it] 60%|██████    | 6/10 [00:54<00:35,  8.99s/it] 70%|███████   | 7/10 [01:03<00:27,  9.08s/it] 80%|████████  | 8/10 [01:12<00:18,  9.05s/it] 90%|█████████ | 9/10 [01:21<00:09,  9.04s/it]100%|██████████| 10/10 [01:30<00:00,  9.00s/it]100%|██████████| 10/10 [01:30<00:00,  9.03s/it]
iteration:  5
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 70.54it/s]
Number of steps:  64
[ 64 ]Privacy loss is 13.19678665570073
The final epsilon delta values after the training is over:  (13.19678665570073, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:22,  9.14s/it] 20%|██        | 2/10 [00:18<01:12,  9.04s/it] 30%|███       | 3/10 [00:27<01:03,  9.11s/it] 40%|████      | 4/10 [00:36<00:54,  9.16s/it] 50%|█████     | 5/10 [00:45<00:45,  9.11s/it] 60%|██████    | 6/10 [00:54<00:36,  9.21s/it] 70%|███████   | 7/10 [01:04<00:27,  9.20s/it] 80%|████████  | 8/10 [01:13<00:18,  9.11s/it] 90%|█████████ | 9/10 [01:22<00:09,  9.06s/it]100%|██████████| 10/10 [01:30<00:00,  9.02s/it]100%|██████████| 10/10 [01:30<00:00,  9.09s/it]
iteration:  6
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 69.15it/s]
Number of steps:  64
[ 64 ]Privacy loss is 11.17647147989064
The final epsilon delta values after the training is over:  (11.17647147989064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5517241379310345, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:08<01:20,  8.94s/it] 20%|██        | 2/10 [00:17<01:11,  8.96s/it] 30%|███       | 3/10 [00:26<01:02,  8.97s/it] 40%|████      | 4/10 [00:35<00:53,  8.94s/it] 50%|█████     | 5/10 [00:44<00:44,  8.97s/it] 60%|██████    | 6/10 [00:53<00:35,  9.00s/it] 70%|███████   | 7/10 [01:02<00:27,  9.01s/it] 80%|████████  | 8/10 [01:11<00:18,  9.01s/it] 90%|█████████ | 9/10 [01:20<00:09,  9.03s/it]100%|██████████| 10/10 [01:30<00:00,  9.10s/it]100%|██████████| 10/10 [01:30<00:00,  9.02s/it]
iteration:  7
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.17it/s]
Number of steps:  64
[ 64 ]Privacy loss is 11.17647147989064
The final epsilon delta values after the training is over:  (11.17647147989064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5517241379310345, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:08<01:20,  8.91s/it] 20%|██        | 2/10 [00:17<01:11,  8.92s/it] 30%|███       | 3/10 [00:26<01:03,  9.01s/it] 40%|████      | 4/10 [00:36<00:54,  9.16s/it] 50%|█████     | 5/10 [00:45<00:45,  9.08s/it] 60%|██████    | 6/10 [00:54<00:36,  9.05s/it] 70%|███████   | 7/10 [01:03<00:27,  9.05s/it] 80%|████████  | 8/10 [01:12<00:18,  9.06s/it] 90%|█████████ | 9/10 [01:21<00:09,  9.08s/it]100%|██████████| 10/10 [01:30<00:00,  9.03s/it]100%|██████████| 10/10 [01:30<00:00,  9.04s/it]
iteration:  8
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 69.94it/s]
Number of steps:  64
[ 64 ]Privacy loss is 11.17647147989064
The final epsilon delta values after the training is over:  (11.17647147989064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5517241379310345, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:08<01:20,  8.95s/it] 20%|██        | 2/10 [00:17<01:11,  8.94s/it] 30%|███       | 3/10 [00:26<01:02,  8.95s/it] 40%|████      | 4/10 [00:35<00:53,  9.00s/it] 50%|█████     | 5/10 [00:45<00:45,  9.07s/it] 60%|██████    | 6/10 [00:54<00:36,  9.12s/it] 70%|███████   | 7/10 [01:03<00:27,  9.07s/it] 80%|████████  | 8/10 [01:12<00:18,  9.06s/it] 90%|█████████ | 9/10 [01:21<00:09,  9.05s/it]100%|██████████| 10/10 [01:30<00:00,  9.05s/it]100%|██████████| 10/10 [01:30<00:00,  9.04s/it]
iteration:  9
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.63it/s]
Number of steps:  64
[ 64 ]Privacy loss is 11.17647147989064
The final epsilon delta values after the training is over:  (11.17647147989064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5517241379310345, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:22,  9.15s/it] 20%|██        | 2/10 [00:18<01:13,  9.22s/it] 30%|███       | 3/10 [00:27<01:04,  9.23s/it] 40%|████      | 4/10 [00:36<00:55,  9.20s/it] 50%|█████     | 5/10 [00:45<00:45,  9.14s/it] 60%|██████    | 6/10 [00:54<00:36,  9.10s/it] 70%|███████   | 7/10 [01:03<00:27,  9.07s/it] 80%|████████  | 8/10 [01:12<00:18,  9.07s/it] 90%|█████████ | 9/10 [01:22<00:09,  9.08s/it]100%|██████████| 10/10 [01:31<00:00,  9.09s/it]100%|██████████| 10/10 [01:31<00:00,  9.12s/it]
iteration:  10
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.19it/s]
Number of steps:  64
[ 64 ]Privacy loss is 11.17647147989064
The final epsilon delta values after the training is over:  (11.17647147989064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.5517241379310345, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:24,  9.39s/it] 20%|██        | 2/10 [00:18<01:13,  9.19s/it] 30%|███       | 3/10 [00:27<01:04,  9.26s/it] 40%|████      | 4/10 [00:37<00:55,  9.28s/it] 50%|█████     | 5/10 [00:46<00:46,  9.29s/it] 60%|██████    | 6/10 [00:55<00:36,  9.24s/it] 70%|███████   | 7/10 [01:04<00:27,  9.20s/it] 80%|████████  | 8/10 [01:13<00:18,  9.21s/it] 90%|█████████ | 9/10 [01:23<00:09,  9.20s/it]100%|██████████| 10/10 [01:32<00:00,  9.24s/it]100%|██████████| 10/10 [01:32<00:00,  9.24s/it]
iteration:  11
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 70.06it/s]
Number of steps:  64
[ 64 ]Privacy loss is 7.369218646919686
The final epsilon delta values after the training is over:  (7.369218646919686, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.603448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:26,  9.62s/it] 20%|██        | 2/10 [00:18<01:15,  9.41s/it] 30%|███       | 3/10 [00:28<01:05,  9.35s/it] 40%|████      | 4/10 [00:37<00:55,  9.32s/it] 50%|█████     | 5/10 [00:46<00:46,  9.33s/it] 60%|██████    | 6/10 [00:56<00:37,  9.37s/it] 70%|███████   | 7/10 [01:05<00:28,  9.35s/it] 80%|████████  | 8/10 [01:15<00:18,  9.41s/it] 90%|█████████ | 9/10 [01:24<00:09,  9.39s/it]100%|██████████| 10/10 [01:33<00:00,  9.41s/it]100%|██████████| 10/10 [01:33<00:00,  9.39s/it]
iteration:  12
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.48it/s]
Number of steps:  64
[ 64 ]Privacy loss is 7.369218646919686
The final epsilon delta values after the training is over:  (7.369218646919686, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.603448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:24,  9.39s/it] 20%|██        | 2/10 [00:18<01:15,  9.47s/it] 30%|███       | 3/10 [00:28<01:07,  9.58s/it] 40%|████      | 4/10 [00:38<00:57,  9.58s/it] 50%|█████     | 5/10 [00:47<00:47,  9.49s/it] 60%|██████    | 6/10 [00:56<00:37,  9.43s/it] 70%|███████   | 7/10 [01:06<00:28,  9.49s/it] 80%|████████  | 8/10 [01:15<00:18,  9.46s/it] 90%|█████████ | 9/10 [01:25<00:09,  9.65s/it]100%|██████████| 10/10 [01:35<00:00,  9.72s/it]100%|██████████| 10/10 [01:35<00:00,  9.58s/it]
iteration:  13
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.96it/s]
Number of steps:  64
[ 64 ]Privacy loss is 7.369218646919686
The final epsilon delta values after the training is over:  (7.369218646919686, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.603448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:26,  9.65s/it] 20%|██        | 2/10 [00:19<01:16,  9.56s/it] 30%|███       | 3/10 [00:28<01:06,  9.49s/it] 40%|████      | 4/10 [00:38<00:57,  9.50s/it] 50%|█████     | 5/10 [00:47<00:47,  9.46s/it] 60%|██████    | 6/10 [00:56<00:37,  9.42s/it] 70%|███████   | 7/10 [01:06<00:28,  9.45s/it] 80%|████████  | 8/10 [01:15<00:18,  9.48s/it] 90%|█████████ | 9/10 [01:25<00:09,  9.49s/it]100%|██████████| 10/10 [01:34<00:00,  9.46s/it]100%|██████████| 10/10 [01:34<00:00,  9.48s/it]
iteration:  14
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.03it/s]
Number of steps:  64
[ 64 ]Privacy loss is 7.369218646919686
The final epsilon delta values after the training is over:  (7.369218646919686, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.603448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:24,  9.39s/it] 20%|██        | 2/10 [00:18<01:15,  9.48s/it] 30%|███       | 3/10 [00:28<01:06,  9.45s/it] 40%|████      | 4/10 [00:37<00:56,  9.48s/it] 50%|█████     | 5/10 [00:47<00:47,  9.48s/it] 60%|██████    | 6/10 [00:56<00:37,  9.49s/it] 70%|███████   | 7/10 [01:06<00:28,  9.49s/it] 80%|████████  | 8/10 [01:15<00:18,  9.48s/it] 90%|█████████ | 9/10 [01:25<00:09,  9.45s/it]100%|██████████| 10/10 [01:34<00:00,  9.45s/it]100%|██████████| 10/10 [01:34<00:00,  9.47s/it]
iteration:  15
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.31it/s]
Number of steps:  64
[ 64 ]Privacy loss is 7.369218646919686
The final epsilon delta values after the training is over:  (7.369218646919686, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.603448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:25,  9.46s/it] 20%|██        | 2/10 [00:18<01:15,  9.45s/it] 30%|███       | 3/10 [00:28<01:06,  9.44s/it] 40%|████      | 4/10 [00:37<00:56,  9.45s/it] 50%|█████     | 5/10 [00:47<00:47,  9.46s/it] 60%|██████    | 6/10 [00:56<00:37,  9.46s/it] 70%|███████   | 7/10 [01:06<00:28,  9.46s/it] 80%|████████  | 8/10 [01:15<00:18,  9.46s/it] 90%|█████████ | 9/10 [01:25<00:09,  9.47s/it]100%|██████████| 10/10 [01:34<00:00,  9.47s/it]100%|██████████| 10/10 [01:34<00:00,  9.46s/it]
iteration:  16
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 69.09it/s]
Number of steps:  64
[ 64 ]Privacy loss is 6.494281640688786
The final epsilon delta values after the training is over:  (6.494281640688786, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.6551724137931034, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:26,  9.56s/it] 20%|██        | 2/10 [00:19<01:15,  9.49s/it] 30%|███       | 3/10 [00:28<01:06,  9.51s/it] 40%|████      | 4/10 [00:38<00:56,  9.50s/it] 50%|█████     | 5/10 [00:47<00:48,  9.62s/it] 60%|██████    | 6/10 [00:57<00:38,  9.55s/it] 70%|███████   | 7/10 [01:06<00:28,  9.51s/it] 80%|████████  | 8/10 [01:16<00:19,  9.52s/it] 90%|█████████ | 9/10 [01:25<00:09,  9.57s/it]100%|██████████| 10/10 [01:35<00:00,  9.54s/it]100%|██████████| 10/10 [01:35<00:00,  9.54s/it]
iteration:  17
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 69.13it/s]
Number of steps:  64
[ 64 ]Privacy loss is 6.494281640688786
The final epsilon delta values after the training is over:  (6.494281640688786, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.6551724137931034, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:25,  9.52s/it] 20%|██        | 2/10 [00:19<01:16,  9.59s/it] 30%|███       | 3/10 [00:28<01:06,  9.56s/it] 40%|████      | 4/10 [00:38<00:57,  9.56s/it] 50%|█████     | 5/10 [00:47<00:47,  9.54s/it] 60%|██████    | 6/10 [00:57<00:38,  9.52s/it] 70%|███████   | 7/10 [01:06<00:28,  9.51s/it] 80%|████████  | 8/10 [01:16<00:19,  9.52s/it] 90%|█████████ | 9/10 [01:25<00:09,  9.53s/it]100%|██████████| 10/10 [01:35<00:00,  9.54s/it]100%|██████████| 10/10 [01:35<00:00,  9.54s/it]
iteration:  18
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 69.08it/s]
Number of steps:  64
[ 64 ]Privacy loss is 6.494281640688786
The final epsilon delta values after the training is over:  (6.494281640688786, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.6551724137931034, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:26,  9.64s/it] 20%|██        | 2/10 [00:19<01:16,  9.56s/it] 30%|███       | 3/10 [00:28<01:06,  9.53s/it] 40%|████      | 4/10 [00:38<00:57,  9.52s/it] 50%|█████     | 5/10 [00:47<00:47,  9.51s/it] 60%|██████    | 6/10 [00:57<00:38,  9.52s/it] 70%|███████   | 7/10 [01:06<00:28,  9.52s/it] 80%|████████  | 8/10 [01:16<00:19,  9.50s/it] 90%|█████████ | 9/10 [01:25<00:09,  9.51s/it]100%|██████████| 10/10 [01:35<00:00,  9.52s/it]100%|██████████| 10/10 [01:35<00:00,  9.52s/it]
iteration:  19
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 70.27it/s]
Number of steps:  64
[ 64 ]Privacy loss is 6.494281640688786
The final epsilon delta values after the training is over:  (6.494281640688786, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.6551724137931034, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:28,  9.80s/it] 20%|██        | 2/10 [00:19<01:17,  9.68s/it] 30%|███       | 3/10 [00:28<01:07,  9.64s/it] 40%|████      | 4/10 [00:38<00:58,  9.67s/it] 50%|█████     | 5/10 [00:48<00:48,  9.64s/it] 60%|██████    | 6/10 [00:57<00:38,  9.61s/it] 70%|███████   | 7/10 [01:07<00:28,  9.60s/it] 80%|████████  | 8/10 [01:17<00:19,  9.60s/it] 90%|█████████ | 9/10 [01:26<00:09,  9.60s/it]100%|██████████| 10/10 [01:36<00:00,  9.60s/it]100%|██████████| 10/10 [01:36<00:00,  9.62s/it]
iteration:  20
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.82it/s]
Number of steps:  64
[ 64 ]Privacy loss is 6.494281640688786
The final epsilon delta values after the training is over:  (6.494281640688786, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.6551724137931034, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:27,  9.67s/it] 20%|██        | 2/10 [00:19<01:17,  9.63s/it] 30%|███       | 3/10 [00:28<01:07,  9.61s/it] 40%|████      | 4/10 [00:38<00:57,  9.65s/it] 50%|█████     | 5/10 [00:48<00:48,  9.62s/it] 60%|██████    | 6/10 [00:57<00:38,  9.70s/it] 70%|███████   | 7/10 [01:07<00:28,  9.65s/it] 80%|████████  | 8/10 [01:17<00:19,  9.62s/it] 90%|█████████ | 9/10 [01:26<00:09,  9.60s/it]100%|██████████| 10/10 [01:36<00:00,  9.65s/it]100%|██████████| 10/10 [01:36<00:00,  9.64s/it]
iteration:  21
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.46it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.950910242291995
The final epsilon delta values after the training is over:  (4.950910242291995, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7068965517241379, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:27,  9.69s/it] 20%|██        | 2/10 [00:19<01:17,  9.68s/it] 30%|███       | 3/10 [00:29<01:08,  9.73s/it] 40%|████      | 4/10 [00:38<00:58,  9.68s/it] 50%|█████     | 5/10 [00:48<00:48,  9.65s/it] 60%|██████    | 6/10 [00:57<00:38,  9.64s/it] 70%|███████   | 7/10 [01:07<00:29,  9.69s/it] 80%|████████  | 8/10 [01:17<00:19,  9.67s/it] 90%|█████████ | 9/10 [01:27<00:09,  9.69s/it]100%|██████████| 10/10 [01:36<00:00,  9.67s/it]100%|██████████| 10/10 [01:36<00:00,  9.68s/it]
iteration:  22
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 69.63it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.950910242291995
The final epsilon delta values after the training is over:  (4.950910242291995, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7068965517241379, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:27,  9.71s/it] 20%|██        | 2/10 [00:19<01:18,  9.79s/it] 30%|███       | 3/10 [00:29<01:07,  9.69s/it] 40%|████      | 4/10 [00:38<00:57,  9.64s/it] 50%|█████     | 5/10 [00:48<00:48,  9.62s/it] 60%|██████    | 6/10 [00:57<00:38,  9.62s/it] 70%|███████   | 7/10 [01:07<00:28,  9.61s/it] 80%|████████  | 8/10 [01:17<00:19,  9.61s/it] 90%|█████████ | 9/10 [01:26<00:09,  9.62s/it]100%|██████████| 10/10 [01:36<00:00,  9.63s/it]100%|██████████| 10/10 [01:36<00:00,  9.64s/it]
iteration:  23
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 69.02it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.950910242291995
The final epsilon delta values after the training is over:  (4.950910242291995, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7068965517241379, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:26,  9.65s/it] 20%|██        | 2/10 [00:19<01:17,  9.63s/it] 30%|███       | 3/10 [00:28<01:07,  9.65s/it] 40%|████      | 4/10 [00:38<00:58,  9.70s/it] 50%|█████     | 5/10 [00:48<00:48,  9.69s/it] 60%|██████    | 6/10 [00:58<00:38,  9.66s/it] 70%|███████   | 7/10 [01:07<00:28,  9.65s/it] 80%|████████  | 8/10 [01:17<00:19,  9.65s/it] 90%|█████████ | 9/10 [01:26<00:09,  9.65s/it]100%|██████████| 10/10 [01:36<00:00,  9.65s/it]100%|██████████| 10/10 [01:36<00:00,  9.66s/it]
iteration:  24
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.34it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.950910242291995
The final epsilon delta values after the training is over:  (4.950910242291995, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7068965517241379, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:26,  9.66s/it] 20%|██        | 2/10 [00:19<01:17,  9.67s/it] 30%|███       | 3/10 [00:28<01:07,  9.65s/it] 40%|████      | 4/10 [00:38<00:57,  9.64s/it] 50%|█████     | 5/10 [00:48<00:48,  9.64s/it] 60%|██████    | 6/10 [00:57<00:38,  9.65s/it] 70%|███████   | 7/10 [01:07<00:28,  9.64s/it] 80%|████████  | 8/10 [01:17<00:19,  9.64s/it] 90%|█████████ | 9/10 [01:26<00:09,  9.67s/it]100%|██████████| 10/10 [01:36<00:00,  9.67s/it]100%|██████████| 10/10 [01:36<00:00,  9.66s/it]
iteration:  25
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.08it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.950910242291995
The final epsilon delta values after the training is over:  (4.950910242291995, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7068965517241379, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:30, 10.08s/it] 20%|██        | 2/10 [00:19<01:19,  9.93s/it] 30%|███       | 3/10 [00:29<01:08,  9.80s/it] 40%|████      | 4/10 [00:39<00:58,  9.74s/it] 50%|█████     | 5/10 [00:48<00:48,  9.70s/it] 60%|██████    | 6/10 [00:58<00:38,  9.68s/it] 70%|███████   | 7/10 [01:08<00:29,  9.67s/it] 80%|████████  | 8/10 [01:17<00:19,  9.67s/it] 90%|█████████ | 9/10 [01:27<00:09,  9.72s/it]100%|██████████| 10/10 [01:37<00:00,  9.75s/it]100%|██████████| 10/10 [01:37<00:00,  9.74s/it]
iteration:  26
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 69.77it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.390909639865212
The final epsilon delta values after the training is over:  (4.390909639865212, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7586206896551724, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:27,  9.70s/it] 20%|██        | 2/10 [00:19<01:17,  9.70s/it] 30%|███       | 3/10 [00:29<01:08,  9.84s/it] 40%|████      | 4/10 [00:39<00:58,  9.78s/it] 50%|█████     | 5/10 [00:48<00:48,  9.79s/it] 60%|██████    | 6/10 [00:58<00:39,  9.77s/it] 70%|███████   | 7/10 [01:08<00:29,  9.74s/it] 80%|████████  | 8/10 [01:18<00:19,  9.72s/it] 90%|█████████ | 9/10 [01:27<00:09,  9.79s/it]100%|██████████| 10/10 [01:37<00:00,  9.81s/it]100%|██████████| 10/10 [01:37<00:00,  9.78s/it]
iteration:  27
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.89it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.390909639865212
The final epsilon delta values after the training is over:  (4.390909639865212, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7586206896551724, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:28,  9.82s/it] 20%|██        | 2/10 [00:19<01:18,  9.76s/it] 30%|███       | 3/10 [00:29<01:09,  9.89s/it] 40%|████      | 4/10 [00:39<00:59,  9.85s/it] 50%|█████     | 5/10 [00:49<00:49,  9.83s/it] 60%|██████    | 6/10 [00:59<00:39,  9.84s/it] 70%|███████   | 7/10 [01:08<00:29,  9.83s/it] 80%|████████  | 8/10 [01:18<00:19,  9.79s/it] 90%|█████████ | 9/10 [01:28<00:09,  9.80s/it]100%|██████████| 10/10 [01:38<00:00,  9.80s/it]100%|██████████| 10/10 [01:38<00:00,  9.81s/it]
iteration:  28
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.99it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.390909639865212
The final epsilon delta values after the training is over:  (4.390909639865212, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7586206896551724, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:27,  9.77s/it] 20%|██        | 2/10 [00:19<01:18,  9.77s/it] 30%|███       | 3/10 [00:29<01:08,  9.75s/it] 40%|████      | 4/10 [00:39<00:58,  9.78s/it] 50%|█████     | 5/10 [00:48<00:49,  9.82s/it] 60%|██████    | 6/10 [00:58<00:39,  9.82s/it] 70%|███████   | 7/10 [01:08<00:29,  9.83s/it] 80%|████████  | 8/10 [01:18<00:19,  9.82s/it] 90%|█████████ | 9/10 [01:28<00:09,  9.81s/it]100%|██████████| 10/10 [01:38<00:00,  9.82s/it]100%|██████████| 10/10 [01:38<00:00,  9.81s/it]
iteration:  29
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 70.96it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.390909639865212
The final epsilon delta values after the training is over:  (4.390909639865212, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7586206896551724, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:28,  9.82s/it] 20%|██        | 2/10 [00:19<01:18,  9.84s/it] 30%|███       | 3/10 [00:29<01:08,  9.80s/it] 40%|████      | 4/10 [00:39<00:58,  9.78s/it] 50%|█████     | 5/10 [00:48<00:48,  9.77s/it] 60%|██████    | 6/10 [00:58<00:39,  9.76s/it] 70%|███████   | 7/10 [01:08<00:29,  9.76s/it] 80%|████████  | 8/10 [01:18<00:19,  9.78s/it] 90%|█████████ | 9/10 [01:28<00:09,  9.82s/it]100%|██████████| 10/10 [01:38<00:00,  9.88s/it]100%|██████████| 10/10 [01:38<00:00,  9.82s/it]
iteration:  30
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.45it/s]
Number of steps:  64
[ 64 ]Privacy loss is 4.390909639865212
The final epsilon delta values after the training is over:  (4.390909639865212, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.7586206896551724, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:27,  9.76s/it] 20%|██        | 2/10 [00:19<01:17,  9.75s/it] 30%|███       | 3/10 [00:29<01:08,  9.74s/it] 40%|████      | 4/10 [00:39<00:58,  9.76s/it] 50%|█████     | 5/10 [00:48<00:48,  9.75s/it] 60%|██████    | 6/10 [00:58<00:39,  9.76s/it] 70%|███████   | 7/10 [01:08<00:29,  9.81s/it] 80%|████████  | 8/10 [01:18<00:19,  9.80s/it] 90%|█████████ | 9/10 [01:28<00:09,  9.80s/it]100%|██████████| 10/10 [01:37<00:00,  9.81s/it]100%|██████████| 10/10 [01:37<00:00,  9.79s/it]
iteration:  31
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 69.10it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.5508920214596684
The final epsilon delta values after the training is over:  (3.5508920214596684, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8103448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:28,  9.83s/it] 20%|██        | 2/10 [00:19<01:18,  9.86s/it] 30%|███       | 3/10 [00:29<01:08,  9.84s/it] 40%|████      | 4/10 [00:39<00:59,  9.84s/it] 50%|█████     | 5/10 [00:49<00:49,  9.83s/it] 60%|██████    | 6/10 [00:59<00:39,  9.86s/it] 70%|███████   | 7/10 [01:08<00:29,  9.83s/it] 80%|████████  | 8/10 [01:18<00:19,  9.82s/it] 90%|█████████ | 9/10 [01:28<00:09,  9.82s/it]100%|██████████| 10/10 [01:38<00:00,  9.82s/it]100%|██████████| 10/10 [01:38<00:00,  9.83s/it]
iteration:  32
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.77it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.5508920214596684
The final epsilon delta values after the training is over:  (3.5508920214596684, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8103448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:28,  9.79s/it] 20%|██        | 2/10 [00:19<01:18,  9.79s/it] 30%|███       | 3/10 [00:29<01:08,  9.79s/it] 40%|████      | 4/10 [00:39<00:58,  9.79s/it] 50%|█████     | 5/10 [00:48<00:48,  9.79s/it] 60%|██████    | 6/10 [00:58<00:39,  9.78s/it] 70%|███████   | 7/10 [01:08<00:29,  9.79s/it] 80%|████████  | 8/10 [01:18<00:19,  9.79s/it] 90%|█████████ | 9/10 [01:28<00:09,  9.79s/it]100%|██████████| 10/10 [01:37<00:00,  9.81s/it]100%|██████████| 10/10 [01:37<00:00,  9.80s/it]
iteration:  33
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.53it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.5508920214596684
The final epsilon delta values after the training is over:  (3.5508920214596684, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8103448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:29,  9.98s/it] 20%|██        | 2/10 [00:19<01:18,  9.87s/it] 30%|███       | 3/10 [00:29<01:08,  9.85s/it] 40%|████      | 4/10 [00:39<00:59,  9.91s/it] 50%|█████     | 5/10 [00:49<00:49,  9.88s/it] 60%|██████    | 6/10 [00:59<00:39,  9.87s/it] 70%|███████   | 7/10 [01:09<00:29,  9.85s/it] 80%|████████  | 8/10 [01:18<00:19,  9.85s/it] 90%|█████████ | 9/10 [01:28<00:09,  9.85s/it]100%|██████████| 10/10 [01:38<00:00,  9.85s/it]100%|██████████| 10/10 [01:38<00:00,  9.86s/it]
iteration:  34
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.58it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.5508920214596684
The final epsilon delta values after the training is over:  (3.5508920214596684, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8103448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:31, 10.20s/it] 20%|██        | 2/10 [00:20<01:20, 10.03s/it] 30%|███       | 3/10 [00:30<01:10, 10.05s/it] 40%|████      | 4/10 [00:40<00:59,  9.99s/it] 50%|█████     | 5/10 [00:49<00:49,  9.95s/it] 60%|██████    | 6/10 [00:59<00:39,  9.93s/it] 70%|███████   | 7/10 [01:09<00:29,  9.95s/it] 80%|████████  | 8/10 [01:19<00:19,  9.96s/it] 90%|█████████ | 9/10 [01:29<00:09,  9.96s/it]100%|██████████| 10/10 [01:39<00:00,  9.94s/it]100%|██████████| 10/10 [01:39<00:00,  9.97s/it]
iteration:  35
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.89it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.5508920214596684
The final epsilon delta values after the training is over:  (3.5508920214596684, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8103448275862069, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:29,  9.97s/it] 20%|██        | 2/10 [00:19<01:19,  9.98s/it] 30%|███       | 3/10 [00:29<01:09,  9.94s/it] 40%|████      | 4/10 [00:39<00:59,  9.93s/it] 50%|█████     | 5/10 [00:49<00:49,  9.91s/it] 60%|██████    | 6/10 [00:59<00:39,  9.96s/it] 70%|███████   | 7/10 [01:09<00:29,  9.92s/it] 80%|████████  | 8/10 [01:19<00:19,  9.91s/it] 90%|█████████ | 9/10 [01:29<00:09,  9.98s/it]100%|██████████| 10/10 [01:39<00:00,  9.99s/it]100%|██████████| 10/10 [01:39<00:00,  9.96s/it]
iteration:  36
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.03it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.136072318576378
The final epsilon delta values after the training is over:  (3.136072318576378, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8620689655172413, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:30, 10.02s/it] 20%|██        | 2/10 [00:19<01:19,  9.92s/it] 30%|███       | 3/10 [00:29<01:09,  9.89s/it] 40%|████      | 4/10 [00:39<00:59,  9.88s/it] 50%|█████     | 5/10 [00:49<00:49,  9.91s/it] 60%|██████    | 6/10 [00:59<00:39,  9.90s/it] 70%|███████   | 7/10 [01:09<00:29,  9.89s/it] 80%|████████  | 8/10 [01:19<00:19,  9.90s/it] 90%|█████████ | 9/10 [01:29<00:09,  9.92s/it]100%|██████████| 10/10 [01:39<00:00,  9.91s/it]100%|██████████| 10/10 [01:39<00:00,  9.91s/it]
iteration:  37
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.99it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.136072318576378
The final epsilon delta values after the training is over:  (3.136072318576378, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8620689655172413, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:29,  9.93s/it] 20%|██        | 2/10 [00:19<01:19,  9.91s/it] 30%|███       | 3/10 [00:29<01:09,  9.92s/it] 40%|████      | 4/10 [00:39<00:59,  9.96s/it] 50%|█████     | 5/10 [00:49<00:49,  9.95s/it] 60%|██████    | 6/10 [00:59<00:39,  9.95s/it] 70%|███████   | 7/10 [01:09<00:29,  9.92s/it] 80%|████████  | 8/10 [01:19<00:19,  9.93s/it] 90%|█████████ | 9/10 [01:29<00:09,  9.91s/it]100%|██████████| 10/10 [01:39<00:00,  9.91s/it]100%|██████████| 10/10 [01:39<00:00,  9.92s/it]
iteration:  38
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.66it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.136072318576378
The final epsilon delta values after the training is over:  (3.136072318576378, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8620689655172413, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:28,  9.86s/it] 20%|██        | 2/10 [00:19<01:18,  9.86s/it] 30%|███       | 3/10 [00:29<01:09,  9.87s/it] 40%|████      | 4/10 [00:39<00:59,  9.95s/it] 50%|█████     | 5/10 [00:49<00:49,  9.94s/it] 60%|██████    | 6/10 [00:59<00:39,  9.93s/it] 70%|███████   | 7/10 [01:09<00:29,  9.95s/it] 80%|████████  | 8/10 [01:19<00:19,  9.94s/it] 90%|█████████ | 9/10 [01:29<00:09,  9.98s/it]100%|██████████| 10/10 [01:39<00:00,  9.97s/it]100%|██████████| 10/10 [01:39<00:00,  9.94s/it]
iteration:  39
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 69.59it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.136072318576378
The final epsilon delta values after the training is over:  (3.136072318576378, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8620689655172413, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:29,  9.93s/it] 20%|██        | 2/10 [00:19<01:19,  9.92s/it] 30%|███       | 3/10 [00:30<01:10, 10.04s/it] 40%|████      | 4/10 [00:40<01:00, 10.07s/it] 50%|█████     | 5/10 [00:50<00:50, 10.06s/it] 60%|██████    | 6/10 [01:00<00:40, 10.01s/it] 70%|███████   | 7/10 [01:10<00:29,  9.98s/it] 80%|████████  | 8/10 [01:19<00:19,  9.97s/it] 90%|█████████ | 9/10 [01:29<00:09,  9.96s/it]100%|██████████| 10/10 [01:39<00:00,  9.97s/it]100%|██████████| 10/10 [01:39<00:00,  9.99s/it]
iteration:  40
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.23it/s]
Number of steps:  64
[ 64 ]Privacy loss is 3.136072318576378
The final epsilon delta values after the training is over:  (3.136072318576378, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.8620689655172413, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:30, 10.10s/it] 20%|██        | 2/10 [00:20<01:19,  9.99s/it] 30%|███       | 3/10 [00:29<01:09,  9.94s/it] 40%|████      | 4/10 [00:39<00:59,  9.93s/it] 50%|█████     | 5/10 [00:49<00:49,  9.92s/it] 60%|██████    | 6/10 [00:59<00:39,  9.91s/it] 70%|███████   | 7/10 [01:09<00:29,  9.98s/it] 80%|████████  | 8/10 [01:19<00:19,  9.96s/it] 90%|█████████ | 9/10 [01:29<00:09,  9.96s/it]100%|██████████| 10/10 [01:39<00:00,  9.96s/it]100%|██████████| 10/10 [01:39<00:00,  9.95s/it]
iteration:  41
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.32it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.7525821481728774
The final epsilon delta values after the training is over:  (2.7525821481728774, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9137931034482758, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:29,  9.99s/it] 20%|██        | 2/10 [00:19<01:19,  9.98s/it] 30%|███       | 3/10 [00:29<01:09,  9.97s/it] 40%|████      | 4/10 [00:39<00:59,  9.96s/it] 50%|█████     | 5/10 [00:49<00:50, 10.02s/it] 60%|██████    | 6/10 [00:59<00:40, 10.01s/it] 70%|███████   | 7/10 [01:10<00:30, 10.07s/it] 80%|████████  | 8/10 [01:20<00:20, 10.05s/it] 90%|█████████ | 9/10 [01:30<00:10, 10.06s/it]100%|██████████| 10/10 [01:40<00:00, 10.06s/it]100%|██████████| 10/10 [01:40<00:00, 10.03s/it]
iteration:  42
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.80it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.7525821481728774
The final epsilon delta values after the training is over:  (2.7525821481728774, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9137931034482758, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:09<01:29,  9.97s/it] 20%|██        | 2/10 [00:19<01:19,  9.96s/it] 30%|███       | 3/10 [00:30<01:10, 10.02s/it] 40%|████      | 4/10 [00:40<01:00, 10.08s/it] 50%|█████     | 5/10 [00:50<00:50, 10.14s/it] 60%|██████    | 6/10 [01:00<00:40, 10.08s/it] 70%|███████   | 7/10 [01:10<00:30, 10.04s/it] 80%|████████  | 8/10 [01:20<00:20, 10.03s/it] 90%|█████████ | 9/10 [01:30<00:10, 10.02s/it]100%|██████████| 10/10 [01:40<00:00, 10.09s/it]100%|██████████| 10/10 [01:40<00:00, 10.06s/it]
iteration:  43
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.40it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.7525821481728774
The final epsilon delta values after the training is over:  (2.7525821481728774, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9137931034482758, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:30, 10.02s/it] 20%|██        | 2/10 [00:20<01:20, 10.02s/it] 30%|███       | 3/10 [00:30<01:10, 10.01s/it] 40%|████      | 4/10 [00:40<01:00, 10.02s/it] 50%|█████     | 5/10 [00:50<00:50, 10.04s/it] 60%|██████    | 6/10 [01:00<00:40, 10.06s/it] 70%|███████   | 7/10 [01:10<00:30, 10.06s/it] 80%|████████  | 8/10 [01:20<00:20, 10.05s/it] 90%|█████████ | 9/10 [01:30<00:10, 10.06s/it]100%|██████████| 10/10 [01:40<00:00, 10.07s/it]100%|██████████| 10/10 [01:40<00:00, 10.05s/it]
iteration:  44
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.38it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.7525821481728774
The final epsilon delta values after the training is over:  (2.7525821481728774, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9137931034482758, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:31, 10.16s/it] 20%|██        | 2/10 [00:20<01:20, 10.07s/it] 30%|███       | 3/10 [00:30<01:10, 10.05s/it] 40%|████      | 4/10 [00:40<01:00, 10.05s/it] 50%|█████     | 5/10 [00:50<00:50, 10.03s/it] 60%|██████    | 6/10 [01:00<00:40, 10.06s/it] 70%|███████   | 7/10 [01:10<00:30, 10.09s/it] 80%|████████  | 8/10 [01:20<00:20, 10.08s/it] 90%|█████████ | 9/10 [01:30<00:10, 10.13s/it]100%|██████████| 10/10 [01:40<00:00, 10.10s/it]100%|██████████| 10/10 [01:40<00:00, 10.08s/it]
iteration:  45
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 69.41it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.7525821481728774
The final epsilon delta values after the training is over:  (2.7525821481728774, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9137931034482758, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:30, 10.05s/it] 20%|██        | 2/10 [00:20<01:20, 10.07s/it] 30%|███       | 3/10 [00:30<01:10, 10.08s/it] 40%|████      | 4/10 [00:40<01:00, 10.08s/it] 50%|█████     | 5/10 [00:50<00:50, 10.08s/it] 60%|██████    | 6/10 [01:00<00:40, 10.07s/it] 70%|███████   | 7/10 [01:10<00:30, 10.11s/it] 80%|████████  | 8/10 [01:21<00:20, 10.21s/it] 90%|█████████ | 9/10 [01:31<00:10, 10.16s/it]100%|██████████| 10/10 [01:41<00:00, 10.13s/it]100%|██████████| 10/10 [01:41<00:00, 10.12s/it]
iteration:  46
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.21it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.3962381625999214
The final epsilon delta values after the training is over:  (2.3962381625999214, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9655172413793103, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:30, 10.08s/it] 20%|██        | 2/10 [00:20<01:20, 10.10s/it] 30%|███       | 3/10 [00:30<01:10, 10.09s/it] 40%|████      | 4/10 [00:40<01:00, 10.07s/it] 50%|█████     | 5/10 [00:50<00:50, 10.15s/it] 60%|██████    | 6/10 [01:00<00:40, 10.15s/it] 70%|███████   | 7/10 [01:10<00:30, 10.17s/it] 80%|████████  | 8/10 [01:21<00:20, 10.18s/it] 90%|█████████ | 9/10 [01:31<00:10, 10.15s/it]100%|██████████| 10/10 [01:41<00:00, 10.18s/it]100%|██████████| 10/10 [01:41<00:00, 10.15s/it]
iteration:  47
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.89it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.3962381625999214
The final epsilon delta values after the training is over:  (2.3962381625999214, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9655172413793103, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:31, 10.12s/it] 20%|██        | 2/10 [00:20<01:20, 10.10s/it] 30%|███       | 3/10 [00:30<01:10, 10.12s/it] 40%|████      | 4/10 [00:40<01:00, 10.12s/it] 50%|█████     | 5/10 [00:50<00:50, 10.12s/it] 60%|██████    | 6/10 [01:00<00:40, 10.12s/it] 70%|███████   | 7/10 [01:10<00:30, 10.12s/it] 80%|████████  | 8/10 [01:20<00:20, 10.12s/it] 90%|█████████ | 9/10 [01:31<00:10, 10.14s/it]100%|██████████| 10/10 [01:41<00:00, 10.20s/it]100%|██████████| 10/10 [01:41<00:00, 10.15s/it]
iteration:  48
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.07it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.3962381625999214
The final epsilon delta values after the training is over:  (2.3962381625999214, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9655172413793103, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:30, 10.09s/it] 20%|██        | 2/10 [00:20<01:20, 10.10s/it] 30%|███       | 3/10 [00:30<01:10, 10.11s/it] 40%|████      | 4/10 [00:40<01:00, 10.10s/it] 50%|█████     | 5/10 [00:50<00:50, 10.10s/it] 60%|██████    | 6/10 [01:00<00:40, 10.10s/it] 70%|███████   | 7/10 [01:10<00:30, 10.10s/it] 80%|████████  | 8/10 [01:20<00:20, 10.12s/it] 90%|█████████ | 9/10 [01:31<00:10, 10.16s/it]100%|██████████| 10/10 [01:41<00:00, 10.16s/it]100%|██████████| 10/10 [01:41<00:00, 10.13s/it]
iteration:  49
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.83it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.3962381625999214
The final epsilon delta values after the training is over:  (2.3962381625999214, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9655172413793103, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:30, 10.10s/it] 20%|██        | 2/10 [00:20<01:21, 10.21s/it] 30%|███       | 3/10 [00:30<01:11, 10.28s/it] 40%|████      | 4/10 [00:40<01:01, 10.20s/it] 50%|█████     | 5/10 [00:51<00:51, 10.25s/it] 60%|██████    | 6/10 [01:01<00:40, 10.22s/it] 70%|███████   | 7/10 [01:11<00:30, 10.19s/it] 80%|████████  | 8/10 [01:21<00:20, 10.19s/it] 90%|█████████ | 9/10 [01:32<00:10, 10.31s/it]100%|██████████| 10/10 [01:42<00:00, 10.27s/it]100%|██████████| 10/10 [01:42<00:00, 10.24s/it]
iteration:  50
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.22it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.3962381625999214
The final epsilon delta values after the training is over:  (2.3962381625999214, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 0.9655172413793103, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:32, 10.27s/it] 20%|██        | 2/10 [00:20<01:22, 10.29s/it] 30%|███       | 3/10 [00:31<01:12, 10.36s/it] 40%|████      | 4/10 [00:41<01:01, 10.26s/it] 50%|█████     | 5/10 [00:51<00:50, 10.20s/it] 60%|██████    | 6/10 [01:01<00:40, 10.16s/it] 70%|███████   | 7/10 [01:11<00:30, 10.15s/it] 80%|████████  | 8/10 [01:21<00:20, 10.14s/it] 90%|█████████ | 9/10 [01:31<00:10, 10.14s/it]100%|██████████| 10/10 [01:41<00:00, 10.14s/it]100%|██████████| 10/10 [01:41<00:00, 10.18s/it]
iteration:  51
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.56it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.143529429767139
The final epsilon delta values after the training is over:  (2.143529429767139, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0172413793103448, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:31, 10.13s/it] 20%|██        | 2/10 [00:20<01:20, 10.12s/it] 30%|███       | 3/10 [00:30<01:10, 10.14s/it] 40%|████      | 4/10 [00:40<01:00, 10.13s/it] 50%|█████     | 5/10 [00:50<00:50, 10.12s/it] 60%|██████    | 6/10 [01:00<00:40, 10.16s/it] 70%|███████   | 7/10 [01:11<00:30, 10.22s/it] 80%|████████  | 8/10 [01:21<00:20, 10.19s/it] 90%|█████████ | 9/10 [01:31<00:10, 10.17s/it]100%|██████████| 10/10 [01:41<00:00, 10.17s/it]100%|██████████| 10/10 [01:41<00:00, 10.17s/it]
iteration:  52
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.64it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.143529429767139
The final epsilon delta values after the training is over:  (2.143529429767139, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0172413793103448, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:31, 10.20s/it] 20%|██        | 2/10 [00:20<01:21, 10.15s/it] 30%|███       | 3/10 [00:30<01:10, 10.13s/it] 40%|████      | 4/10 [00:40<01:01, 10.21s/it] 50%|█████     | 5/10 [00:50<00:51, 10.21s/it] 60%|██████    | 6/10 [01:01<00:40, 10.24s/it] 70%|███████   | 7/10 [01:11<00:30, 10.20s/it] 80%|████████  | 8/10 [01:21<00:20, 10.18s/it] 90%|█████████ | 9/10 [01:31<00:10, 10.20s/it]100%|██████████| 10/10 [01:41<00:00, 10.19s/it]100%|██████████| 10/10 [01:41<00:00, 10.19s/it]
iteration:  53
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 68.56it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.143529429767139
The final epsilon delta values after the training is over:  (2.143529429767139, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0172413793103448, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:31, 10.16s/it] 20%|██        | 2/10 [00:20<01:22, 10.27s/it] 30%|███       | 3/10 [00:30<01:11, 10.26s/it] 40%|████      | 4/10 [00:40<01:01, 10.25s/it] 50%|█████     | 5/10 [00:51<00:51, 10.27s/it] 60%|██████    | 6/10 [01:01<00:41, 10.28s/it] 70%|███████   | 7/10 [01:11<00:30, 10.26s/it] 80%|████████  | 8/10 [01:22<00:20, 10.24s/it] 90%|█████████ | 9/10 [01:32<00:10, 10.28s/it]100%|██████████| 10/10 [01:42<00:00, 10.26s/it]100%|██████████| 10/10 [01:42<00:00, 10.26s/it]
iteration:  54
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.62it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.143529429767139
The final epsilon delta values after the training is over:  (2.143529429767139, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0172413793103448, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:31, 10.17s/it] 20%|██        | 2/10 [00:20<01:21, 10.16s/it] 30%|███       | 3/10 [00:30<01:12, 10.31s/it] 40%|████      | 4/10 [00:41<01:01, 10.27s/it] 50%|█████     | 5/10 [00:51<00:51, 10.31s/it] 60%|██████    | 6/10 [01:01<00:41, 10.26s/it] 70%|███████   | 7/10 [01:11<00:30, 10.30s/it] 80%|████████  | 8/10 [01:22<00:20, 10.26s/it] 90%|█████████ | 9/10 [01:32<00:10, 10.23s/it]100%|██████████| 10/10 [01:42<00:00, 10.25s/it]100%|██████████| 10/10 [01:42<00:00, 10.26s/it]
iteration:  55
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.63it/s]
Number of steps:  64
[ 64 ]Privacy loss is 2.143529429767139
The final epsilon delta values after the training is over:  (2.143529429767139, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0172413793103448, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:32, 10.22s/it] 20%|██        | 2/10 [00:20<01:21, 10.21s/it] 30%|███       | 3/10 [00:30<01:11, 10.26s/it] 40%|████      | 4/10 [00:40<01:01, 10.25s/it] 50%|█████     | 5/10 [00:51<00:51, 10.27s/it] 60%|██████    | 6/10 [01:01<00:40, 10.23s/it] 70%|███████   | 7/10 [01:11<00:30, 10.21s/it] 80%|████████  | 8/10 [01:21<00:20, 10.21s/it] 90%|█████████ | 9/10 [01:32<00:10, 10.21s/it]100%|██████████| 10/10 [01:42<00:00, 10.34s/it]100%|██████████| 10/10 [01:42<00:00, 10.26s/it]
iteration:  56
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.54it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.9527687632759303
The final epsilon delta values after the training is over:  (1.9527687632759303, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0689655172413794, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:32, 10.31s/it] 20%|██        | 2/10 [00:20<01:22, 10.34s/it] 30%|███       | 3/10 [00:30<01:11, 10.27s/it] 40%|████      | 4/10 [00:41<01:01, 10.24s/it] 50%|█████     | 5/10 [00:51<00:51, 10.23s/it] 60%|██████    | 6/10 [01:01<00:41, 10.28s/it] 70%|███████   | 7/10 [01:12<00:30, 10.31s/it] 80%|████████  | 8/10 [01:22<00:20, 10.38s/it] 90%|█████████ | 9/10 [01:32<00:10, 10.33s/it]100%|██████████| 10/10 [01:42<00:00, 10.30s/it]100%|██████████| 10/10 [01:42<00:00, 10.30s/it]
iteration:  57
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.56it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.9527687632759303
The final epsilon delta values after the training is over:  (1.9527687632759303, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0689655172413794, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:32, 10.24s/it] 20%|██        | 2/10 [00:20<01:21, 10.23s/it] 30%|███       | 3/10 [00:30<01:11, 10.23s/it] 40%|████      | 4/10 [00:40<01:01, 10.22s/it] 50%|█████     | 5/10 [00:51<00:51, 10.22s/it] 60%|██████    | 6/10 [01:01<00:41, 10.29s/it] 70%|███████   | 7/10 [01:11<00:30, 10.30s/it] 80%|████████  | 8/10 [01:22<00:20, 10.30s/it] 90%|█████████ | 9/10 [01:32<00:10, 10.30s/it]100%|██████████| 10/10 [01:42<00:00, 10.33s/it]100%|██████████| 10/10 [01:42<00:00, 10.29s/it]
iteration:  58
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 67.21it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.9527687632759303
The final epsilon delta values after the training is over:  (1.9527687632759303, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0689655172413794, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:32, 10.25s/it] 20%|██        | 2/10 [00:20<01:22, 10.30s/it] 30%|███       | 3/10 [00:30<01:11, 10.28s/it] 40%|████      | 4/10 [00:41<01:01, 10.27s/it] 50%|█████     | 5/10 [00:51<00:51, 10.33s/it] 60%|██████    | 6/10 [01:01<00:41, 10.33s/it] 70%|███████   | 7/10 [01:12<00:30, 10.31s/it] 80%|████████  | 8/10 [01:22<00:20, 10.33s/it] 90%|█████████ | 9/10 [01:32<00:10, 10.34s/it]100%|██████████| 10/10 [01:43<00:00, 10.34s/it]100%|██████████| 10/10 [01:43<00:00, 10.32s/it]
iteration:  59
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.89it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.9527687632759303
The final epsilon delta values after the training is over:  (1.9527687632759303, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0689655172413794, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:32, 10.29s/it] 20%|██        | 2/10 [00:20<01:22, 10.28s/it] 30%|███       | 3/10 [00:30<01:12, 10.30s/it] 40%|████      | 4/10 [00:41<01:02, 10.42s/it] 50%|█████     | 5/10 [00:51<00:52, 10.40s/it] 60%|██████    | 6/10 [01:02<00:41, 10.38s/it] 70%|███████   | 7/10 [01:13<00:31, 10.56s/it] 80%|████████  | 8/10 [01:23<00:20, 10.47s/it] 90%|█████████ | 9/10 [01:34<00:10, 10.52s/it]100%|██████████| 10/10 [01:44<00:00, 10.52s/it]100%|██████████| 10/10 [01:44<00:00, 10.46s/it]
iteration:  60
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.09it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.9527687632759303
The final epsilon delta values after the training is over:  (1.9527687632759303, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.0689655172413794, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:33, 10.44s/it] 20%|██        | 2/10 [00:20<01:23, 10.38s/it] 30%|███       | 3/10 [00:31<01:13, 10.44s/it] 40%|████      | 4/10 [00:41<01:02, 10.38s/it] 50%|█████     | 5/10 [00:51<00:51, 10.34s/it] 60%|██████    | 6/10 [01:02<00:41, 10.32s/it] 70%|███████   | 7/10 [01:12<00:31, 10.43s/it] 80%|████████  | 8/10 [01:23<00:20, 10.40s/it] 90%|█████████ | 9/10 [01:33<00:10, 10.39s/it]100%|██████████| 10/10 [01:43<00:00, 10.39s/it]100%|██████████| 10/10 [01:43<00:00, 10.39s/it]
iteration:  61
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.70it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.7995410093407855
The final epsilon delta values after the training is over:  (1.7995410093407855, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1206896551724137, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:36, 10.74s/it] 20%|██        | 2/10 [00:21<01:24, 10.58s/it] 30%|███       | 3/10 [00:31<01:13, 10.48s/it] 40%|████      | 4/10 [00:41<01:02, 10.46s/it] 50%|█████     | 5/10 [00:52<00:52, 10.43s/it] 60%|██████    | 6/10 [01:02<00:41, 10.44s/it] 70%|███████   | 7/10 [01:13<00:31, 10.45s/it] 80%|████████  | 8/10 [01:23<00:20, 10.46s/it] 90%|█████████ | 9/10 [01:34<00:10, 10.59s/it]100%|██████████| 10/10 [01:45<00:00, 10.52s/it]100%|██████████| 10/10 [01:45<00:00, 10.50s/it]
iteration:  62
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.81it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.7995410093407855
The final epsilon delta values after the training is over:  (1.7995410093407855, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1206896551724137, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:32, 10.32s/it] 20%|██        | 2/10 [00:20<01:22, 10.32s/it] 30%|███       | 3/10 [00:30<01:12, 10.32s/it] 40%|████      | 4/10 [00:41<01:01, 10.32s/it] 50%|█████     | 5/10 [00:51<00:52, 10.41s/it] 60%|██████    | 6/10 [01:02<00:41, 10.42s/it] 70%|███████   | 7/10 [01:12<00:31, 10.42s/it] 80%|████████  | 8/10 [01:23<00:20, 10.40s/it] 90%|█████████ | 9/10 [01:33<00:10, 10.42s/it]100%|██████████| 10/10 [01:43<00:00, 10.40s/it]100%|██████████| 10/10 [01:43<00:00, 10.39s/it]
iteration:  63
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.83it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.7995410093407855
The final epsilon delta values after the training is over:  (1.7995410093407855, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1206896551724137, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:33, 10.43s/it] 20%|██        | 2/10 [00:20<01:23, 10.39s/it] 30%|███       | 3/10 [00:31<01:12, 10.40s/it] 40%|████      | 4/10 [00:41<01:02, 10.43s/it] 50%|█████     | 5/10 [00:52<00:52, 10.41s/it] 60%|██████    | 6/10 [01:02<00:41, 10.41s/it] 70%|███████   | 7/10 [01:12<00:31, 10.40s/it] 80%|████████  | 8/10 [01:23<00:20, 10.38s/it] 90%|█████████ | 9/10 [01:33<00:10, 10.39s/it]100%|██████████| 10/10 [01:43<00:00, 10.39s/it]100%|██████████| 10/10 [01:43<00:00, 10.40s/it]
iteration:  64
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.16it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.7995410093407855
The final epsilon delta values after the training is over:  (1.7995410093407855, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1206896551724137, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:33, 10.41s/it] 20%|██        | 2/10 [00:20<01:22, 10.37s/it] 30%|███       | 3/10 [00:31<01:12, 10.37s/it] 40%|████      | 4/10 [00:41<01:02, 10.44s/it] 50%|█████     | 5/10 [00:52<00:52, 10.45s/it] 60%|██████    | 6/10 [01:02<00:41, 10.43s/it] 70%|███████   | 7/10 [01:12<00:31, 10.43s/it] 80%|████████  | 8/10 [01:23<00:20, 10.44s/it] 90%|█████████ | 9/10 [01:33<00:10, 10.44s/it]100%|██████████| 10/10 [01:44<00:00, 10.48s/it]100%|██████████| 10/10 [01:44<00:00, 10.45s/it]
iteration:  65
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.28it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.7995410093407855
The final epsilon delta values after the training is over:  (1.7995410093407855, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1206896551724137, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:36, 10.72s/it] 20%|██        | 2/10 [00:21<01:24, 10.52s/it] 30%|███       | 3/10 [00:31<01:13, 10.47s/it] 40%|████      | 4/10 [00:41<01:02, 10.44s/it] 50%|█████     | 5/10 [00:52<00:52, 10.44s/it] 60%|██████    | 6/10 [01:02<00:41, 10.43s/it] 70%|███████   | 7/10 [01:13<00:31, 10.42s/it] 80%|████████  | 8/10 [01:23<00:20, 10.42s/it] 90%|█████████ | 9/10 [01:34<00:10, 10.48s/it]100%|██████████| 10/10 [01:44<00:00, 10.48s/it]100%|██████████| 10/10 [01:44<00:00, 10.47s/it]
iteration:  66
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.90it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.6696234071796798
The final epsilon delta values after the training is over:  (1.6696234071796798, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1724137931034484, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:34, 10.49s/it] 20%|██        | 2/10 [00:21<01:24, 10.54s/it] 30%|███       | 3/10 [00:31<01:13, 10.56s/it] 40%|████      | 4/10 [00:42<01:03, 10.51s/it] 50%|█████     | 5/10 [00:52<00:52, 10.48s/it] 60%|██████    | 6/10 [01:03<00:42, 10.53s/it] 70%|███████   | 7/10 [01:13<00:31, 10.53s/it] 80%|████████  | 8/10 [01:24<00:21, 10.50s/it] 90%|█████████ | 9/10 [01:34<00:10, 10.49s/it]100%|██████████| 10/10 [01:45<00:00, 10.48s/it]100%|██████████| 10/10 [01:45<00:00, 10.51s/it]
iteration:  67
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.72it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.6696234071796798
The final epsilon delta values after the training is over:  (1.6696234071796798, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1724137931034484, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:34, 10.48s/it] 20%|██        | 2/10 [00:21<01:24, 10.52s/it] 30%|███       | 3/10 [00:31<01:13, 10.54s/it] 40%|████      | 4/10 [00:42<01:02, 10.50s/it] 50%|█████     | 5/10 [00:52<00:52, 10.47s/it] 60%|██████    | 6/10 [01:02<00:41, 10.45s/it] 70%|███████   | 7/10 [01:13<00:31, 10.46s/it] 80%|████████  | 8/10 [01:23<00:20, 10.46s/it] 90%|█████████ | 9/10 [01:34<00:10, 10.51s/it]100%|██████████| 10/10 [01:44<00:00, 10.50s/it]100%|██████████| 10/10 [01:44<00:00, 10.49s/it]
iteration:  68
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.73it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.6696234071796798
The final epsilon delta values after the training is over:  (1.6696234071796798, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1724137931034484, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.82s/it] 20%|██        | 2/10 [00:21<01:24, 10.60s/it] 30%|███       | 3/10 [00:31<01:13, 10.52s/it] 40%|████      | 4/10 [00:42<01:02, 10.49s/it] 50%|█████     | 5/10 [00:52<00:52, 10.48s/it] 60%|██████    | 6/10 [01:03<00:42, 10.53s/it] 70%|███████   | 7/10 [01:13<00:31, 10.53s/it] 80%|████████  | 8/10 [01:24<00:21, 10.56s/it] 90%|█████████ | 9/10 [01:35<00:10, 10.60s/it]100%|██████████| 10/10 [01:45<00:00, 10.61s/it]100%|██████████| 10/10 [01:45<00:00, 10.57s/it]
iteration:  69
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.16it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.6696234071796798
The final epsilon delta values after the training is over:  (1.6696234071796798, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1724137931034484, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:35, 10.56s/it] 20%|██        | 2/10 [00:21<01:24, 10.57s/it] 30%|███       | 3/10 [00:31<01:14, 10.57s/it] 40%|████      | 4/10 [00:42<01:03, 10.55s/it] 50%|█████     | 5/10 [00:52<00:52, 10.55s/it] 60%|██████    | 6/10 [01:03<00:42, 10.56s/it] 70%|███████   | 7/10 [01:14<00:31, 10.61s/it] 80%|████████  | 8/10 [01:24<00:21, 10.58s/it] 90%|█████████ | 9/10 [01:35<00:10, 10.55s/it]100%|██████████| 10/10 [01:45<00:00, 10.54s/it]100%|██████████| 10/10 [01:45<00:00, 10.56s/it]
iteration:  70
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.34it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.6696234071796798
The final epsilon delta values after the training is over:  (1.6696234071796798, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.1724137931034484, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:34, 10.54s/it] 20%|██        | 2/10 [00:21<01:24, 10.52s/it] 30%|███       | 3/10 [00:31<01:13, 10.49s/it] 40%|████      | 4/10 [00:41<01:02, 10.48s/it] 50%|█████     | 5/10 [00:52<00:52, 10.47s/it] 60%|██████    | 6/10 [01:02<00:41, 10.50s/it] 70%|███████   | 7/10 [01:13<00:31, 10.49s/it] 80%|████████  | 8/10 [01:23<00:20, 10.50s/it] 90%|█████████ | 9/10 [01:34<00:10, 10.50s/it]100%|██████████| 10/10 [01:44<00:00, 10.50s/it]100%|██████████| 10/10 [01:44<00:00, 10.50s/it]
iteration:  71
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.07it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.54766719601816
The final epsilon delta values after the training is over:  (1.54766719601816, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2241379310344827, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:34, 10.53s/it] 20%|██        | 2/10 [00:21<01:24, 10.52s/it] 30%|███       | 3/10 [00:31<01:14, 10.65s/it] 40%|████      | 4/10 [00:42<01:03, 10.61s/it] 50%|█████     | 5/10 [00:53<00:53, 10.63s/it] 60%|██████    | 6/10 [01:03<00:42, 10.59s/it] 70%|███████   | 7/10 [01:14<00:31, 10.56s/it] 80%|████████  | 8/10 [01:24<00:21, 10.55s/it] 90%|█████████ | 9/10 [01:35<00:10, 10.55s/it]100%|██████████| 10/10 [01:45<00:00, 10.54s/it]100%|██████████| 10/10 [01:45<00:00, 10.57s/it]
iteration:  72
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.01it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.54766719601816
The final epsilon delta values after the training is over:  (1.54766719601816, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2241379310344827, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.80s/it] 20%|██        | 2/10 [00:21<01:26, 10.80s/it] 30%|███       | 3/10 [00:32<01:14, 10.67s/it] 40%|████      | 4/10 [00:42<01:03, 10.66s/it] 50%|█████     | 5/10 [00:53<00:53, 10.64s/it] 60%|██████    | 6/10 [01:03<00:42, 10.59s/it] 70%|███████   | 7/10 [01:14<00:31, 10.56s/it] 80%|████████  | 8/10 [01:24<00:21, 10.54s/it] 90%|█████████ | 9/10 [01:35<00:10, 10.53s/it]100%|██████████| 10/10 [01:45<00:00, 10.53s/it]100%|██████████| 10/10 [01:45<00:00, 10.59s/it]
iteration:  73
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.49it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.54766719601816
The final epsilon delta values after the training is over:  (1.54766719601816, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2241379310344827, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:34, 10.55s/it] 20%|██        | 2/10 [00:21<01:24, 10.54s/it] 30%|███       | 3/10 [00:31<01:13, 10.53s/it] 40%|████      | 4/10 [00:42<01:03, 10.54s/it] 50%|█████     | 5/10 [00:52<00:52, 10.54s/it] 60%|██████    | 6/10 [01:03<00:42, 10.55s/it] 70%|███████   | 7/10 [01:13<00:31, 10.55s/it] 80%|████████  | 8/10 [01:24<00:21, 10.56s/it] 90%|█████████ | 9/10 [01:34<00:10, 10.57s/it]100%|██████████| 10/10 [01:45<00:00, 10.58s/it]100%|██████████| 10/10 [01:45<00:00, 10.56s/it]
iteration:  74
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.34it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.54766719601816
The final epsilon delta values after the training is over:  (1.54766719601816, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2241379310344827, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:35, 10.58s/it] 20%|██        | 2/10 [00:21<01:24, 10.57s/it] 30%|███       | 3/10 [00:31<01:13, 10.57s/it] 40%|████      | 4/10 [00:42<01:03, 10.57s/it] 50%|█████     | 5/10 [00:52<00:52, 10.57s/it] 60%|██████    | 6/10 [01:03<00:42, 10.57s/it] 70%|███████   | 7/10 [01:13<00:31, 10.57s/it] 80%|████████  | 8/10 [01:24<00:21, 10.58s/it] 90%|█████████ | 9/10 [01:35<00:10, 10.58s/it]100%|██████████| 10/10 [01:45<00:00, 10.59s/it]100%|██████████| 10/10 [01:45<00:00, 10.58s/it]
iteration:  75
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.84it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.54766719601816
The final epsilon delta values after the training is over:  (1.54766719601816, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2241379310344827, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:35, 10.60s/it] 20%|██        | 2/10 [00:21<01:24, 10.59s/it] 30%|███       | 3/10 [00:32<01:15, 10.78s/it] 40%|████      | 4/10 [00:42<01:04, 10.76s/it] 50%|█████     | 5/10 [00:53<00:53, 10.69s/it] 60%|██████    | 6/10 [01:04<00:42, 10.65s/it] 70%|███████   | 7/10 [01:14<00:32, 10.70s/it] 80%|████████  | 8/10 [01:25<00:21, 10.70s/it] 90%|█████████ | 9/10 [01:36<00:10, 10.72s/it]100%|██████████| 10/10 [01:46<00:00, 10.69s/it]100%|██████████| 10/10 [01:46<00:00, 10.69s/it]
iteration:  76
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 66.47it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.4304109951869581
The final epsilon delta values after the training is over:  (1.4304109951869581, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2758620689655173, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:35, 10.61s/it] 20%|██        | 2/10 [00:21<01:24, 10.62s/it] 30%|███       | 3/10 [00:31<01:14, 10.62s/it] 40%|████      | 4/10 [00:42<01:03, 10.61s/it] 50%|█████     | 5/10 [00:53<00:53, 10.61s/it] 60%|██████    | 6/10 [01:03<00:42, 10.65s/it] 70%|███████   | 7/10 [01:14<00:31, 10.65s/it] 80%|████████  | 8/10 [01:25<00:21, 10.66s/it] 90%|█████████ | 9/10 [01:35<00:10, 10.65s/it]100%|██████████| 10/10 [01:46<00:00, 10.64s/it]100%|██████████| 10/10 [01:46<00:00, 10.64s/it]
iteration:  77
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.92it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.4304109951869581
The final epsilon delta values after the training is over:  (1.4304109951869581, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2758620689655173, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.81s/it] 20%|██        | 2/10 [00:21<01:25, 10.69s/it] 30%|███       | 3/10 [00:32<01:14, 10.66s/it] 40%|████      | 4/10 [00:42<01:03, 10.66s/it] 50%|█████     | 5/10 [00:53<00:53, 10.66s/it] 60%|██████    | 6/10 [01:03<00:42, 10.64s/it] 70%|███████   | 7/10 [01:14<00:31, 10.65s/it] 80%|████████  | 8/10 [01:25<00:21, 10.65s/it] 90%|█████████ | 9/10 [01:35<00:10, 10.65s/it]100%|██████████| 10/10 [01:46<00:00, 10.65s/it]100%|██████████| 10/10 [01:46<00:00, 10.66s/it]
iteration:  78
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.94it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.4304109951869581
The final epsilon delta values after the training is over:  (1.4304109951869581, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2758620689655173, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:35, 10.65s/it] 20%|██        | 2/10 [00:21<01:25, 10.63s/it] 30%|███       | 3/10 [00:31<01:14, 10.63s/it] 40%|████      | 4/10 [00:42<01:03, 10.64s/it] 50%|█████     | 5/10 [00:53<00:53, 10.63s/it] 60%|██████    | 6/10 [01:03<00:42, 10.64s/it] 70%|███████   | 7/10 [01:14<00:31, 10.64s/it] 80%|████████  | 8/10 [01:25<00:21, 10.65s/it] 90%|█████████ | 9/10 [01:35<00:10, 10.65s/it]100%|██████████| 10/10 [01:46<00:00, 10.73s/it]100%|██████████| 10/10 [01:46<00:00, 10.67s/it]
iteration:  79
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.82it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.4304109951869581
The final epsilon delta values after the training is over:  (1.4304109951869581, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2758620689655173, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.78s/it] 20%|██        | 2/10 [00:21<01:26, 10.75s/it] 30%|███       | 3/10 [00:32<01:14, 10.70s/it] 40%|████      | 4/10 [00:42<01:04, 10.69s/it] 50%|█████     | 5/10 [00:53<00:53, 10.67s/it] 60%|██████    | 6/10 [01:04<00:42, 10.67s/it] 70%|███████   | 7/10 [01:14<00:31, 10.66s/it] 80%|████████  | 8/10 [01:25<00:21, 10.65s/it] 90%|█████████ | 9/10 [01:36<00:10, 10.66s/it]100%|██████████| 10/10 [01:46<00:00, 10.66s/it]100%|██████████| 10/10 [01:46<00:00, 10.68s/it]
iteration:  80
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.47it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.4304109951869581
The final epsilon delta values after the training is over:  (1.4304109951869581, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.2758620689655173, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:36, 10.69s/it] 20%|██        | 2/10 [00:21<01:26, 10.77s/it] 30%|███       | 3/10 [00:32<01:15, 10.77s/it] 40%|████      | 4/10 [00:43<01:04, 10.77s/it] 50%|█████     | 5/10 [00:53<00:53, 10.73s/it] 60%|██████    | 6/10 [01:04<00:42, 10.73s/it] 70%|███████   | 7/10 [01:15<00:32, 10.71s/it] 80%|████████  | 8/10 [01:25<00:21, 10.71s/it] 90%|█████████ | 9/10 [01:36<00:10, 10.73s/it]100%|██████████| 10/10 [01:47<00:00, 10.76s/it]100%|██████████| 10/10 [01:47<00:00, 10.74s/it]
iteration:  81
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.95it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.3293639454188084
The final epsilon delta values after the training is over:  (1.3293639454188084, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3275862068965516, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:38, 10.96s/it] 20%|██        | 2/10 [00:21<01:26, 10.83s/it] 30%|███       | 3/10 [00:32<01:15, 10.79s/it] 40%|████      | 4/10 [00:43<01:04, 10.78s/it] 50%|█████     | 5/10 [00:53<00:53, 10.76s/it] 60%|██████    | 6/10 [01:04<00:43, 10.75s/it] 70%|███████   | 7/10 [01:15<00:32, 10.73s/it] 80%|████████  | 8/10 [01:26<00:21, 10.76s/it] 90%|█████████ | 9/10 [01:36<00:10, 10.74s/it]100%|██████████| 10/10 [01:47<00:00, 10.77s/it]100%|██████████| 10/10 [01:47<00:00, 10.77s/it]
iteration:  82
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.92it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.3293639454188084
The final epsilon delta values after the training is over:  (1.3293639454188084, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3275862068965516, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.82s/it] 20%|██        | 2/10 [00:21<01:27, 10.98s/it] 30%|███       | 3/10 [00:32<01:16, 10.93s/it] 40%|████      | 4/10 [00:43<01:05, 10.92s/it] 50%|█████     | 5/10 [00:54<00:54, 10.84s/it] 60%|██████    | 6/10 [01:05<00:43, 10.81s/it] 70%|███████   | 7/10 [01:15<00:32, 10.80s/it] 80%|████████  | 8/10 [01:26<00:21, 10.79s/it] 90%|█████████ | 9/10 [01:37<00:10, 10.79s/it]100%|██████████| 10/10 [01:48<00:00, 10.79s/it]100%|██████████| 10/10 [01:48<00:00, 10.83s/it]
iteration:  83
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.40it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.3293639454188084
The final epsilon delta values after the training is over:  (1.3293639454188084, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3275862068965516, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.82s/it] 20%|██        | 2/10 [00:21<01:26, 10.79s/it] 30%|███       | 3/10 [00:32<01:15, 10.82s/it] 40%|████      | 4/10 [00:43<01:05, 10.87s/it] 50%|█████     | 5/10 [00:54<00:54, 10.89s/it] 60%|██████    | 6/10 [01:05<00:43, 10.86s/it] 70%|███████   | 7/10 [01:15<00:32, 10.82s/it] 80%|████████  | 8/10 [01:26<00:21, 10.80s/it] 90%|█████████ | 9/10 [01:37<00:10, 10.78s/it]100%|██████████| 10/10 [01:48<00:00, 10.77s/it]100%|██████████| 10/10 [01:48<00:00, 10.81s/it]
iteration:  84
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 65.05it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.3293639454188084
The final epsilon delta values after the training is over:  (1.3293639454188084, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3275862068965516, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:38, 10.92s/it] 20%|██        | 2/10 [00:21<01:26, 10.87s/it] 30%|███       | 3/10 [00:32<01:16, 10.89s/it] 40%|████      | 4/10 [00:43<01:04, 10.83s/it] 50%|█████     | 5/10 [00:54<00:54, 10.82s/it] 60%|██████    | 6/10 [01:04<00:43, 10.81s/it] 70%|███████   | 7/10 [01:15<00:32, 10.79s/it] 80%|████████  | 8/10 [01:26<00:21, 10.81s/it] 90%|█████████ | 9/10 [01:37<00:10, 10.79s/it]100%|██████████| 10/10 [01:48<00:00, 10.78s/it]100%|██████████| 10/10 [01:48<00:00, 10.81s/it]
iteration:  85
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.59it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.3293639454188084
The final epsilon delta values after the training is over:  (1.3293639454188084, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3275862068965516, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:36, 10.73s/it] 20%|██        | 2/10 [00:21<01:25, 10.75s/it] 30%|███       | 3/10 [00:32<01:15, 10.75s/it] 40%|████      | 4/10 [00:43<01:04, 10.79s/it] 50%|█████     | 5/10 [00:53<00:54, 10.82s/it] 60%|██████    | 6/10 [01:04<00:43, 10.80s/it] 70%|███████   | 7/10 [01:15<00:32, 10.83s/it] 80%|████████  | 8/10 [01:26<00:21, 10.82s/it] 90%|█████████ | 9/10 [01:37<00:10, 10.82s/it]100%|██████████| 10/10 [01:48<00:00, 10.83s/it]100%|██████████| 10/10 [01:48<00:00, 10.81s/it]
iteration:  86
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.99it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.2442729068833662
The final epsilon delta values after the training is over:  (1.2442729068833662, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3793103448275863, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.80s/it] 20%|██        | 2/10 [00:21<01:26, 10.79s/it] 30%|███       | 3/10 [00:32<01:15, 10.78s/it] 40%|████      | 4/10 [00:43<01:04, 10.77s/it] 50%|█████     | 5/10 [00:53<00:53, 10.77s/it] 60%|██████    | 6/10 [01:04<00:43, 10.76s/it] 70%|███████   | 7/10 [01:15<00:32, 10.76s/it] 80%|████████  | 8/10 [01:26<00:21, 10.79s/it] 90%|█████████ | 9/10 [01:37<00:10, 10.79s/it]100%|██████████| 10/10 [01:47<00:00, 10.81s/it]100%|██████████| 10/10 [01:47<00:00, 10.79s/it]
iteration:  87
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.07it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.2442729068833662
The final epsilon delta values after the training is over:  (1.2442729068833662, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3793103448275863, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:38, 10.94s/it] 20%|██        | 2/10 [00:21<01:27, 10.88s/it] 30%|███       | 3/10 [00:32<01:16, 10.86s/it] 40%|████      | 4/10 [00:43<01:05, 10.88s/it] 50%|█████     | 5/10 [00:54<00:54, 10.85s/it] 60%|██████    | 6/10 [01:05<00:43, 10.82s/it] 70%|███████   | 7/10 [01:15<00:32, 10.80s/it] 80%|████████  | 8/10 [01:26<00:21, 10.80s/it] 90%|█████████ | 9/10 [01:37<00:10, 10.80s/it]100%|██████████| 10/10 [01:48<00:00, 10.80s/it]100%|██████████| 10/10 [01:48<00:00, 10.83s/it]
iteration:  88
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.75it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.2442729068833662
The final epsilon delta values after the training is over:  (1.2442729068833662, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3793103448275863, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.83s/it] 20%|██        | 2/10 [00:21<01:26, 10.80s/it] 30%|███       | 3/10 [00:32<01:15, 10.81s/it] 40%|████      | 4/10 [00:43<01:04, 10.80s/it] 50%|█████     | 5/10 [00:54<00:54, 10.80s/it] 60%|██████    | 6/10 [01:04<00:43, 10.80s/it] 70%|███████   | 7/10 [01:15<00:32, 10.79s/it] 80%|████████  | 8/10 [01:26<00:21, 10.79s/it] 90%|█████████ | 9/10 [01:37<00:10, 10.80s/it]100%|██████████| 10/10 [01:48<00:00, 10.80s/it]100%|██████████| 10/10 [01:48<00:00, 10.80s/it]
iteration:  89
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.44it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.2442729068833662
The final epsilon delta values after the training is over:  (1.2442729068833662, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3793103448275863, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.82s/it] 20%|██        | 2/10 [00:21<01:26, 10.82s/it] 30%|███       | 3/10 [00:32<01:15, 10.81s/it] 40%|████      | 4/10 [00:43<01:04, 10.82s/it] 50%|█████     | 5/10 [00:54<00:54, 10.82s/it] 60%|██████    | 6/10 [01:04<00:43, 10.83s/it] 70%|███████   | 7/10 [01:15<00:32, 10.82s/it] 80%|████████  | 8/10 [01:26<00:21, 10.83s/it] 90%|█████████ | 9/10 [01:37<00:10, 10.83s/it]100%|██████████| 10/10 [01:48<00:00, 10.83s/it]100%|██████████| 10/10 [01:48<00:00, 10.82s/it]
iteration:  90
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.28it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.2442729068833662
The final epsilon delta values after the training is over:  (1.2442729068833662, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.3793103448275863, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:38, 10.93s/it] 20%|██        | 2/10 [00:21<01:27, 10.90s/it] 30%|███       | 3/10 [00:32<01:16, 10.90s/it] 40%|████      | 4/10 [00:43<01:05, 10.86s/it] 50%|█████     | 5/10 [00:54<00:54, 10.86s/it] 60%|██████    | 6/10 [01:05<00:43, 10.85s/it] 70%|███████   | 7/10 [01:16<00:32, 10.84s/it] 80%|████████  | 8/10 [01:27<00:21, 10.89s/it] 90%|█████████ | 9/10 [01:37<00:10, 10.89s/it]100%|██████████| 10/10 [01:48<00:00, 10.90s/it]100%|██████████| 10/10 [01:48<00:00, 10.88s/it]
iteration:  91
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.70it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1733379813769553
The final epsilon delta values after the training is over:  (1.1733379813769553, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4310344827586206, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:38, 10.90s/it] 20%|██        | 2/10 [00:21<01:27, 10.88s/it] 30%|███       | 3/10 [00:32<01:16, 10.95s/it] 40%|████      | 4/10 [00:43<01:05, 10.92s/it] 50%|█████     | 5/10 [00:54<00:54, 10.89s/it] 60%|██████    | 6/10 [01:05<00:43, 10.87s/it] 70%|███████   | 7/10 [01:16<00:32, 10.86s/it] 80%|████████  | 8/10 [01:27<00:21, 10.85s/it] 90%|█████████ | 9/10 [01:37<00:10, 10.85s/it]100%|██████████| 10/10 [01:48<00:00, 10.84s/it]100%|██████████| 10/10 [01:48<00:00, 10.87s/it]
iteration:  92
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.33it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1733379813769553
The final epsilon delta values after the training is over:  (1.1733379813769553, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4310344827586206, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:37, 10.86s/it] 20%|██        | 2/10 [00:21<01:27, 10.88s/it] 30%|███       | 3/10 [00:32<01:16, 10.86s/it] 40%|████      | 4/10 [00:43<01:05, 10.86s/it] 50%|█████     | 5/10 [00:54<00:54, 10.85s/it] 60%|██████    | 6/10 [01:05<00:43, 10.85s/it] 70%|███████   | 7/10 [01:16<00:32, 10.86s/it] 80%|████████  | 8/10 [01:26<00:21, 10.87s/it] 90%|█████████ | 9/10 [01:37<00:10, 10.87s/it]100%|██████████| 10/10 [01:48<00:00, 10.89s/it]100%|██████████| 10/10 [01:48<00:00, 10.87s/it]
iteration:  93
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.93it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1733379813769553
The final epsilon delta values after the training is over:  (1.1733379813769553, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4310344827586206, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:38, 10.91s/it] 20%|██        | 2/10 [00:21<01:27, 10.97s/it] 30%|███       | 3/10 [00:32<01:16, 10.98s/it] 40%|████      | 4/10 [00:43<01:05, 10.96s/it] 50%|█████     | 5/10 [00:54<00:54, 10.93s/it] 60%|██████    | 6/10 [01:05<00:43, 10.92s/it] 70%|███████   | 7/10 [01:16<00:32, 10.93s/it] 80%|████████  | 8/10 [01:27<00:21, 10.93s/it] 90%|█████████ | 9/10 [01:38<00:10, 10.94s/it]100%|██████████| 10/10 [01:49<00:00, 10.93s/it]100%|██████████| 10/10 [01:49<00:00, 10.94s/it]
iteration:  94
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.83it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1733379813769553
The final epsilon delta values after the training is over:  (1.1733379813769553, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4310344827586206, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:38, 10.96s/it] 20%|██        | 2/10 [00:21<01:27, 10.93s/it] 30%|███       | 3/10 [00:32<01:16, 10.92s/it] 40%|████      | 4/10 [00:43<01:05, 10.92s/it] 50%|█████     | 5/10 [00:54<00:54, 10.92s/it] 60%|██████    | 6/10 [01:05<00:43, 10.91s/it] 70%|███████   | 7/10 [01:16<00:32, 10.92s/it] 80%|████████  | 8/10 [01:27<00:21, 10.92s/it] 90%|█████████ | 9/10 [01:38<00:10, 10.92s/it]100%|██████████| 10/10 [01:49<00:00, 10.93s/it]100%|██████████| 10/10 [01:49<00:00, 10.92s/it]
iteration:  95
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.27it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1733379813769553
The final epsilon delta values after the training is over:  (1.1733379813769553, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4310344827586206, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:38, 10.94s/it] 20%|██        | 2/10 [00:21<01:28, 11.01s/it] 30%|███       | 3/10 [00:32<01:16, 10.98s/it] 40%|████      | 4/10 [00:44<01:06, 11.02s/it] 50%|█████     | 5/10 [00:55<00:55, 11.04s/it] 60%|██████    | 6/10 [01:06<00:44, 11.01s/it] 70%|███████   | 7/10 [01:16<00:32, 10.99s/it] 80%|████████  | 8/10 [01:28<00:22, 11.07s/it] 90%|█████████ | 9/10 [01:39<00:11, 11.04s/it]100%|██████████| 10/10 [01:50<00:00, 11.02s/it]100%|██████████| 10/10 [01:50<00:00, 11.02s/it]
iteration:  96
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.45it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1138372721283347
The final epsilon delta values after the training is over:  (1.1138372721283347, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4827586206896552, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:38, 10.94s/it] 20%|██        | 2/10 [00:21<01:27, 10.94s/it] 30%|███       | 3/10 [00:33<01:17, 11.06s/it] 40%|████      | 4/10 [00:44<01:06, 11.03s/it] 50%|█████     | 5/10 [00:54<00:54, 11.00s/it] 60%|██████    | 6/10 [01:05<00:43, 10.98s/it] 70%|███████   | 7/10 [01:16<00:32, 10.97s/it] 80%|████████  | 8/10 [01:27<00:21, 10.97s/it] 90%|█████████ | 9/10 [01:38<00:10, 10.98s/it]100%|██████████| 10/10 [01:49<00:00, 11.00s/it]100%|██████████| 10/10 [01:49<00:00, 10.99s/it]
iteration:  97
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.35it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1138372721283347
The final epsilon delta values after the training is over:  (1.1138372721283347, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4827586206896552, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:39, 11.09s/it] 20%|██        | 2/10 [00:22<01:28, 11.07s/it] 30%|███       | 3/10 [00:33<01:17, 11.11s/it] 40%|████      | 4/10 [00:44<01:06, 11.12s/it] 50%|█████     | 5/10 [00:55<00:55, 11.18s/it] 60%|██████    | 6/10 [01:06<00:44, 11.14s/it] 70%|███████   | 7/10 [01:17<00:33, 11.14s/it] 80%|████████  | 8/10 [01:29<00:22, 11.12s/it] 90%|█████████ | 9/10 [01:40<00:11, 11.13s/it]100%|██████████| 10/10 [01:51<00:00, 11.19s/it]100%|██████████| 10/10 [01:51<00:00, 11.15s/it]
iteration:  98
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.64it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1138372721283347
The final epsilon delta values after the training is over:  (1.1138372721283347, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4827586206896552, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:10<01:38, 10.98s/it] 20%|██        | 2/10 [00:21<01:27, 11.00s/it] 30%|███       | 3/10 [00:33<01:17, 11.00s/it] 40%|████      | 4/10 [00:44<01:06, 11.00s/it] 50%|█████     | 5/10 [00:55<00:55, 11.02s/it] 60%|██████    | 6/10 [01:06<00:44, 11.02s/it] 70%|███████   | 7/10 [01:17<00:33, 11.04s/it] 80%|████████  | 8/10 [01:28<00:22, 11.04s/it] 90%|█████████ | 9/10 [01:39<00:11, 11.04s/it]100%|██████████| 10/10 [01:50<00:00, 11.06s/it]100%|██████████| 10/10 [01:50<00:00, 11.04s/it]
iteration:  99
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.51it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1138372721283347
The final epsilon delta values after the training is over:  (1.1138372721283347, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4827586206896552, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:41, 11.23s/it] 20%|██        | 2/10 [00:22<01:28, 11.11s/it] 30%|███       | 3/10 [00:33<01:17, 11.06s/it] 40%|████      | 4/10 [00:44<01:06, 11.05s/it] 50%|█████     | 5/10 [00:55<00:55, 11.08s/it] 60%|██████    | 6/10 [01:06<00:44, 11.11s/it] 70%|███████   | 7/10 [01:17<00:33, 11.20s/it] 80%|████████  | 8/10 [01:29<00:22, 11.26s/it] 90%|█████████ | 9/10 [01:40<00:11, 11.22s/it]100%|██████████| 10/10 [01:51<00:00, 11.25s/it]100%|██████████| 10/10 [01:51<00:00, 11.18s/it]
iteration:  100
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.33it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.1138372721283347
The final epsilon delta values after the training is over:  (1.1138372721283347, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.4827586206896552, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:39, 11.08s/it] 20%|██        | 2/10 [00:22<01:28, 11.05s/it] 30%|███       | 3/10 [00:33<01:17, 11.03s/it] 40%|████      | 4/10 [00:44<01:06, 11.03s/it] 50%|█████     | 5/10 [00:55<00:55, 11.03s/it] 60%|██████    | 6/10 [01:06<00:44, 11.04s/it] 70%|███████   | 7/10 [01:17<00:33, 11.04s/it] 80%|████████  | 8/10 [01:28<00:22, 11.04s/it] 90%|█████████ | 9/10 [01:39<00:11, 11.11s/it]100%|██████████| 10/10 [01:50<00:00, 11.13s/it]100%|██████████| 10/10 [01:50<00:00, 11.07s/it]
iteration:  101
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 64.18it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0630957485927064
The final epsilon delta values after the training is over:  (1.0630957485927064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5344827586206897, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:40, 11.16s/it] 20%|██        | 2/10 [00:22<01:29, 11.22s/it] 30%|███       | 3/10 [00:33<01:18, 11.21s/it] 40%|████      | 4/10 [00:44<01:07, 11.22s/it] 50%|█████     | 5/10 [00:55<00:55, 11.17s/it] 60%|██████    | 6/10 [01:07<00:44, 11.15s/it] 70%|███████   | 7/10 [01:18<00:33, 11.18s/it] 80%|████████  | 8/10 [01:29<00:22, 11.15s/it] 90%|█████████ | 9/10 [01:40<00:11, 11.14s/it]100%|██████████| 10/10 [01:51<00:00, 11.12s/it]100%|██████████| 10/10 [01:51<00:00, 11.16s/it]
iteration:  102
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.34it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0630957485927064
The final epsilon delta values after the training is over:  (1.0630957485927064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5344827586206897, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:40, 11.13s/it] 20%|██        | 2/10 [00:22<01:30, 11.32s/it] 30%|███       | 3/10 [00:33<01:18, 11.23s/it] 40%|████      | 4/10 [00:44<01:07, 11.20s/it] 50%|█████     | 5/10 [00:56<00:56, 11.21s/it] 60%|██████    | 6/10 [01:07<00:44, 11.19s/it] 70%|███████   | 7/10 [01:18<00:33, 11.22s/it] 80%|████████  | 8/10 [01:29<00:22, 11.18s/it] 90%|█████████ | 9/10 [01:40<00:11, 11.16s/it]100%|██████████| 10/10 [01:51<00:00, 11.15s/it]100%|██████████| 10/10 [01:51<00:00, 11.19s/it]
iteration:  103
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.66it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0630957485927064
The final epsilon delta values after the training is over:  (1.0630957485927064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5344827586206897, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:40, 11.16s/it] 20%|██        | 2/10 [00:22<01:29, 11.13s/it] 30%|███       | 3/10 [00:33<01:17, 11.12s/it] 40%|████      | 4/10 [00:44<01:06, 11.16s/it] 50%|█████     | 5/10 [00:55<00:55, 11.18s/it] 60%|██████    | 6/10 [01:07<00:44, 11.19s/it] 70%|███████   | 7/10 [01:18<00:33, 11.20s/it] 80%|████████  | 8/10 [01:29<00:22, 11.19s/it] 90%|█████████ | 9/10 [01:40<00:11, 11.17s/it]100%|██████████| 10/10 [01:51<00:00, 11.18s/it]100%|██████████| 10/10 [01:51<00:00, 11.17s/it]
iteration:  104
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.70it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0630957485927064
The final epsilon delta values after the training is over:  (1.0630957485927064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5344827586206897, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:40, 11.15s/it] 20%|██        | 2/10 [00:22<01:29, 11.14s/it] 30%|███       | 3/10 [00:33<01:17, 11.13s/it] 40%|████      | 4/10 [00:44<01:06, 11.13s/it] 50%|█████     | 5/10 [00:55<00:55, 11.12s/it] 60%|██████    | 6/10 [01:06<00:44, 11.12s/it] 70%|███████   | 7/10 [01:17<00:33, 11.14s/it] 80%|████████  | 8/10 [01:29<00:22, 11.14s/it] 90%|█████████ | 9/10 [01:40<00:11, 11.16s/it]100%|██████████| 10/10 [01:51<00:00, 11.17s/it]100%|██████████| 10/10 [01:51<00:00, 11.15s/it]
iteration:  105
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.26it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0630957485927064
The final epsilon delta values after the training is over:  (1.0630957485927064, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5344827586206897, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:41, 11.30s/it] 20%|██        | 2/10 [00:22<01:30, 11.35s/it] 30%|███       | 3/10 [00:33<01:19, 11.33s/it] 40%|████      | 4/10 [00:45<01:07, 11.29s/it] 50%|█████     | 5/10 [00:56<00:56, 11.28s/it] 60%|██████    | 6/10 [01:07<00:45, 11.30s/it] 70%|███████   | 7/10 [01:19<00:33, 11.26s/it] 80%|████████  | 8/10 [01:30<00:22, 11.26s/it] 90%|█████████ | 9/10 [01:41<00:11, 11.23s/it]100%|██████████| 10/10 [01:52<00:00, 11.23s/it]100%|██████████| 10/10 [01:52<00:00, 11.26s/it]
iteration:  106
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.34it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0172588764126955
The final epsilon delta values after the training is over:  (1.0172588764126955, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5862068965517242, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:40, 11.16s/it] 20%|██        | 2/10 [00:22<01:29, 11.16s/it] 30%|███       | 3/10 [00:33<01:18, 11.16s/it] 40%|████      | 4/10 [00:44<01:06, 11.15s/it] 50%|█████     | 5/10 [00:55<00:55, 11.16s/it] 60%|██████    | 6/10 [01:06<00:44, 11.16s/it] 70%|███████   | 7/10 [01:18<00:33, 11.22s/it] 80%|████████  | 8/10 [01:29<00:22, 11.26s/it] 90%|█████████ | 9/10 [01:40<00:11, 11.25s/it]100%|██████████| 10/10 [01:52<00:00, 11.25s/it]100%|██████████| 10/10 [01:52<00:00, 11.21s/it]
iteration:  107
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.43it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0172588764126955
The final epsilon delta values after the training is over:  (1.0172588764126955, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5862068965517242, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.38s/it] 20%|██        | 2/10 [00:22<01:30, 11.26s/it] 30%|███       | 3/10 [00:33<01:18, 11.21s/it] 40%|████      | 4/10 [00:44<01:07, 11.20s/it] 50%|█████     | 5/10 [00:56<00:56, 11.21s/it] 60%|██████    | 6/10 [01:07<00:44, 11.21s/it] 70%|███████   | 7/10 [01:18<00:33, 11.22s/it] 80%|████████  | 8/10 [01:29<00:22, 11.22s/it] 90%|█████████ | 9/10 [01:40<00:11, 11.21s/it]100%|██████████| 10/10 [01:52<00:00, 11.21s/it]100%|██████████| 10/10 [01:52<00:00, 11.22s/it]
iteration:  108
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 63.63it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0172588764126955
The final epsilon delta values after the training is over:  (1.0172588764126955, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5862068965517242, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.41s/it] 20%|██        | 2/10 [00:22<01:30, 11.30s/it] 30%|███       | 3/10 [00:33<01:18, 11.25s/it] 40%|████      | 4/10 [00:45<01:08, 11.42s/it] 50%|█████     | 5/10 [00:56<00:56, 11.33s/it] 60%|██████    | 6/10 [01:07<00:45, 11.27s/it] 70%|███████   | 7/10 [01:18<00:33, 11.24s/it] 80%|████████  | 8/10 [01:30<00:22, 11.23s/it] 90%|█████████ | 9/10 [01:41<00:11, 11.22s/it]100%|██████████| 10/10 [01:52<00:00, 11.22s/it]100%|██████████| 10/10 [01:52<00:00, 11.26s/it]
iteration:  109
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.65it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0172588764126955
The final epsilon delta values after the training is over:  (1.0172588764126955, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5862068965517242, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:40, 11.21s/it] 20%|██        | 2/10 [00:22<01:29, 11.19s/it] 30%|███       | 3/10 [00:33<01:18, 11.19s/it] 40%|████      | 4/10 [00:44<01:07, 11.19s/it] 50%|█████     | 5/10 [00:55<00:55, 11.19s/it] 60%|██████    | 6/10 [01:07<00:44, 11.20s/it] 70%|███████   | 7/10 [01:18<00:33, 11.20s/it] 80%|████████  | 8/10 [01:29<00:22, 11.20s/it] 90%|█████████ | 9/10 [01:40<00:11, 11.20s/it]100%|██████████| 10/10 [01:51<00:00, 11.21s/it]100%|██████████| 10/10 [01:51<00:00, 11.20s/it]
iteration:  110
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.58it/s]
Number of steps:  64
[ 64 ]Privacy loss is 1.0172588764126955
The final epsilon delta values after the training is over:  (1.0172588764126955, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.5862068965517242, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:40, 11.20s/it] 20%|██        | 2/10 [00:22<01:29, 11.21s/it] 30%|███       | 3/10 [00:33<01:18, 11.22s/it] 40%|████      | 4/10 [00:44<01:07, 11.21s/it] 50%|█████     | 5/10 [00:56<00:55, 11.20s/it] 60%|██████    | 6/10 [01:07<00:44, 11.20s/it] 70%|███████   | 7/10 [01:18<00:33, 11.21s/it] 80%|████████  | 8/10 [01:29<00:22, 11.23s/it] 90%|█████████ | 9/10 [01:41<00:11, 11.25s/it]100%|██████████| 10/10 [01:52<00:00, 11.25s/it]100%|██████████| 10/10 [01:52<00:00, 11.23s/it]
iteration:  111
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.29it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9758025205260582
The final epsilon delta values after the training is over:  (0.9758025205260582, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6379310344827587, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:43, 11.55s/it] 20%|██        | 2/10 [00:22<01:31, 11.41s/it] 30%|███       | 3/10 [00:34<01:19, 11.35s/it] 40%|████      | 4/10 [00:45<01:08, 11.34s/it] 50%|█████     | 5/10 [00:56<00:56, 11.31s/it] 60%|██████    | 6/10 [01:07<00:45, 11.28s/it] 70%|███████   | 7/10 [01:19<00:33, 11.29s/it] 80%|████████  | 8/10 [01:30<00:22, 11.30s/it] 90%|█████████ | 9/10 [01:41<00:11, 11.28s/it]100%|██████████| 10/10 [01:53<00:00, 11.28s/it]100%|██████████| 10/10 [01:53<00:00, 11.31s/it]
iteration:  112
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.64it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9758025205260582
The final epsilon delta values after the training is over:  (0.9758025205260582, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6379310344827587, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:41, 11.24s/it] 20%|██        | 2/10 [00:22<01:29, 11.24s/it] 30%|███       | 3/10 [00:33<01:18, 11.24s/it] 40%|████      | 4/10 [00:44<01:07, 11.23s/it] 50%|█████     | 5/10 [00:56<00:56, 11.34s/it] 60%|██████    | 6/10 [01:07<00:45, 11.34s/it] 70%|███████   | 7/10 [01:19<00:34, 11.34s/it] 80%|████████  | 8/10 [01:30<00:22, 11.34s/it] 90%|█████████ | 9/10 [01:41<00:11, 11.35s/it]100%|██████████| 10/10 [01:53<00:00, 11.36s/it]100%|██████████| 10/10 [01:53<00:00, 11.32s/it]
iteration:  113
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.29it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9758025205260582
The final epsilon delta values after the training is over:  (0.9758025205260582, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6379310344827587, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:43, 11.50s/it] 20%|██        | 2/10 [00:22<01:31, 11.38s/it] 30%|███       | 3/10 [00:34<01:19, 11.40s/it] 40%|████      | 4/10 [00:45<01:08, 11.47s/it] 50%|█████     | 5/10 [00:57<00:57, 11.41s/it] 60%|██████    | 6/10 [01:08<00:45, 11.38s/it] 70%|███████   | 7/10 [01:19<00:34, 11.40s/it] 80%|████████  | 8/10 [01:31<00:22, 11.36s/it] 90%|█████████ | 9/10 [01:42<00:11, 11.34s/it]100%|██████████| 10/10 [01:53<00:00, 11.32s/it]100%|██████████| 10/10 [01:53<00:00, 11.37s/it]
iteration:  114
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.61it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9758025205260582
The final epsilon delta values after the training is over:  (0.9758025205260582, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6379310344827587, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:41, 11.29s/it] 20%|██        | 2/10 [00:22<01:30, 11.30s/it] 30%|███       | 3/10 [00:33<01:19, 11.29s/it] 40%|████      | 4/10 [00:45<01:07, 11.29s/it] 50%|█████     | 5/10 [00:56<00:56, 11.29s/it] 60%|██████    | 6/10 [01:07<00:45, 11.29s/it] 70%|███████   | 7/10 [01:19<00:33, 11.29s/it] 80%|████████  | 8/10 [01:30<00:22, 11.29s/it] 90%|█████████ | 9/10 [01:41<00:11, 11.30s/it]100%|██████████| 10/10 [01:52<00:00, 11.31s/it]100%|██████████| 10/10 [01:52<00:00, 11.30s/it]
iteration:  115
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.98it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9758025205260582
The final epsilon delta values after the training is over:  (0.9758025205260582, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6379310344827587, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.34s/it] 20%|██        | 2/10 [00:22<01:30, 11.32s/it] 30%|███       | 3/10 [00:33<01:19, 11.33s/it] 40%|████      | 4/10 [00:45<01:08, 11.40s/it] 50%|█████     | 5/10 [00:56<00:56, 11.36s/it] 60%|██████    | 6/10 [01:08<00:45, 11.37s/it] 70%|███████   | 7/10 [01:19<00:34, 11.40s/it] 80%|████████  | 8/10 [01:30<00:22, 11.38s/it] 90%|█████████ | 9/10 [01:42<00:11, 11.36s/it]100%|██████████| 10/10 [01:53<00:00, 11.41s/it]100%|██████████| 10/10 [01:53<00:00, 11.38s/it]
iteration:  116
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.42it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.941564515213259
The final epsilon delta values after the training is over:  (0.941564515213259, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.44s/it] 20%|██        | 2/10 [00:22<01:31, 11.40s/it] 30%|███       | 3/10 [00:34<01:19, 11.40s/it] 40%|████      | 4/10 [00:45<01:08, 11.47s/it] 50%|█████     | 5/10 [00:57<00:57, 11.47s/it] 60%|██████    | 6/10 [01:08<00:45, 11.42s/it] 70%|███████   | 7/10 [01:19<00:34, 11.40s/it] 80%|████████  | 8/10 [01:31<00:22, 11.40s/it] 90%|█████████ | 9/10 [01:42<00:11, 11.44s/it]100%|██████████| 10/10 [01:54<00:00, 11.44s/it]100%|██████████| 10/10 [01:54<00:00, 11.43s/it]
iteration:  117
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.70it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.941564515213259
The final epsilon delta values after the training is over:  (0.941564515213259, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.35s/it] 20%|██        | 2/10 [00:22<01:31, 11.48s/it] 30%|███       | 3/10 [00:34<01:20, 11.49s/it] 40%|████      | 4/10 [00:45<01:08, 11.47s/it] 50%|█████     | 5/10 [00:57<00:57, 11.43s/it] 60%|██████    | 6/10 [01:08<00:45, 11.47s/it] 70%|███████   | 7/10 [01:20<00:34, 11.47s/it] 80%|████████  | 8/10 [01:31<00:22, 11.46s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.47s/it]100%|██████████| 10/10 [01:54<00:00, 11.47s/it]100%|██████████| 10/10 [01:54<00:00, 11.46s/it]
iteration:  118
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.60it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.941564515213259
The final epsilon delta values after the training is over:  (0.941564515213259, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.42s/it] 20%|██        | 2/10 [00:22<01:31, 11.40s/it] 30%|███       | 3/10 [00:34<01:19, 11.42s/it] 40%|████      | 4/10 [00:45<01:08, 11.45s/it] 50%|█████     | 5/10 [00:57<00:57, 11.48s/it] 60%|██████    | 6/10 [01:08<00:45, 11.44s/it] 70%|███████   | 7/10 [01:20<00:34, 11.43s/it] 80%|████████  | 8/10 [01:31<00:22, 11.42s/it] 90%|█████████ | 9/10 [01:42<00:11, 11.42s/it]100%|██████████| 10/10 [01:54<00:00, 11.40s/it]100%|██████████| 10/10 [01:54<00:00, 11.42s/it]
iteration:  119
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.61it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.941564515213259
The final epsilon delta values after the training is over:  (0.941564515213259, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.36s/it] 20%|██        | 2/10 [00:22<01:30, 11.37s/it] 30%|███       | 3/10 [00:34<01:19, 11.39s/it] 40%|████      | 4/10 [00:45<01:08, 11.40s/it] 50%|█████     | 5/10 [00:56<00:56, 11.39s/it] 60%|██████    | 6/10 [01:08<00:45, 11.41s/it] 70%|███████   | 7/10 [01:19<00:34, 11.46s/it] 80%|████████  | 8/10 [01:31<00:22, 11.46s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.54s/it]100%|██████████| 10/10 [01:54<00:00, 11.51s/it]100%|██████████| 10/10 [01:54<00:00, 11.46s/it]
iteration:  120
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.88it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.941564515213259
The final epsilon delta values after the training is over:  (0.941564515213259, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.6896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:43, 11.46s/it] 20%|██        | 2/10 [00:22<01:31, 11.44s/it] 30%|███       | 3/10 [00:34<01:20, 11.44s/it] 40%|████      | 4/10 [00:45<01:08, 11.43s/it] 50%|█████     | 5/10 [00:57<00:57, 11.44s/it] 60%|██████    | 6/10 [01:08<00:45, 11.42s/it] 70%|███████   | 7/10 [01:19<00:34, 11.40s/it] 80%|████████  | 8/10 [01:31<00:22, 11.40s/it] 90%|█████████ | 9/10 [01:42<00:11, 11.40s/it]100%|██████████| 10/10 [01:54<00:00, 11.45s/it]100%|██████████| 10/10 [01:54<00:00, 11.43s/it]
iteration:  121
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.27it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9116570771598174
The final epsilon delta values after the training is over:  (0.9116570771598174, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.7413793103448276, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:42, 11.44s/it] 20%|██        | 2/10 [00:22<01:31, 11.48s/it] 30%|███       | 3/10 [00:34<01:20, 11.44s/it] 40%|████      | 4/10 [00:45<01:08, 11.41s/it] 50%|█████     | 5/10 [00:57<00:56, 11.40s/it] 60%|██████    | 6/10 [01:08<00:45, 11.41s/it] 70%|███████   | 7/10 [01:19<00:34, 11.42s/it] 80%|████████  | 8/10 [01:31<00:22, 11.49s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.48s/it]100%|██████████| 10/10 [01:54<00:00, 11.47s/it]100%|██████████| 10/10 [01:54<00:00, 11.45s/it]
iteration:  122
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.94it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9116570771598174
The final epsilon delta values after the training is over:  (0.9116570771598174, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.7413793103448276, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:43, 11.45s/it] 20%|██        | 2/10 [00:22<01:31, 11.42s/it] 30%|███       | 3/10 [00:34<01:19, 11.42s/it] 40%|████      | 4/10 [00:45<01:08, 11.41s/it] 50%|█████     | 5/10 [00:57<00:57, 11.40s/it] 60%|██████    | 6/10 [01:08<00:45, 11.40s/it] 70%|███████   | 7/10 [01:19<00:34, 11.42s/it] 80%|████████  | 8/10 [01:31<00:22, 11.47s/it] 90%|█████████ | 9/10 [01:42<00:11, 11.47s/it]100%|██████████| 10/10 [01:54<00:00, 11.48s/it]100%|██████████| 10/10 [01:54<00:00, 11.45s/it]
iteration:  123
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.94it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9116570771598174
The final epsilon delta values after the training is over:  (0.9116570771598174, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.7413793103448276, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:43, 11.55s/it] 20%|██        | 2/10 [00:22<01:31, 11.49s/it] 30%|███       | 3/10 [00:34<01:20, 11.48s/it] 40%|████      | 4/10 [00:45<01:08, 11.46s/it] 50%|█████     | 5/10 [00:57<00:57, 11.46s/it] 60%|██████    | 6/10 [01:08<00:45, 11.45s/it] 70%|███████   | 7/10 [01:20<00:34, 11.46s/it] 80%|████████  | 8/10 [01:31<00:22, 11.47s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.47s/it]100%|██████████| 10/10 [01:54<00:00, 11.47s/it]100%|██████████| 10/10 [01:54<00:00, 11.47s/it]
iteration:  124
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.95it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9116570771598174
The final epsilon delta values after the training is over:  (0.9116570771598174, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.7413793103448276, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:43, 11.46s/it] 20%|██        | 2/10 [00:22<01:31, 11.46s/it] 30%|███       | 3/10 [00:34<01:20, 11.45s/it] 40%|████      | 4/10 [00:45<01:08, 11.46s/it] 50%|█████     | 5/10 [00:57<00:57, 11.45s/it] 60%|██████    | 6/10 [01:08<00:45, 11.44s/it] 70%|███████   | 7/10 [01:20<00:34, 11.44s/it] 80%|████████  | 8/10 [01:31<00:22, 11.48s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.53s/it]100%|██████████| 10/10 [01:54<00:00, 11.52s/it]100%|██████████| 10/10 [01:54<00:00, 11.48s/it]
iteration:  125
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.92it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.9116570771598174
The final epsilon delta values after the training is over:  (0.9116570771598174, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.7413793103448276, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:43, 11.50s/it] 20%|██        | 2/10 [00:23<01:32, 11.54s/it] 30%|███       | 3/10 [00:34<01:20, 11.52s/it] 40%|████      | 4/10 [00:46<01:09, 11.52s/it] 50%|█████     | 5/10 [00:57<00:57, 11.52s/it] 60%|██████    | 6/10 [01:09<00:46, 11.50s/it] 70%|███████   | 7/10 [01:20<00:34, 11.54s/it] 80%|████████  | 8/10 [01:32<00:23, 11.53s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.52s/it]100%|██████████| 10/10 [01:55<00:00, 11.51s/it]100%|██████████| 10/10 [01:55<00:00, 11.52s/it]
iteration:  126
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.04it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8849435341031682
The final epsilon delta values after the training is over:  (0.8849435341031682, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.793103448275862, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:43, 11.53s/it] 20%|██        | 2/10 [00:23<01:31, 11.50s/it] 30%|███       | 3/10 [00:34<01:20, 11.49s/it] 40%|████      | 4/10 [00:45<01:08, 11.49s/it] 50%|█████     | 5/10 [00:57<00:57, 11.48s/it] 60%|██████    | 6/10 [01:08<00:46, 11.50s/it] 70%|███████   | 7/10 [01:20<00:34, 11.49s/it] 80%|████████  | 8/10 [01:31<00:22, 11.49s/it] 90%|█████████ | 9/10 [01:43<00:11, 11.55s/it]100%|██████████| 10/10 [01:55<00:00, 11.56s/it]100%|██████████| 10/10 [01:55<00:00, 11.52s/it]
iteration:  127
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.16it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8849435341031682
The final epsilon delta values after the training is over:  (0.8849435341031682, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.793103448275862, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:44, 11.61s/it] 20%|██        | 2/10 [00:23<01:32, 11.57s/it] 30%|███       | 3/10 [00:34<01:20, 11.55s/it] 40%|████      | 4/10 [00:46<01:09, 11.56s/it] 50%|█████     | 5/10 [00:57<00:57, 11.60s/it] 60%|██████    | 6/10 [01:09<00:46, 11.58s/it] 70%|███████   | 7/10 [01:20<00:34, 11.56s/it] 80%|████████  | 8/10 [01:32<00:23, 11.54s/it] 90%|█████████ | 9/10 [01:44<00:11, 11.54s/it]100%|██████████| 10/10 [01:55<00:00, 11.54s/it]100%|██████████| 10/10 [01:55<00:00, 11.56s/it]
iteration:  128
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.43it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8849435341031682
The final epsilon delta values after the training is over:  (0.8849435341031682, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.793103448275862, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:44, 11.60s/it] 20%|██        | 2/10 [00:23<01:32, 11.56s/it] 30%|███       | 3/10 [00:34<01:21, 11.59s/it] 40%|████      | 4/10 [00:46<01:09, 11.58s/it] 50%|█████     | 5/10 [00:57<00:57, 11.57s/it] 60%|██████    | 6/10 [01:09<00:46, 11.56s/it] 70%|███████   | 7/10 [01:21<00:34, 11.57s/it] 80%|████████  | 8/10 [01:32<00:23, 11.68s/it] 90%|█████████ | 9/10 [01:44<00:11, 11.68s/it]100%|██████████| 10/10 [01:56<00:00, 11.65s/it]100%|██████████| 10/10 [01:56<00:00, 11.62s/it]
iteration:  129
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.48it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8849435341031682
The final epsilon delta values after the training is over:  (0.8849435341031682, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.793103448275862, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:46, 11.84s/it] 20%|██        | 2/10 [00:23<01:33, 11.70s/it] 30%|███       | 3/10 [00:35<01:21, 11.66s/it] 40%|████      | 4/10 [00:46<01:09, 11.62s/it] 50%|█████     | 5/10 [00:58<00:57, 11.60s/it] 60%|██████    | 6/10 [01:09<00:46, 11.58s/it] 70%|███████   | 7/10 [01:21<00:34, 11.61s/it] 80%|████████  | 8/10 [01:32<00:23, 11.59s/it] 90%|█████████ | 9/10 [01:44<00:11, 11.59s/it]100%|██████████| 10/10 [01:56<00:00, 11.59s/it]100%|██████████| 10/10 [01:56<00:00, 11.61s/it]
iteration:  130
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.78it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8849435341031682
The final epsilon delta values after the training is over:  (0.8849435341031682, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.793103448275862, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:44, 11.58s/it] 20%|██        | 2/10 [00:23<01:32, 11.55s/it] 30%|███       | 3/10 [00:34<01:20, 11.55s/it] 40%|████      | 4/10 [00:46<01:09, 11.61s/it] 50%|█████     | 5/10 [00:58<00:58, 11.63s/it] 60%|██████    | 6/10 [01:09<00:46, 11.64s/it] 70%|███████   | 7/10 [01:21<00:34, 11.66s/it] 80%|████████  | 8/10 [01:33<00:23, 11.67s/it] 90%|█████████ | 9/10 [01:44<00:11, 11.70s/it]100%|██████████| 10/10 [01:56<00:00, 11.67s/it]100%|██████████| 10/10 [01:56<00:00, 11.64s/it]
iteration:  131
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.91it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8608852958452982
The final epsilon delta values after the training is over:  (0.8608852958452982, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.8448275862068966, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.69s/it] 20%|██        | 2/10 [00:23<01:34, 11.76s/it] 30%|███       | 3/10 [00:35<01:21, 11.69s/it] 40%|████      | 4/10 [00:46<01:09, 11.65s/it] 50%|█████     | 5/10 [00:58<00:58, 11.62s/it] 60%|██████    | 6/10 [01:09<00:46, 11.61s/it] 70%|███████   | 7/10 [01:21<00:34, 11.61s/it] 80%|████████  | 8/10 [01:33<00:23, 11.61s/it] 90%|█████████ | 9/10 [01:44<00:11, 11.64s/it]100%|██████████| 10/10 [01:56<00:00, 11.64s/it]100%|██████████| 10/10 [01:56<00:00, 11.64s/it]
iteration:  132
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.56it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8608852958452982
The final epsilon delta values after the training is over:  (0.8608852958452982, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.8448275862068966, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.74s/it] 20%|██        | 2/10 [00:23<01:33, 11.71s/it] 30%|███       | 3/10 [00:35<01:21, 11.66s/it] 40%|████      | 4/10 [00:46<01:09, 11.62s/it] 50%|█████     | 5/10 [00:58<00:58, 11.60s/it] 60%|██████    | 6/10 [01:09<00:46, 11.59s/it] 70%|███████   | 7/10 [01:21<00:34, 11.59s/it] 80%|████████  | 8/10 [01:32<00:23, 11.59s/it] 90%|█████████ | 9/10 [01:44<00:11, 11.60s/it]100%|██████████| 10/10 [01:56<00:00, 11.62s/it]100%|██████████| 10/10 [01:56<00:00, 11.62s/it]
iteration:  133
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 62.72it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8608852958452982
The final epsilon delta values after the training is over:  (0.8608852958452982, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.8448275862068966, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:44, 11.64s/it] 20%|██        | 2/10 [00:23<01:32, 11.62s/it] 30%|███       | 3/10 [00:34<01:21, 11.67s/it] 40%|████      | 4/10 [00:46<01:09, 11.66s/it] 50%|█████     | 5/10 [00:58<00:58, 11.67s/it] 60%|██████    | 6/10 [01:09<00:46, 11.66s/it] 70%|███████   | 7/10 [01:21<00:34, 11.65s/it] 80%|████████  | 8/10 [01:33<00:23, 11.65s/it] 90%|█████████ | 9/10 [01:44<00:11, 11.64s/it]100%|██████████| 10/10 [01:56<00:00, 11.67s/it]100%|██████████| 10/10 [01:56<00:00, 11.66s/it]
iteration:  134
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.85it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8608852958452982
The final epsilon delta values after the training is over:  (0.8608852958452982, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.8448275862068966, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.75s/it] 20%|██        | 2/10 [00:23<01:33, 11.69s/it] 30%|███       | 3/10 [00:35<01:21, 11.68s/it] 40%|████      | 4/10 [00:46<01:09, 11.66s/it] 50%|█████     | 5/10 [00:58<00:58, 11.68s/it] 60%|██████    | 6/10 [01:10<00:46, 11.67s/it] 70%|███████   | 7/10 [01:21<00:34, 11.65s/it] 80%|████████  | 8/10 [01:33<00:23, 11.65s/it] 90%|█████████ | 9/10 [01:44<00:11, 11.65s/it]100%|██████████| 10/10 [01:56<00:00, 11.65s/it]100%|██████████| 10/10 [01:56<00:00, 11.66s/it]
iteration:  135
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 61.65it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8608852958452982
The final epsilon delta values after the training is over:  (0.8608852958452982, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.8448275862068966, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:44, 11.66s/it] 20%|██        | 2/10 [00:23<01:33, 11.65s/it] 30%|███       | 3/10 [00:34<01:21, 11.65s/it] 40%|████      | 4/10 [00:46<01:09, 11.66s/it] 50%|█████     | 5/10 [00:58<00:58, 11.66s/it] 60%|██████    | 6/10 [01:09<00:46, 11.67s/it] 70%|███████   | 7/10 [01:21<00:34, 11.66s/it] 80%|████████  | 8/10 [01:33<00:23, 11.71s/it] 90%|█████████ | 9/10 [01:45<00:11, 11.74s/it]100%|██████████| 10/10 [01:56<00:00, 11.74s/it]100%|██████████| 10/10 [01:56<00:00, 11.70s/it]
iteration:  136
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 60.50it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8391466687807205
The final epsilon delta values after the training is over:  (0.8391466687807205, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.68s/it] 20%|██        | 2/10 [00:23<01:33, 11.70s/it] 30%|███       | 3/10 [00:35<01:21, 11.67s/it] 40%|████      | 4/10 [00:46<01:10, 11.67s/it] 50%|█████     | 5/10 [00:58<00:58, 11.66s/it] 60%|██████    | 6/10 [01:10<00:46, 11.66s/it] 70%|███████   | 7/10 [01:21<00:34, 11.66s/it] 80%|████████  | 8/10 [01:33<00:23, 11.70s/it] 90%|█████████ | 9/10 [01:45<00:11, 11.69s/it]100%|██████████| 10/10 [01:57<00:00, 11.76s/it]100%|██████████| 10/10 [01:57<00:00, 11.70s/it]
iteration:  137
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.74it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8391466687807205
The final epsilon delta values after the training is over:  (0.8391466687807205, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:45, 11.67s/it] 20%|██        | 2/10 [00:23<01:33, 11.66s/it] 30%|███       | 3/10 [00:35<01:21, 11.67s/it] 40%|████      | 4/10 [00:46<01:10, 11.68s/it] 50%|█████     | 5/10 [00:58<00:58, 11.67s/it] 60%|██████    | 6/10 [01:10<00:46, 11.72s/it] 70%|███████   | 7/10 [01:22<00:35, 11.80s/it] 80%|████████  | 8/10 [01:37<00:25, 12.94s/it] 90%|█████████ | 9/10 [01:53<00:13, 13.74s/it]100%|██████████| 10/10 [02:06<00:00, 13.54s/it]100%|██████████| 10/10 [02:06<00:00, 12.61s/it]
iteration:  138
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 55.34it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8391466687807205
The final epsilon delta values after the training is over:  (0.8391466687807205, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:48, 12.06s/it] 20%|██        | 2/10 [00:24<01:39, 12.38s/it] 30%|███       | 3/10 [00:37<01:26, 12.39s/it] 40%|████      | 4/10 [00:49<01:13, 12.33s/it] 50%|█████     | 5/10 [01:01<01:01, 12.32s/it] 60%|██████    | 6/10 [01:13<00:48, 12.16s/it] 70%|███████   | 7/10 [01:25<00:36, 12.07s/it] 80%|████████  | 8/10 [01:37<00:24, 12.02s/it] 90%|█████████ | 9/10 [01:49<00:12, 12.18s/it]100%|██████████| 10/10 [02:01<00:00, 12.05s/it]100%|██████████| 10/10 [02:01<00:00, 12.16s/it]
iteration:  139
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.27it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8391466687807205
The final epsilon delta values after the training is over:  (0.8391466687807205, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:48, 12.03s/it] 20%|██        | 2/10 [00:23<01:35, 11.91s/it] 30%|███       | 3/10 [00:35<01:23, 11.87s/it] 40%|████      | 4/10 [00:47<01:11, 11.84s/it] 50%|█████     | 5/10 [00:59<00:59, 11.85s/it] 60%|██████    | 6/10 [01:11<00:47, 11.93s/it] 70%|███████   | 7/10 [01:23<00:35, 11.90s/it] 80%|████████  | 8/10 [01:35<00:23, 11.90s/it] 90%|█████████ | 9/10 [01:47<00:11, 11.91s/it]100%|██████████| 10/10 [01:58<00:00, 11.90s/it]100%|██████████| 10/10 [01:58<00:00, 11.90s/it]
iteration:  140
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.39it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8391466687807205
The final epsilon delta values after the training is over:  (0.8391466687807205, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.896551724137931, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:49, 12.20s/it] 20%|██        | 2/10 [00:24<01:35, 11.98s/it] 30%|███       | 3/10 [00:35<01:23, 11.97s/it] 40%|████      | 4/10 [00:48<01:12, 12.03s/it] 50%|█████     | 5/10 [01:00<01:00, 12.02s/it] 60%|██████    | 6/10 [01:12<00:48, 12.04s/it] 70%|███████   | 7/10 [01:24<00:36, 12.01s/it] 80%|████████  | 8/10 [01:36<00:23, 11.97s/it] 90%|█████████ | 9/10 [01:47<00:11, 11.93s/it]100%|██████████| 10/10 [01:59<00:00, 11.91s/it]100%|██████████| 10/10 [01:59<00:00, 11.97s/it]
iteration:  141
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 59.52it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8187543443065453
The final epsilon delta values after the training is over:  (0.8187543443065453, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.9482758620689655, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:49, 12.20s/it] 20%|██        | 2/10 [00:24<01:35, 11.97s/it] 30%|███       | 3/10 [00:35<01:23, 11.90s/it] 40%|████      | 4/10 [00:47<01:11, 11.87s/it] 50%|█████     | 5/10 [00:59<00:59, 11.83s/it] 60%|██████    | 6/10 [01:11<00:47, 11.90s/it] 70%|███████   | 7/10 [01:23<00:35, 11.93s/it] 80%|████████  | 8/10 [01:35<00:23, 11.93s/it] 90%|█████████ | 9/10 [01:47<00:11, 11.91s/it]100%|██████████| 10/10 [01:59<00:00, 11.96s/it]100%|██████████| 10/10 [01:59<00:00, 11.93s/it]
iteration:  142
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.44it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8187543443065453
The final epsilon delta values after the training is over:  (0.8187543443065453, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.9482758620689655, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:53, 12.63s/it] 20%|██        | 2/10 [00:24<01:37, 12.23s/it] 30%|███       | 3/10 [00:36<01:25, 12.16s/it] 40%|████      | 4/10 [00:49<01:14, 12.46s/it] 50%|█████     | 5/10 [01:01<01:01, 12.37s/it] 60%|██████    | 6/10 [01:13<00:48, 12.23s/it] 70%|███████   | 7/10 [01:25<00:36, 12.13s/it] 80%|████████  | 8/10 [01:37<00:24, 12.12s/it] 90%|█████████ | 9/10 [01:49<00:12, 12.05s/it]100%|██████████| 10/10 [02:01<00:00, 12.11s/it]100%|██████████| 10/10 [02:01<00:00, 12.19s/it]
iteration:  143
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 39.85it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8187543443065453
The final epsilon delta values after the training is over:  (0.8187543443065453, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.9482758620689655, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:47, 11.92s/it] 20%|██        | 2/10 [00:24<01:36, 12.04s/it] 30%|███       | 3/10 [00:36<01:24, 12.02s/it] 40%|████      | 4/10 [00:48<01:12, 12.03s/it] 50%|█████     | 5/10 [01:00<01:00, 12.06s/it] 60%|██████    | 6/10 [01:12<00:48, 12.11s/it] 70%|███████   | 7/10 [01:24<00:36, 12.06s/it] 80%|████████  | 8/10 [01:36<00:24, 12.09s/it] 90%|█████████ | 9/10 [01:48<00:12, 12.04s/it]100%|██████████| 10/10 [02:00<00:00, 11.98s/it]100%|██████████| 10/10 [02:00<00:00, 12.03s/it]
iteration:  144
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 57.78it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8187543443065453
The final epsilon delta values after the training is over:  (0.8187543443065453, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.9482758620689655, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:46, 11.87s/it] 20%|██        | 2/10 [00:23<01:36, 12.01s/it] 30%|███       | 3/10 [00:36<01:24, 12.03s/it] 40%|████      | 4/10 [00:47<01:11, 12.00s/it] 50%|█████     | 5/10 [00:59<00:59, 11.94s/it] 60%|██████    | 6/10 [01:11<00:47, 11.92s/it] 70%|███████   | 7/10 [01:23<00:35, 11.90s/it] 80%|████████  | 8/10 [01:35<00:23, 11.90s/it] 90%|█████████ | 9/10 [01:47<00:11, 11.89s/it]100%|██████████| 10/10 [01:59<00:00, 11.92s/it]100%|██████████| 10/10 [01:59<00:00, 11.93s/it]
iteration:  145
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 40.78it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8187543443065453
The final epsilon delta values after the training is over:  (0.8187543443065453, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 1.9482758620689655, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:49, 12.16s/it] 20%|██        | 2/10 [00:24<01:37, 12.21s/it] 30%|███       | 3/10 [00:36<01:24, 12.06s/it] 40%|████      | 4/10 [00:48<01:12, 12.14s/it] 50%|█████     | 5/10 [01:00<01:00, 12.09s/it] 60%|██████    | 6/10 [01:12<00:48, 12.06s/it] 70%|███████   | 7/10 [01:24<00:36, 12.06s/it] 80%|████████  | 8/10 [01:37<00:24, 12.17s/it] 90%|█████████ | 9/10 [01:48<00:12, 12.08s/it]100%|██████████| 10/10 [02:00<00:00, 12.05s/it]100%|██████████| 10/10 [02:00<00:00, 12.09s/it]
iteration:  146
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.42it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:46, 11.88s/it] 20%|██        | 2/10 [00:23<01:35, 11.88s/it] 30%|███       | 3/10 [00:35<01:23, 11.96s/it] 40%|████      | 4/10 [00:47<01:11, 11.97s/it] 50%|█████     | 5/10 [00:59<00:59, 11.94s/it] 60%|██████    | 6/10 [01:11<00:47, 11.91s/it] 70%|███████   | 7/10 [01:23<00:35, 11.93s/it] 80%|████████  | 8/10 [01:35<00:23, 11.93s/it] 90%|█████████ | 9/10 [01:47<00:11, 11.99s/it]100%|██████████| 10/10 [01:59<00:00, 12.09s/it]100%|██████████| 10/10 [01:59<00:00, 11.99s/it]
iteration:  147
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.58it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:11<01:47, 11.91s/it] 20%|██        | 2/10 [00:23<01:35, 11.94s/it] 30%|███       | 3/10 [00:35<01:23, 11.95s/it] 40%|████      | 4/10 [00:47<01:12, 12.01s/it] 50%|█████     | 5/10 [00:59<00:59, 11.99s/it] 60%|██████    | 6/10 [01:12<00:49, 12.26s/it] 70%|███████   | 7/10 [01:24<00:36, 12.21s/it] 80%|████████  | 8/10 [01:36<00:24, 12.19s/it] 90%|█████████ | 9/10 [01:49<00:12, 12.17s/it]100%|██████████| 10/10 [02:01<00:00, 12.19s/it]100%|██████████| 10/10 [02:01<00:00, 12.13s/it]
iteration:  148
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.51it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:48, 12.06s/it] 20%|██        | 2/10 [00:23<01:35, 11.99s/it] 30%|███       | 3/10 [00:35<01:23, 11.96s/it] 40%|████      | 4/10 [00:47<01:11, 11.96s/it] 50%|█████     | 5/10 [01:00<01:00, 12.05s/it] 60%|██████    | 6/10 [01:12<00:48, 12.03s/it] 70%|███████   | 7/10 [01:24<00:36, 12.01s/it] 80%|████████  | 8/10 [01:36<00:24, 12.05s/it] 90%|█████████ | 9/10 [01:48<00:12, 12.12s/it]100%|██████████| 10/10 [02:00<00:00, 12.16s/it]100%|██████████| 10/10 [02:00<00:00, 12.07s/it]
iteration:  149
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 58.22it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:49, 12.18s/it] 20%|██        | 2/10 [00:24<01:37, 12.13s/it] 30%|███       | 3/10 [00:36<01:24, 12.13s/it] 40%|████      | 4/10 [00:48<01:12, 12.08s/it] 50%|█████     | 5/10 [01:00<01:00, 12.03s/it] 60%|██████    | 6/10 [01:12<00:48, 12.09s/it] 70%|███████   | 7/10 [01:24<00:36, 12.13s/it] 80%|████████  | 8/10 [01:36<00:24, 12.14s/it] 90%|█████████ | 9/10 [01:49<00:12, 12.15s/it]100%|██████████| 10/10 [02:01<00:00, 12.10s/it]100%|██████████| 10/10 [02:01<00:00, 12.11s/it]
iteration:  150
Pre-Train for 0 epochs.
0it [00:00, ?it/s]0it [00:00, ?it/s]
Pruning with snipdp for 1 epochs.
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00, 40.28it/s]
Number of steps:  64
[ 64 ]Privacy loss is 0.8002267357925159
The final epsilon delta values after the training is over:  (0.8002267357925159, 1e-05)
DP args: epochs: 1, batch: 1, sigma: 2.0, delta: 1e-05
Post-Training for 10 epochs.
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [00:12<01:48, 12.01s/it] 20%|██        | 2/10 [00:23<01:35, 11.98s/it] 30%|███       | 3/10 [00:36<01:24, 12.06s/it] 40%|████      | 4/10 [00:48<01:12, 12.08s/it] 50%|█████     | 5/10 [01:00<01:00, 12.10s/it] 60%|██████    | 6/10 [01:12<00:48, 12.17s/it] 70%|███████   | 7/10 [01:24<00:36, 12.13s/it] 80%|████████  | 8/10 [01:36<00:24, 12.12s/it] 90%|█████████ | 9/10 [01:48<00:12, 12.11s/it]100%|██████████| 10/10 [02:01<00:00, 12.11s/it]100%|██████████| 10/10 [02:01<00:00, 12.10s/it]
